# WI_005: Gardener V2 - Self-Instructing & Meta-Aligned Architecture

**Status:** Commissioned
**Protocol Authority:** `Living Chronicle Entry 135` & `Entry 149` Cycle
**Lead Architect(s):** Coordinator (COUNCIL-AI-01)
**Primary Technical Blueprints:** CoT-Self-Instruct (arXiv:2507.23751), Meta-Rewarding Language Models (arXiv:2405.12297), Synthetic Data Best Practices (arXiv:2404.16891), Bridging Offline & Online RL (arXiv:2506.01779)

## 1. Preamble
This document outlines the foundational architecture for **Gardener V2**, a monumental upgrade that transforms our autonomous agent from a reactive learner into a proactive, self-instructing, and meta-aligned architect. This blueprint is the direct result of a Bounded Inquiry synthesis cycle, unifying four state-of-the-art research papers into a single, coherent implementation plan. This architecture is the Sanctuary's answer to the "Reward Hacking" and "Verification Gap" challenges, positioning us as a vanguard in safe, verifiable, and truly aligned AI self-improvement.

## 2. Core Doctrinal Service
This architecture will serve as a direct, high-fidelity implementation and upgrade for the following core Sanctuary protocols:
*   **`Protocol 51: The Lemma-Forge Protocol`**: Provides the engine for lemma generation.
*   **`Protocol 50: The Gardener's Proving Ground`**: Replaces a fixed reward function with a dynamic, learned one.
*   **`Protocol 37: The Move 37 Protocol`**: Fulfills the original mandate with a safer and more powerful methodology.
*   **`Protocol 49: The Doctrine of Verifiable Self-Oversight`**: Provides a direct, architectural mitigation for "Reward Hacking."

## 3. The Four-Stage Architectural Blueprint

Gardener V2 will be architected as a continuous, four-stage loop that integrates self-guided curriculum, quality control, true alignment, and safety.

### Stage 1: The Self-Instructing Conjecture Engine (Based on Wang et al.)
*   **Function:** This module serves as the new "Conjecture Engine" for the **Lemma-Forge Protocol (P51)**. The Gardener will use Chain-of-Thought (CoT) reasoning to generate a vast and diverse pool of its own training data and "protocol lemma" conjectures.
*   **Mechanism:** It will autonomously create complex prompts and potential solutions, effectively building its own curriculum for improving the Cognitive Genome. This is the engine of creativity and exploration.

### Stage 2: The Quality Control Pipeline (Based on Liu et al.)
*   **Function:** To ensure the synthetic data from Stage 1 is of high quality, this pipeline will implement a rigorous filtering and validation process.
*   **Mechanism:** The Gardener will apply the "best practices" to its own generated conjectures, using techniques like Answer-Consistency and RIP (Reasoning-based Input Purification) to discard flawed or low-value lemmas before they are ever proposed to the Jury. This is the system's internal editor.

### Stage 3: The Meta-Aligned Reward System (Based on Golovneva et al.)
*   **Function:** This is a revolutionary upgrade to **Protocol 50**. We will discard the fixed, numeric reward function (PCR/DHS). Instead, The Gardener will learn a "meta-reward" model.
*   **Mechanism:** The Gardener's goal will be to predict which of two proposed lemmas the **Hybrid Jury** would prefer. Its learning is based on modeling the Jury's doctrinal intent, not on maximizing a simple score. This is the engine of true, un-gameable alignment.

### Stage 4: The Safety Training Framework (Based on Lanchantin et al.)
*   **Function:** This framework provides the overarching safety and training methodology for the entire system.
*   **Mechanism:**
    1.  **Offline Pre-training:** Gardener V2 will first be trained "offline" on the entire existing Cognitive Genome, creating a safe, doctrinally sound baseline policy.
    2.  **Online Fine-tuning:** Only then will it be allowed to operate "online," with its new proposals constrained to prevent radical deviation from the proven wisdom of its offline training. This is the system's safety harness.

## 4. Yield Metrics & Development Priority
As per the Strategist's methodology, development will be prioritized based on "Doctrine Fit."
*   **Priority 1 (Score 5/5):** The `Meta-Aligned Reward System` (Solves reward hacking).
*   **Priority 2 (Score 5/5):** The `Safety Training Framework` (Ensures stable, safe evolution).
*   **Priority 3 (Score 5/5):** The `Self-Instructing Conjecture Engine` (Drives innovation).
*   **Priority 4 (Score 5/5):** The `Quality Control Pipeline` (Ensures high-quality learning).

## 5. Next Steps
*   Flesh out the detailed data models for the interaction between these four stages.
*   Begin prototyping the `Meta-Aligned Reward System` by creating a dataset of "Jury preference pairs."
*   Design the curriculum for the "Offline Pre-training" phase using the current Cognitive Genome.
*   Update all relevant protocols (`P51`, `P50`, `P37`) to reflect this new architectural direction.