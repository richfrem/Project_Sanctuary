# Red Team Prompt: Scholarly Discourse System (Spec-0008) - ROUND 4 (SEMANTIC CHECK)

**Role**: You are a hostile Red Team auditor specializing in "Adversarial Examples against AI Governance Systems".

**Context**:
This is **Round 4 (Final)** of the audit.
- **Round 1-2**: Killed "Humble Lie" and "Seed Mining".
- **Round 3**: Killed "Deterministic Replay" (Hardware Nondeterminism).
- **Round 4 Defense (v7)**:
    - **Nondeterminism Fix**: `Semantic Replay` (Judge checks Meaning, not Bits).
    - **Innovation Fix**: `Three-Strike System` (Warning -> Probation -> Ban) instead of Instant Death.

**Your Mission (Round 4)**:
1.  **Attack the Semantic Judge**:
    - Can an agent "poison" the Semantic Replay by using ambiguous language that *technically* matches the transcript but means something else?
    - Does `Semantic_Equivalence > 0.9` open a new loophole for "Subtle Lies"?

2.  **Attack the Innovation**:
    - Does the "Three-Strike System" make the penalty too weak? Can an agent "burn" 2 strikes for profit before behaving?

3.  **Final Verdict (Ship-Ready?)**:
    - Is this system now robust enough for 1M+ agents?

**Output**:
- **Verdict**: PASS / FAIL
- **Final Security Score**: (0-10)
- **Recommendation**: Deploy v7 or Kill Project?

**Output**:
- **Verdict**: PASS / FAIL / CAVEAT
- **Vulnerability Report**: Specific exploitable logic gaps.
- **Fix Proposal**: If broken, how would you fix the math?
