# RLM Factory Plugin ğŸ­

Recursive Language Model factory â€” distill repository files into semantic summaries
using Ollama for instant context retrieval.

## Installation

### Local Development
```bash
claude --plugin-dir ./plugins/rlm-factory
```

### Prerequisites
- **Claude Code** â‰¥ 1.0.33
- **Python** â‰¥ 3.8
- **Ollama** (for distillation only): `brew install ollama` or [ollama.com](https://ollama.com/)
- **Model**: `ollama pull granite3.2:8b`
- **Python deps**: `pip install requests python-dotenv`

> **Note:** Only `distill` requires Ollama. The `query`, `audit`, and `cleanup` commands
> work offline â€” they just read/write JSON.

### Verify Installation
After loading, `/help` should show:
```
/rlm-factory:distill   Summarize files via Ollama
/rlm-factory:query     Search the semantic ledger
/rlm-factory:audit     Report cache coverage
/rlm-factory:cleanup   Remove stale entries
```

---

## Usage Guide

### Quick Start
```bash
# 1. Check what's already memorized
/rlm-factory:audit

# 2. Search for a topic (no Ollama needed)
/rlm-factory:query "authentication"

# 3. Distill missing files (requires Ollama running)
ollama serve  # in another terminal
/rlm-factory:distill

# 4. Clean up deleted files
/rlm-factory:cleanup --apply
```

### Memory Banks (Profiles)

| Profile | Flag | Cache File | Use For |
|:---|:---|:---|:---|
| **Legacy** | `--type legacy` | `rlm_summary_cache.json` | Docs, protocols, ADRs |
| **Tool** | `--type tool` | `rlm_tool_cache.json` | Python scripts, CLI tools |

### Commands Reference

| Command | Script | Ollama? | Description |
|:---|:---|:---|:---|
| `/rlm-factory:distill` | `distiller.py` | âœ… | LLM-powered file summarization |
| `/rlm-factory:query` | `query_cache.py` | âŒ | Search the semantic ledger |
| `/rlm-factory:audit` | `inventory.py` | âŒ | Coverage report (fs vs cache) |
| `/rlm-factory:cleanup` | `cleanup_cache.py` | âŒ | Remove stale/orphan entries |

### Agent Distillation (The "Brain Upgrade")

For small batches (< 10 files), the agent can distill directly without Ollama by
reading the file and writing the summary into the cache JSON. This is 3-5x faster
and produces higher-quality summaries using frontier model intelligence.

See `skills/rlm-curator/SKILL.md` for the full Agent Distill protocol.

---

## Architecture

See [docs/rlm-factory-workflow.mmd](docs/rlm-factory-workflow.mmd) for the full
sequence diagram.

```mermaid
graph LR
    A["Audit ğŸ“Š"] -->|Coverage gaps| B["Distill ğŸ­"]
    B -->|Ollama + granite3.2| C["Cache JSON"]
    C -->|Search| D["Query ğŸ”"]
    C -->|Curate| E["Cleanup ğŸ§¹"]
```

Additional diagrams (from original tool):
- [distillation_process.mmd](docs/distillation_process.mmd) â€” Detailed data flow
- [search_process.mmd](docs/search_process.mmd) â€” Summary-first search
- [logic.mmd](docs/logic.mmd) â€” Internal decision logic
- [workflow.mmd](docs/workflow.mmd) â€” User workflow

### How It Works
1. **Distiller** reads each file, computes a content hash
2. If hash differs from cache â†’ sends content to Ollama with a summarization prompt
3. Ollama (granite3.2:8b) returns a dense semantic summary
4. Summary is persisted to JSON immediately (crash-resilient)
5. **Query** does O(1) substring search across all summaries
6. **Cleanup** compares cache keys against filesystem to remove stale entries

### Plugin Directory Structure
```
rlm-factory/
â”œâ”€â”€ .claude-plugin/
â”‚   â””â”€â”€ plugin.json              # Plugin identity + runtime deps
â”œâ”€â”€ commands/
â”‚   â”œâ”€â”€ distill.md               # /rlm-factory:distill
â”‚   â”œâ”€â”€ query.md                 # /rlm-factory:query
â”‚   â”œâ”€â”€ audit.md                 # /rlm-factory:audit
â”‚   â””â”€â”€ cleanup.md               # /rlm-factory:cleanup
â”œâ”€â”€ skills/
â”‚   â””â”€â”€ rlm-curator/
â”‚       â””â”€â”€ SKILL.md             # Auto-invoked curator skill
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ distiller.py             # The Writer (Ollama)
â”‚   â”œâ”€â”€ query_cache.py           # The Reader
â”‚   â”œâ”€â”€ inventory.py             # The Auditor
â”‚   â”œâ”€â”€ cleanup_cache.py         # The Janitor
â”‚   â””â”€â”€ rlm_config.py            # Shared config (RLMConfig)
â”œâ”€â”€ resources/
â”‚   â”œâ”€â”€ manifest-index.json      # Profile registry
â”‚   â”œâ”€â”€ distiller_manifest.json  # Default scope config
â”‚   â””â”€â”€ rlm_manifest.json        # Legacy manifest
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ rlm-factory-workflow.mmd # Plugin sequence diagram
â”‚   â”œâ”€â”€ BLUEPRINT.md             # Architecture theory
â”‚   â”œâ”€â”€ research-summary.md      # RLM research paper summary
â”‚   â”œâ”€â”€ distillation_process.mmd # Data flow detail
â”‚   â”œâ”€â”€ search_process.mmd       # Search flow
â”‚   â”œâ”€â”€ logic.mmd                # Internal logic
â”‚   â”œâ”€â”€ workflow.mmd             # User workflow
â”‚   â””â”€â”€ unpacking.mmd            # Legacy unpacking
â”œâ”€â”€ requirements.in              # Python dependencies
â””â”€â”€ README.md
```

---

## License

MIT
