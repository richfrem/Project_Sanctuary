services:
  vector-db:
    image: chromadb/chroma:latest
    container_name: sanctuary-vector-db
    ports:
      - "8000:8000"
    volumes:
      # Use CHROMA_DATA_PATH from .env, default to .vector_data if not set
      - ${CHROMA_DATA_PATH:-.vector_data}:/chroma/chroma
    environment:
      - IS_PERSISTENT=TRUE
      - ANONYMIZED_TELEMETRY=FALSE
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  ollama-model-mcp:
    image: ollama/ollama:latest
    container_name: sanctuary-ollama-mcp
    ports:
      - "11434:11434"
    volumes:
      # Mount point for models persisted on the host machine
      - ./ollama_models:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
      # Use OLLAMA_MODEL from the host environment if available, otherwise default
      - OLLAMA_MODEL=${OLLAMA_MODEL:-Sanctuary-Qwen2-7B:latest}
    deploy:
      resources:
        reservations:
          devices:
            # CRITICAL: Configure for GPU acceleration (Example for NVIDIA/Podman)
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    entrypoint: [ "/bin/sh", "-c" ]
    command:
      - |
        ollama serve &
        sleep 10
        ollama pull $${OLLAMA_MODEL:-Sanctuary-Qwen2-7B:latest}
        wait -n
    restart: unless-stopped

  # Fleet of 8 - Container #1: sanctuary-utils (ADR 060)
  sanctuary-utils:
    build:
      context: .
      dockerfile: mcp_servers/utils/Dockerfile
    container_name: sanctuary-utils
    ports:
      - "${SANCTUARY_UTILS_PORT:-8100}:8000"
    volumes:
      - .:/app
    networks:
      - mcp-network
    environment:
      - PORT=8000
      - PYTHONPATH=/app
    command: [ "python", "-m", "mcp_servers.utils.server" ]
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 5s
    restart: unless-stopped

  # Fleet of 8 - Container #2: sanctuary-filesystem (Task 128)
  sanctuary-filesystem:
    build:
      context: .
      dockerfile: mcp_servers/code/Dockerfile
    container_name: sanctuary-filesystem
    ports:
      - "${SANCTUARY_FILESYSTEM_PORT:-8101}:8000"
    volumes:
      - .:/app
    networks:
      - mcp-network
    environment:
      - PORT=8000
      - PROJECT_ROOT=/app
      - PYTHONUNBUFFERED=1
    command: [ "python", "-m", "mcp_servers.code.server" ]
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 30s
      retries: 3
    restart: unless-stopped

  # Fleet of 8 - Container #3: sanctuary-network (Task 129)
  sanctuary-network:
    build:
      context: .
      dockerfile: mcp_servers/network/Dockerfile
    container_name: sanctuary-network
    ports:
      - "${SANCTUARY_NETWORK_PORT:-8102}:8000"
    volumes:
      - .:/app
    networks:
      - mcp-network
    environment:
      - PORT=8000
      - PYTHONPATH=/app
    command: [ "python", "-m", "mcp_servers.network.server" ]
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 30s
      retries: 3
    restart: unless-stopped

  # Fleet of 8 - Container #4: sanctuary-git (Task 130)
  sanctuary-git:
    build:
      context: .
      dockerfile: mcp_servers/git/Dockerfile
    container_name: sanctuary-git
    ports:
      - "${SANCTUARY_GIT_PORT:-8103}:8000"
    volumes:
      - .:/app
    networks:
      - mcp-network
    environment:
      - PORT=8000
      - PYTHONPATH=/app
    command: [ "python", "-m", "mcp_servers.git.server" ]
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 30s
      retries: 3
    restart: unless-stopped

  # Fleet of 8 - Container #5: sanctuary-cortex (Task 131)
  sanctuary-cortex:
    build:
      context: .
      dockerfile: mcp_servers/rag_cortex/Dockerfile
    container_name: sanctuary-cortex
    ports:
      - "${SANCTUARY_CORTEX_PORT:-8104}:8000"
    volumes:
      - .:/app
    environment:
      - PROJECT_ROOT=/app
      - PYTHONPATH=/app
      - PORT=8000
      - CHROMA_DB_HOST=sanctuary-vector-db
      - CHROMA_DB_PORT=8000
      - OLLAMA_HOST=http://sanctuary-ollama-mcp:11434
    networks:
      - mcp-network
    depends_on:
      - vector-db
      - ollama-model-mcp
    command: [ "python", "-m", "mcp_servers.rag_cortex.server" ]
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 30s
      retries: 3
    restart: unless-stopped

  # Fleet of 8 - Container #6: sanctuary-domain (ADR 061)
  # Hosting: Chronicle, Protocol, Task, ADR, and Python Dev Tools
  sanctuary-domain:
    build:
      context: .
      dockerfile: mcp_servers/domain/Dockerfile
    container_name: sanctuary-domain
    ports:
      - "${SANCTUARY_DOMAIN_PORT:-8105}:8105"
    volumes:
      # Mount project root to allow tools to access all files (linting, etc.)
      - .:/app
    networks:
      - mcp-network
    environment:
      - PROJECT_ROOT=/app
      - DOMAIN_SERVER_PORT=8105
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: '512M'
    # Default FastMCP uses 0.0.0.0 if not specified? Better explicit.
    # Assuming mcp.run() parses args or we rely on python execution.
    # fastmcp uses uvicorn under the hood often.
    command: [ "python", "mcp_servers/domain/unified_server.py", "--port", "8105", "--transport", "sse" ]
    restart: unless-stopped

networks:
  mcp-network:
    driver: bridge
