# Example environment variables for Project_Sanctuary
# Copy this file to `.env` and fill in real secrets / values before running.

# API keys / models
# SECURITY NOTE: Do NOT store secrets here.
# Set these in your Windows User Environment Variables and share via WSLENV.
# See docs/WSL_SECRETS_CONFIGURATION.md for details.
#
# GEMINI_API_KEY=Provided by Windows User Env via WSLENV
# OPENAI_API_KEY=Provided by Windows User Env via WSLENV
# HUGGING_FACE_TOKEN=Provided by Windows User Env via WSLENV

CHAT_GPT_MODEL=gpt-4-turbo
CHAT_GPT_QUOTE_AGENT_MODEL=gpt-4-turbo
OLLAMA_MODEL=Sanctuary-Qwen2-7B:latest
GEMINI_MODEL=gemini-2.5-flash

HUGGING_FACE_USERNAME=richfrem
HUGGING_FACE_REPO=Sanctuary-Qwen2-7B-v1.0-GGUF-Final

# Path to the Chroma DB directory relative to the mnemonic_cortex folder
# The ingestion/inspection scripts expect DB_PATH to point to the chroma_db
# directory (e.g. "chroma_db").
DB_PATH="chroma_db"
# CHROMA_ROOT may be absolute or relative to the repository root.
# When set, vector DB services and scripts will resolve relative paths
# from the repo root. Example: "mnemonic_cortex/chroma_db"
CHROMA_ROOT="mnemonic_cortex/chroma_db"

GITHUB_REPO_URL="https://github.com/richfrem/Project_Sanctuary/blob/main/"

# Engine Configuration Parameters
GEMINI_MAX_TOKENS=4096
GEMINI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=4096
OPENAI_TEMPERATURE=0.7
OLLAMA_MAX_TOKENS=4096
OLLAMA_TEMPERATURE=0.7

# Chroma collection names (used by ingest/inspect/vector service)
# Set these to the exact folder names created by ingestion (e.g. child_chunks_v5)
CHROMA_CHILD_COLLECTION=child_chunks_v5
CHROMA_PARENT_STORE=parent_documents_v5

# Engine Limits (per-request token limits)
GEMINI_PER_REQUEST_LIMIT=200000
OPENAI_PER_REQUEST_LIMIT=100000
OLLAMA_PER_REQUEST_LIMIT=8000

# TPM Limits (tokens per minute)
GEMINI_TPM_LIMIT=250000
OPENAI_TPM_LIMIT=120000
OLLAMA_TPM_LIMIT=999999
