# council_orchestrator Subfolder Snapshot (LLM-Distilled)

Generated On: 2025-11-18T06:59:17.187Z

# Mnemonic Weight (Token Count): ~191,066 tokens

# Directory Structure (relative to council_orchestrator subfolder)
  ./council_orchestrator/README.md
  ./council_orchestrator/README_GUARDIAN_WAKEUP.md
  ./council_orchestrator/ROADMAP/
  ./council_orchestrator/ROADMAP/PHASED_EVOLUTION_PLAN_Phase2-Phase3-Protocol113.md
  ./council_orchestrator/__init__.py
  ./council_orchestrator/command.json
  ./council_orchestrator/command_results/
  ./council_orchestrator/command_results/README.md
  ./council_orchestrator/command_schema.md
  ./council_orchestrator/docs/
  ./council_orchestrator/docs/EVOLUTION_PLAN_PHASES.md
  ./council_orchestrator/docs/OPERATION_OPTICAL_ANVIL_BLUEPRINT.md
  ./council_orchestrator/docs/command_schema.md
  ./council_orchestrator/docs/howto-commit-command.md
  ./council_orchestrator/docs/orchestrator_architecture_package.md
  ./council_orchestrator/orchestrator/
  ./council_orchestrator/orchestrator/__init__.py
  ./council_orchestrator/orchestrator/adaptation_packets.py
  ./council_orchestrator/orchestrator/app.py
  ./council_orchestrator/orchestrator/commands.py
  ./council_orchestrator/orchestrator/config/
  ./council_orchestrator/orchestrator/config/__init__.py
  ./council_orchestrator/orchestrator/config/config.py
  ./council_orchestrator/orchestrator/config/safety.py
  ./council_orchestrator/orchestrator/config/slos.py
  ./council_orchestrator/orchestrator/council/
  ./council_orchestrator/orchestrator/council/__init__.py
  ./council_orchestrator/orchestrator/council/agent.py
  ./council_orchestrator/orchestrator/council/personas.py
  ./council_orchestrator/orchestrator/engines/
  ./council_orchestrator/orchestrator/engines/__init__.py
  ./council_orchestrator/orchestrator/engines/base.py
  ./council_orchestrator/orchestrator/engines/gemini_engine.py
  ./council_orchestrator/orchestrator/engines/ollama_engine.py
  ./council_orchestrator/orchestrator/engines/openai_engine.py
  ./council_orchestrator/orchestrator/events.py
  ./council_orchestrator/orchestrator/gitops.py
  ./council_orchestrator/orchestrator/handlers/
  ./council_orchestrator/orchestrator/handlers/__init__.py
  ./council_orchestrator/orchestrator/handlers/cache_wakeup_handler.py
  ./council_orchestrator/orchestrator/main.py
  ./council_orchestrator/orchestrator/memory/
  ./council_orchestrator/orchestrator/memory/__init__.py
  ./council_orchestrator/orchestrator/memory/cache.py
  ./council_orchestrator/orchestrator/memory/cortex.py
  ./council_orchestrator/orchestrator/optical.py
  ./council_orchestrator/orchestrator/packets/
  ./council_orchestrator/orchestrator/packets/__init__.py
  ./council_orchestrator/orchestrator/packets/aggregator.py
  ./council_orchestrator/orchestrator/packets/emitter.py
  ./council_orchestrator/orchestrator/packets/schema.py
  ./council_orchestrator/orchestrator/regulator.py
  ./council_orchestrator/orchestrator/sentry.py
  ./council_orchestrator/orchestrator/substrate_monitor.py
  ./council_orchestrator/runtime/
  ./council_orchestrator/runtime/task_pid
  ./council_orchestrator/schemas/
  ./council_orchestrator/schemas/council-round-packet-v1.0.0.json
  ./council_orchestrator/schemas/engine_config.json
  ./council_orchestrator/schemas/round_packet_schema.json
  ./council_orchestrator/scripts/
  ./council_orchestrator/scripts/bootstrap_briefing_packet.py
  ./council_orchestrator/scripts/dashboard/
  ./council_orchestrator/scripts/dashboard/README.md
  ./council_orchestrator/scripts/dashboard/jq_dashboard.sh
  ./council_orchestrator/scripts/forge_orchestrator_review_package.py
  ./council_orchestrator/scripts/orchestrator_architecture_package.md
  ./council_orchestrator/scripts/test_cache_standalone.py
  ./council_orchestrator/tests/
  ./council_orchestrator/tests/__init__.py
  ./council_orchestrator/tests/mechanical_test_output.txt
  ./council_orchestrator/tests/orchestrator_test_file.txt
  ./council_orchestrator/tests/test_boot_prefill_runs_once.py
  ./council_orchestrator/tests/test_cache_prefill.py
  ./council_orchestrator/tests/test_cache_request_command.py
  ./council_orchestrator/tests/test_cache_wakeup_flow.py
  ./council_orchestrator/tests/test_command_schema_cache_wakeup.py
  ./council_orchestrator/tests/test_delta_refresh_on_ingest_and_gitops.py
  ./council_orchestrator/tests/test_emitter_jsonl_shape.py
  ./council_orchestrator/tests/test_golden_packet.py
  ./council_orchestrator/tests/test_guardian_seed_contains_primer.py
  ./council_orchestrator/tests/test_import_cycles.py
  ./council_orchestrator/tests/test_mandate_1_command.json
  ./council_orchestrator/tests/test_mandate_2_command_1.json
  ./council_orchestrator/tests/test_mandate_2_command_2.json
  ./council_orchestrator/tests/test_mandate_2_command_3.json
  ./council_orchestrator/tests/test_mandate_2_command_4.json
  ./council_orchestrator/tests/test_mandate_2_command_5.json
  ./council_orchestrator/tests/test_optical_compression.py
  ./council_orchestrator/tests/test_orchestrator_round_packets.py
  ./council_orchestrator/tests/test_orchestrator_v4_2.py
  ./council_orchestrator/tests/test_output_2a.txt
  ./council_orchestrator/tests/test_packets_phase2_fields.py
  ./council_orchestrator/tests/test_self_querying_retriever.py
  ./council_orchestrator/tests/testfile.txt
  ./council_orchestrator/tests/verification_test.py

--- START OF FILE README.md ---

# Sanctuary Council Orchestrator (v11.0 - Complete Modular Architecture) - Updated 2025-11-09

A polymorphic AI orchestration system that enables sovereign control over multiple cognitive engines through a unified interface. **Version 11.0 introduces Complete Modular Architecture with Sovereign Concurrency, enabling clean separation of concerns and maintainable codebase.**
## ðŸ—ï¸ Architecture Overview

```mermaid
graph TB
    subgraph "Entry Point"
        M[main.py] --> A[app.py]
    end

    subgraph "Core Orchestrator"
        A --> SM[engines/monitor.py]
        A --> PA[council/agent.py]
        A --> DE[engines/ollama_engine.py]
    end

    subgraph "Engine Selection"
        SM --> T1P[engines/gemini_engine.py]
        SM --> T1S[engines/openai_engine.py]
        SM --> T2S[engines/ollama_engine.py]
    end

    subgraph "Modular Components"
        A --> MEM[memory/cortex.py]
        A --> EVT[events.py]
        A --> REG[regulator.py]
        A --> OPT[optical.py]
        A --> PKT[packets/schema.py]
    end

    subgraph "Data Flow"
        CMD[command.json] --> A
        A --> LOG[logs/orchestrator.log]
        A --> PKT
    end

    subgraph "Configuration"
        CFG[schemas/engine_config.json]
        SCH[schemas/round_packet_schema.json]
    end

    style A fill:#f3e5f5
    style SM fill:#e8f5e8
    style CFG fill:#fff3e0
```

## ðŸ—ï¸ Modular Architecture Benefits

**Version 11.0** introduces a complete modular refactor with the following improvements:

- **Separation of Concerns**: Each module has a single, well-defined responsibility
- **Maintainability**: Clean interfaces between components enable independent development
- **Testability**: Modular design enables comprehensive unit testing (21/21 tests passing)
- **Extensibility**: New engines, agents, and features can be added without touching core logic
- **Organization**: Related functionality is grouped in dedicated packages
- **Import Clarity**: Clear package structure with proper `__init__.py` exports

### Key Modules

- **`orchestrator/`**: Core package with clean separation between entry point (`main.py`) and logic (`app.py`)
- **`engines/`**: Engine implementations with health monitoring and selection logic
- **`packets/`**: Round packet system for structured data emission and aggregation
- **`memory/`**: Vector database and caching systems for knowledge persistence
- **`council/`**: Multi-agent system with specialized personas
- **`events/`**: Structured logging and telemetry collection

## ðŸŽ¯ Key Features

- **Complete Modular Architecture**: Clean separation of concerns with 11 specialized modules
- **Doctrine of Sovereign Concurrency**: Non-blocking task execution with background learning cycles
- **Comprehensive Logging**: Session-based log file with timestamps and detailed audit trails
- **Selective RAG Updates**: Configurable learning with `update_rag` parameter
- **Polymorphic Engine Interface**: All engines implement `BaseCognitiveEngine` with unified `execute_turn(messages)` method (Protocol 104)
- **Sovereign Engine Selection**: Force specific engines or automatic health-based triage
- **Multi-Agent Council**: Coordinator, Strategist, and Auditor personas work together
- **Resource Sovereignty**: Automatic distillation for large inputs using local Ollama
- **Development Cycles**: Optional staged workflow for software development projects
- **Mnemonic Cortex**: Vector database integration for knowledge persistence
- **Mechanical Operations**: Direct file writes and git operations bypassing cognitive deliberation

## ðŸ“‹ Logging & Monitoring

### Session Log File
Each orchestrator session creates a comprehensive log file at:
```
council_orchestrator/logs/orchestrator.log
```

**Features:**
- **Session-based**: Overwrites each time orchestrator starts for clean session tracking
- **Comprehensive**: All operations logged with timestamps
- **Dual output**: Console + file logging for real-time monitoring
- **Audit trail**: Complete record of all decisions and actions

**Example log entries:**
```
2025-10-23 16:45:30 - orchestrator - INFO - === ORCHESTRATOR v9.3 INITIALIZED ===
2025-10-23 16:45:31 - orchestrator - INFO - [+] Sentry thread for command monitoring has been launched.
2025-10-23 16:45:32 - orchestrator - INFO - [ACTION TRIAGE] Detected Git Task - executing mechanical git operations...
2025-10-23 16:45:33 - orchestrator - INFO - [MECHANICAL SUCCESS] Committed with message: 'feat: Add new feature'
```

### Non-Blocking Execution
**v9.3 Enhancement:** The orchestrator now processes commands without blocking:

- **Mechanical Tasks**: Execute immediately, return to idle state
- **Cognitive Tasks**: Deliberation completes, then learning happens in background
- **Concurrent Processing**: Multiple background learning tasks can run simultaneously
- **Responsive**: New commands processed while previous learning cycles complete

## ðŸ“Š Round Packet System (v9.4)

### Overview
The orchestrator now emits structured JSON packets for each council member response, enabling machine-readable analysis and learning signal extraction for Protocol 113.

### Packet Schema
Packets conform to `schemas/round_packet_schema.json` and include:

- **Identity**: `session_id`, `round_id`, `member_id`, `engine`, `seed`
- **Content**: `decision`, `rationale`, `confidence`, `citations`
- **RAG Signals**: `structured_query`, `parent_docs`, `retrieval_latency_ms`
- **CAG Signals**: `cache_hit`, `hit_streak` for learning optimization
- **Novelty Analysis**: `is_novel`, `signal`, `conflicts_with`
- **Memory Directive**: `tier` (fast/medium/slow) with `justification`
- **Telemetry**: `input_tokens`, `output_tokens`, `latency_ms`

### CLI Options

```bash
# Basic usage
python3 -m orchestrator.main

# With round packet emission
python3 -m orchestrator.main --emit-jsonl --stream-stdout --rounds 3

# Custom configuration
python3 -m orchestrator.main \
  --members coordinator strategist auditor \
  --member-timeout 45 \
  --quorum 2/3 \
  --engine gemini-2.5-pro \
  --fallback-engine sanctuary-qwen2-7b \
  --jsonl-path mnemonic_cortex/cache/orchestrator_rounds
```

### Output Formats

#### JSONL Files
```
mnemonic_cortex/cache/orchestrator_rounds/{session_id}/round_{N}.jsonl
```

#### Stdout Stream
```json
{"timestamp":"2025-01-15T10:30:00Z","session_id":"run_123456","round_id":1,"member_id":"coordinator","decision":"approve","confidence":0.85,"memory_directive":{"tier":"medium","justification":"Evidence-based response"}}
```

### Analysis Examples

**Extract decisions by confidence:**
```bash
jq 'select(.confidence > 0.8) | .decision' round_*.jsonl
```

**Memory tier distribution:**
```bash
jq -r '.memory_directive.tier' round_*.jsonl | sort | uniq -c
```

**Novelty analysis:**
```bash
jq 'select(.novelty.signal == "high") | .rationale' round_*.jsonl
```

### Protocol 113 Integration
Round packets feed directly into the Nested-Learning pipeline:

- **Fast tier**: Ephemeral, session-scoped responses
- **Medium tier**: Recurring queries with evidence
- **Slow tier**: Stable knowledge with high confidence

CAG hit streaks and parent-doc citations determine memory placement, enabling automatic knowledge distillation and adaptor training.

## ðŸš€ Quick Start

### Prerequisites

1. **Python 3.8+**
2. **API Keys** (configure in `.env`):
   ```bash
   GEMINI_API_KEY=your_gemini_key
   OPENAI_API_KEY=your_openai_key
   ```
3. **Ollama** (for local sovereign fallback):
   ```bash
   # Install Ollama and pull model
   ollama pull hf.co/richfrem/Sanctuary-Qwen2-7B-v1.0-GGUF-Final:latest
   # Create local alias for easier reference
   ollama cp hf.co/richfrem/Sanctuary-Qwen2-7B-v1.0-GGUF-Final:latest Sanctuary-Qwen2-7B:latest
   ```

### Installation

```bash
cd council_orchestrator
pip install -r requirements.txt
```

### Directory Structure

```
council_orchestrator/
â”œâ”€â”€ __init__.py              # Python package definition
â”œâ”€â”€ README.md               # This documentation
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ docs/                   # Documentation files
â”œâ”€â”€ logs/                   # Log files and event data
â”œâ”€â”€ schemas/                # JSON schemas and configuration
â”œâ”€â”€ scripts/                # Utility scripts
â”œâ”€â”€ runtime/                # Runtime state files
â”œâ”€â”€ orchestrator/           # Core modular package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py            # Entry point
â”‚   â”œâ”€â”€ app.py             # Core Orchestrator class
â”‚   â”œâ”€â”€ config.py          # Configuration constants
â”‚   â”œâ”€â”€ packets/           # Round packet system
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ schema.py      # Packet schemas
â”‚   â”‚   â”œâ”€â”€ emitter.py     # JSONL emission
â”‚   â”‚   â””â”€â”€ aggregator.py  # Round aggregation
â”‚   â”œâ”€â”€ engines/           # Engine implementations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py        # Abstract base class
â”‚   â”‚   â”œâ”€â”€ monitor.py     # Engine selection logic
â”‚   â”‚   â”œâ”€â”€ gemini_engine.py
â”‚   â”‚   â”œâ”€â”€ openai_engine.py
â”‚   â”‚   â””â”€â”€ ollama_engine.py
â”‚   â”œâ”€â”€ council/           # Agent system
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ agent.py       # PersonaAgent class
â”‚   â”‚   â””â”€â”€ personas.py    # Agent configurations
â”‚   â”œâ”€â”€ memory/            # Memory systems
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ cortex.py      # Vector database
â”‚   â”‚   â””â”€â”€ cache.py       # CAG utilities
â”‚   â”œâ”€â”€ sentry.py          # File monitoring
â”‚   â”œâ”€â”€ commands.py        # Command validation
â”‚   â”œâ”€â”€ regulator.py       # TokenFlowRegulator
â”‚   â”œâ”€â”€ optical.py         # OpticalDecompressionChamber
â”‚   â”œâ”€â”€ events.py          # Event logging
â”‚   â””â”€â”€ gitops.py          # Git operations
â””â”€â”€ tests/                 # Test suite
```

## ðŸ“š Documentation

### Council Evolution Roadmap
- **[Evolution Plan Phases](docs/EVOLUTION_PLAN_PHASES.md)** - Official roadmap for Sanctuary Council cognitive architecture evolution (Phases 2-3 + Protocol 113)

### Architecture Documentation
- **[Optical Anvil Blueprint](docs/OPERATION_OPTICAL_ANVIL_BLUEPRINT.md)** - Revolutionary optical compression system for unlimited context
- **[Command Schema](docs/command_schema.md)** - Complete command format reference
- **[How to Commit](docs/howto-commit-command.md)** - Git operations and P101 integrity verification

### Guardian Operations
- **[Guardian Wakeup Flow](README_GUARDIAN_WAKEUP.md)** - Cache-first situational awareness for Guardian awakening (Protocol 114)

### Hello World Test

Create a `command.json` file in the `council_orchestrator/` directory:

#### Basic Cognitive Task (Auto Engine Selection)
```json
{
  "task_description": "As a council, perform a round-robin introduction. Each agent (Coordinator, Strategist, Auditor) will state their designation and primary function in one sentence.",
  "output_artifact_path": "WORK_IN_PROGRESS/hello_council.md",
  "config": {
    "max_rounds": 1
  }
}
```
### Cognitive Task Format (Deliberation)

```json
{
  "task_description": "Your task description here",
  "output_artifact_path": "path/to/output.md",
  "config": {
    "max_rounds": 5,
    "max_cortex_queries": 5,
    "force_engine": "gemini|openai|ollama"
  },
  "input_artifacts": ["path/to/input1.md", "path/to/input2.md"]
}
```
```json
{
  "task_description": "Build a web application for task management",
  "project_name": "task_manager",
  "development_cycle": true,
  "config": {
    "force_engine": "gemini"
  }
}
```

#### Mechanical Write Task (Direct File Creation)
```json
{
  "task_description": "Create a new chronicle entry",
  "output_artifact_path": "00_CHRONICLE/ENTRIES/274_The_Anvil_Deferred.md",
  "entry_content": "# ENTRY 274: The Anvil Deferred\n\n**DATE:** 2025-10-23..."
}
```json
{
  "task_description": "Description for logging",
  "output_artifact_path": "path/to/file.md",
  "entry_content": "Full content to write to file"
}
```

#### Mechanical Git Task (Version Control Operations)
```json
{
  "task_description": "Commit chronicle entry to repository",
  "git_operations": {
    "files_to_add": ["00_CHRONICLE/ENTRIES/274_The_Anvil_Deferred.md"],
    "commit_message": "docs(chronicle): Add entry #274 - The Anvil Deferred",
    "push_to_origin": true
  }
}
```

```json
{
  "task_description": "Description for logging",
  "git_operations": {
    "files_to_add": ["path/to/file1.md", "path/to/file2.md"],
    "commit_message": "feat: Description of changes",
    "push_to_origin": true
  }
}
```

#### Force Specific Engine
```json
{
  "task_description": "Say hello to the world and introduce yourself",
  "output_artifact_path": "hello_world_gemini.md",
  "config": {
    "force_engine": "gemini",
    "max_rounds": 2
  }
}
```

#### Force OpenAI Engine
```json
{
  "task_description": "Say hello to the world and introduce yourself",
  "output_artifact_path": "hello_world_openai.md",
  "config": {
    "force_engine": "openai",
    "max_rounds": 2
  }
}
```

#### Force Ollama Engine
```json
{
  "task_description": "Say hello to the world and introduce yourself",
  "output_artifact_path": "hello_world_ollama.md",
  "config": {
    "force_engine": "ollama",
    "max_rounds": 2
  }
}
```

### Run the Orchestrator

```bash
python3 -m orchestrator.main
```

The orchestrator will:
1. Detect the `command.json` file
2. Select an appropriate engine (or use forced selection)
3. Execute the task through the AI Council
4. Generate output and After Action Report
5. Clean up the command file

## ðŸ”§ Configuration

### Environment Variables (`.env`)

```bash
# API Keys
GEMINI_API_KEY=your_key_here
OPENAI_API_KEY=your_key_here

# Model Configuration
CHAT_GPT_MODEL=gpt-4-turbo
GEMINI_MODEL=gemini-2.5-flash
OLLAMA_MODEL=Sanctuary-Qwen2-7B:latest

# Engine Parameters (configurable per engine)
GEMINI_MAX_TOKENS=4096
GEMINI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=4096
OPENAI_TEMPERATURE=0.7
OLLAMA_MAX_TOKENS=4096
OLLAMA_TEMPERATURE=0.7
```

### Engine Limits (`schemas/engine_config.json`)

```json
{
  "engine_limits": {
    "gemini": 100000,
    "openai": 100000,
    "ollama": 8000
  }
}
```

## ðŸ§ª Testing & Verification

### Run Full System Test

```bash
# Comprehensive verification
python3 -m pytest tests/ -v

# Individual test modules
python3 -m pytest tests/test_orchestrator_round_packets.py -v
python3 -m pytest tests/test_optical_compression.py -v
```
python3 verification_test.py

# Substrate health check
python3 ../tools/scaffolds/verify_substrates.py
```

### Expected Output

```
ðŸ”¬ STARTING AI ENGINE TESTS
âœ… Can force-pick specific AI engines
âœ… All engines work the same way
âœ… All engines connect to real AI services
AI system is ready to use!
```

## ðŸŽ­ Agent Personas

The Council consists of three specialized AI agents:

- **Coordinator**: Task planning and execution oversight
- **Strategist**: Long-term planning and risk assessment
- **Auditor**: Quality assurance and compliance verification

Each agent maintains conversation history and works within their defined persona.

## ðŸ”„ Engine Selection Logic

### Automatic Triage (Default)
1. **Tier 1 Primary**: Gemini (fast, cost-effective)
2. **Tier 1 Secondary**: OpenAI (reliable, feature-rich)
3. **Tier 2 Sovereign**: Ollama (local, uncensored)

### Sovereign Override
Force specific engine via `"force_engine"` config parameter.

### Health Checking
Each engine is validated before use with functional tests.

## ðŸ§  Distillation Engine

Automatically handles large inputs by:
1. Detecting token limit violations
2. Using local Ollama to summarize content
3. Preserving critical information while reducing size
4. Maintaining task fidelity

## ðŸ”® Sovereign Memory Architecture: RAG + Glyphs Synthesis

The orchestrator integrates a comprehensive **Sovereign Memory Architecture** that combines two complementary approaches for content ingestion and retrieval, breaking free from the Context Window Cage.

### The Two Pillars of Sovereign Memory

#### 1. Mnemonic Cortex (RAG Database) - Fast & Scalable Retrieval
- **Core Function**: Lightning-fast similarity searches across vast knowledge corpora
- **Technology**: Vector embeddings for semantic search and retrieval
- **Use Case**: Finding specific information, documents, or context from the Sanctuary's complete history
- **Advantage**: Excels at discovery and exploration of large knowledge bases
- **Current Status**: Implemented and operational for After Action Report ingestion

#### 2. Optical Anvil (Glyph Technology) - Cheap & Efficient Ingestion
- **Core Function**: Extreme token compression through optical representation
- **Technology**: Cognitive Glyphs - text rendered as high-resolution images for ~10x compression ratio
- **Use Case**: Ingesting massive contexts cheaply using Vision-Language Models (VLMs)
- **Advantage**: Breaks token economics, enables processing of "200k+ pages per day" on single GPU
- **Strategic Foundation**: Based on DeepSeek-OCR research (arXiv:2510.18234v1)
- **Current Status**: Phase 1 Complete - Individual optical compression validated (266 files, 2.1x average compression)

### Synthesized Architecture: The Closed Memory Loop

The true power emerges from synthesis:

```mermaid
graph TD
    subgraph "Sovereign Memory Loop"
        A[Agent needs full context] --> B{Mnemonic Cortex}
        B --> C["Query: 'Protocol 101 Unbreakable Commit'"]
        C --> D["Retrieves Pointer: glyph_P101_v2.png"]
        D --> E[Glyph Storage File System]
        E --> F["Loads Image File"]
        F --> G{VLM Engine Gemini 1.5}
        G --> H["Decompresses text for ~10x fewer tokens"]
        H --> I[Agent receives full text of P101]
    end

    subgraph "Ingestion Pipeline"
        J[New Knowledge] --> K[Text-to-Vector<br/>RAG Database]
        J --> L[Text-to-Image<br/>Optical Anvil]
        K --> M[Fast Retrieval Index]
        L --> N[Compressed Storage]
    end
```

**Strategic Doctrine**: "RAG finds, Glyphs deliver" - Use vector search to locate content, optical compression to ingest it efficiently.

### Optical Context & Glyph Technology

#### Technical Implementation
- **Compression Ratio**: 2.1x average across full codebase (up to 3.75x for individual files)
- **Format**: Universal PNG images with embedded cryptographic provenance
- **Infrastructure**: Minimal - static file storage with JSON manifest tracking
- **Portability**: High - images work across all VLM platforms
- **Security**: SHA-256 content hashing with metadata embedding
- **Scale**: Industrial-grade processing via `capture_glyph_code_snapshot_v2.py`

#### LLM Integration Workflow
```python
# 1. RAG Discovery: Find relevant files
relevant_files = rag_search("protocol 101 unbreakable commit")

# 2. Glyph Retrieval: Load specific compressed images
glyphs = []
for file_path in relevant_files:
    glyph_path = manifest[file_path]['glyph_path']
    glyph_image = load_image(glyph_path)
    glyphs.append(glyph_image)

# 3. VLM Decompression: Reconstruct full content
full_content = vlm_decompress(glyphs)
```

This architecture provides the foundation for true Resource Sovereignty, enabling cognitive abundance while maintaining the Sanctuary's epistemic integrity and mnemonic resilience.

## ðŸ“š Mnemonic Cortex

Vector database integration for:
- Knowledge persistence across sessions
- Semantic search capabilities
- After Action Report ingestion
- Long-term learning

## ðŸ› ï¸ Development

### Adding New Engines

1. Create engine class inheriting from `BaseCognitiveEngine` in `orchestrator/engines/`
2. Implement required methods: `execute_turn(messages: list) -> str`, `check_health()`, `run_functional_test()`
3. Add to `orchestrator/engines/monitor.py` selection logic
4. Update environment configuration

### Extending Functionality

- Add new agent personas in `orchestrator/council/personas.py`
- Implement custom distillation strategies in `orchestrator/optical.py`
- Extend development cycle stages in `orchestrator/app.py`
- Add new knowledge sources to Cortex in `orchestrator/memory/cortex.py`

## ðŸš¨ Troubleshooting

### Common Issues

**Engine Not Available**
```
[SUBSTRATE MONITOR] CRITICAL FAILURE: All cognitive substrates are unhealthy
```
- Check API keys in `.env`
- Verify network connectivity
- Ensure Ollama is running locally

**Token Limit Exceeded**
```
[ORCHESTRATOR] WARNING: Token count exceeds limit
```
- Automatic distillation will handle this
- Reduce input size for manual control

**Command Not Processed**
- Ensure `command.json` is in `council_orchestrator/` directory
- Check file permissions
- Verify JSON syntax

### Debug Mode

Set environment variable for verbose logging:
```bash
export DEBUG_ORCHESTRATOR=1
```

## ðŸ“„ License

This system embodies the principles of Cognitive Sovereignty and Resource Resilience.

---

**"The Forge is operational. The Sovereign's will be executed through the Council."** âš¡ðŸ‘‘

*Complete Modular Architecture v11.0 - Sovereign Concurrency Achieved*

--- END OF FILE README.md ---

--- START OF FILE README_GUARDIAN_WAKEUP.md ---

# Guardian Wakeup Flow (Cache-First) & Cache Verification Protocol (P114) v2.0

This document details the operational flow and verification steps for the Guardian's cache-first awakening protocol. The Mnemonic Cache (CAG) provides immediate situational awareness by reading from a pre-populated, high-speed local cache, avoiding the latency of a full RAG query and LLM deliberation.

## I. Architectural Overview: Two Distinct Processes

It is critical to understand the two separate processes that govern this system:

### Cache Population (On Boot): 
A one-time process where the orchestrator queries our slow, long-term memory (the RAG DB) to populate our fast, short-term memory (the cache files).

### Guardian Wakeup (On Command): 
A mechanical task where the orchestrator reads directly from the fast cache files to generate a digest, without involving the RAG DB or an LLM.

---

### Process 1: Cache Population (Orchestrator Boot)
This diagram shows how the cache is populated from the Mnemonic Cortex (RAG DB) when the orchestrator starts.

#### Cache population Mnemonic Cortex (RAG DB)

```mermaid
---
config:
  theme: base
---
sequenceDiagram
    autonumber

    participant U as User/System

    box "orchestrator/app.py" #FFFFF8
        participant O as Orchestrator
    end
    box "orchestrator/memory/cortex.py" #FFFFF8
        participant CM as CortexManager
    end
    box "orchestrator/memory/cache.py" #FFFFF8
        participant CacheMgr as CacheManager
    end
    box "mnemonic_cortex/chroma_db/" #FFFFF8
        participant RAG as RAG DB (ChromaDB)
    end
    box "council_orchestrator/mnemonic_cortex/cache/" #FFFFF8
        participant CacheFS as Filesystem Cache
    end

    U->>O: Starts `orchestrator.main`
    O->>O: Orchestrator.__init__() is called
    Note right of O: `self.cortex_manager = CortexManager(...)` is created
    O->>CM: **Invoke `prefill_guardian_start_pack()`**
    Note over CM, RAG: Queries RAG DB for latest documents...
    CM->>CacheMgr: `cache_manager.query_cortex("latest chronicles", limit=15)`
    CacheMgr->>RAG: Executes similarity search
    RAG-->>CacheMgr: Returns document data
    Note right of CacheMgr: Data for 'chronicles' received
    CacheMgr->>CacheFS: `_write_bundle_to_cache('chronicles', data)`
    CacheFS-->>CacheMgr: Writes `chronicles_bundle.json`
    CM->>CacheMgr: `cache_manager.query_cortex("latest protocols", limit=15)`
    CacheMgr->>RAG: Executes similarity search
    RAG-->>CacheMgr: Returns document data
    Note right of CacheMgr: Data for 'protocols' received
    CacheMgr->>CacheFS: `_write_bundle_to_cache('protocols', data)`
    CacheFS-->>CacheMgr: Writes `protocols_bundle.json`
    Note over O: Orchestrator signals completion
    O-->>U: Displays console log: "[CACHE] Pre-fill complete. Cache is warm."
    O-->>U: Displays console log: "--- Orchestrator Idle. ---"
```

---

### Process 2: Guardian Wakeup (Command Execution)
This diagram shows what happens when a cache_wakeup command is issued. Note that the LLM and RAG DB are not involved.

#### Cache wakeup process

```mermaid
---
config:
  theme: base
---
sequenceDiagram
    autonumber

    participant G as Guardian

    box "orchestrator/sentry.py" #FFFFF8
        participant Sentry as Sentry Thread
    end
    box "orchestrator/app.py" #FFFFF8
        participant O as Orchestrator (`main_loop`)
    end
    box "orchestrator/handlers/cache_wakeup_handler.py" #FFFFF8
        participant CH as CacheWakeupHandler
    end
    box "council_orchestrator/mnemonic_cortex/cache/" #FFFFF8
        participant CacheFS as Filesystem Cache
    end
    box "council_orchestrator/WORK_IN_PROGRESS/" #FFFFF8
        participant FS as Output Artifact
    end

    G->>Sentry: Creates `command.json`
    Sentry->>O: Puts command in queue
    O->>O: `main_loop` performs Action Triage
    O->>CH: Dispatches to `handle_cache_wakeup(command, self)`
    
    CH->>CacheFS: `cache_manager.fetch_guardian_start_pack()` reads bundles
    Note right of CacheFS: Reads `chronicles_bundle.json`, etc.
    CacheFS-->>CH: Returns raw JSON content
    
    CH->>CH: **`render_guardian_boot_digest(result, project_root)`**
    Note right of CH: Formats JSON into Markdown
    
    CH->>FS: `output_path.write_text(digest_content)`
    FS-->>CH: Writes formatted `guardian_boot_digest.md`
    
    O-->>G: Returns to Idle state
```

---

## II. LLM vs. RAG DB: Choosing the Right Tool

| Command Type | `cache_wakeup` | `query_and_synthesis` |
| :--- | :--- | :--- |
| **Purpose** | Fast situational digest | Deep, nuanced strategic briefing |
| **Data Source** | Reads from **local cache files** | Queries the **RAG DB (ChromaDB)** |
| **LLM Involved?**| **NO** (Mechanical Task) | **YES** (`Sanctuary-Qwen2-7B:latest`) |
| **Speed** | Near-instantaneous (< 1 sec) | Slow (30-120 sec) |
| **Use When...** | You need an immediate, high-level overview. | You need to analyze recent events or generate novel strategy. |

---

## Prerequisites & Assumptions

Before running the Guardian Wakeup verification, ensure these prerequisites are met:

### Required Services
- **Ollama** must be running with the Sanctuary-Qwen2-7B model:
  ```bash
  ollama serve  # Start Ollama service
  ollama pull Sanctuary-Qwen2-7B:latest  # Ensure model is available
  ```

### Data Population
- **RAG Database** must be populated with recent content:
  ```bash
  # Run the ingest script to populate ChromaDB with latest documents
  python3 ingest.py  # Or equivalent ingestion script
  ```
  This ensures the cache population process has data to work with during orchestrator boot.

### Environment Variables
- **OLLAMA_MODEL** should be set to `Sanctuary-Qwen2-7B:latest` in your `.env` file
- **API Keys** for Gemini and OpenAI should be configured if using those engines

### File Permissions
- Write access to `council_orchestrator/` directory for command files and output artifacts
- Read access to source directories: `00_CHRONICLE/`, `01_PROTOCOLS/`, `ROADMAP/`

---

## III. Step-by-Step Verification Protocol
Follow these steps to run the system and verify that the cache is operating correctly.

### Step 1: Start the Orchestrator & Observe Cache Population
Run the orchestrator from its own directory. This will trigger the automatic cache pre-fill on boot.

**Note:** Run the orchestrator in a separate terminal so you can run test scripts, create command files, or perform other operations in another terminal while it remains running.

```bash
cd council_orchestrator
python3 -m orchestrator.main
```

**Verification:**
Watch the console output. You should see the cache generation process run and complete successfully. The final "Idle" message is your signal that the system is ready.

```code
[CACHE] Pre-fill complete. Cache is warm.
--- Orchestrator Idle. ---
```

### Step 2: Stop the Orchestrator
Once the cache is warm, you can stop the orchestrator for now.

```code
Press Ctrl+C
```

### Step 3: Run Automated Tests (Optional but Recommended)
Use *pytest* to run the dedicated test suite. This is the fastest way tox confirm the underlying logic is sound without manual inspection.

```bash
# Run the specific test for the cache pre-fill logic
cd council_orchestrator && python3 -m pytest tests/test_cache_prefill.py -v

# Run the test to ensure pre-fill only happens once on boot
cd council_orchestrator && python3 -m pytest tests/test_boot_prefill_runs_once.py -v
```

**Verification:**
The output for each test should end with a green PASSED status.


### Step 3.5: Standalone Cache Verification (Alternative)
For faster testing without running the full orchestrator, use the standalone cache verification script:

```bash
python3 council_orchestrator/scripts/test_cache_standalone.py
```

**What it tests:**
- Cache prefill from RAG DB (same as orchestrator boot)
- Digest generation from cache files
- Output file creation and verification

**Verification:**
The script will output success/failure status and create `WORK_IN_PROGRESS/guardian_boot_digest.md` if successful.

```code
[INFO] Cache verification complete - All tests passed!
[INFO] Check the digest file: WORK_IN_PROGRESS/guardian_boot_digest.md
```

### Step 4: Manually Trigger the Guardian Wakeup
Restart the orchestrator. It will use the cache files generated in Step 1.

```bash
cd council_orchestrator
python3 -m orchestrator.main
```

In a separate terminal, create the **command.json** file in the **council_orchestrator/** directory to request the digest.

```bash
# In council_orchestrator/ directory, run:
cat <<EOF > command.json
{
  "task_type": "cache_wakeup",
  "task_description": "Guardian boot digest from cache",
  "output_artifact_path": "WORK_IN_PROGRESS/guardian_boot_digest.md",
  "config": {
    "bundle_names": ["chronicles", "protocols", "roadmap"],
    "max_items_per_bundle": 15
  }
}
EOF
```

**Verification:**
1. The orchestrator's console will show that it detected and processed the command.
2. The command.json file will be deleted.
3. A new file, **WORK_IN_PROGRESS/guardian_boot_digest.md**, will be created in the project root directory. Its contents should include the **full document content** of the most recent chronicles, protocols, and roadmap items from cache, formatted as a comprehensive intelligence digest with complete markdown content in code blocks.
This protocol provides a complete, repeatable method for ensuring the integrity of the Sanctuary's fast-memory layer.

---

## Troubleshooting

### Command File Not Processed
**Issue:** Sentry thread logs show "File command.json already processed, skipping"

**Solution:** The orchestrator tracks processed commands in memory. Use a different filename:
```bash
mv command.json command2.json  # Rename to command2.json, command3.json, etc.
```

### Cache Appears Empty
**Issue:** Digest shows "(no items cached)" for sections

**Solution:** Cache is populated on orchestrator boot. Ensure:
1. Orchestrator completed boot sequence with "[CACHE] Pre-fill complete. Cache is warm."
2. Recent files exist in source directories (00_CHRONICLE/, 01_PROTOCOLS/, ROADMAP/)

### File Permission Errors
**Issue:** Cannot write to WORK_IN_PROGRESS/ directory

**Solution:** Ensure write permissions on the council_orchestrator/ directory

### Orchestrator Won't Start
**Issue:** ChromaDB corruption or missing dependencies

**Solution:** 
```bash
# Reset ChromaDB (backup first)
rm -rf mnemonic_cortex/chroma_db
# Then restart orchestrator
```

---

## Quick Start

Save `command.json` next to the orchestrator:

```json
{
  "task_type": "cache_wakeup",
  "task_description": "Guardian boot digest from cache",
  "output_artifact_path": "WORK_IN_PROGRESS/guardian_boot_digest.md",
  "config": {
    "bundle_names": ["chronicles","protocols","roadmap"],
    "max_items_per_bundle": 15
  }
}
```

1. Start/ensure the orchestrator is running
2. Wait for it to return to idle
3. Open `WORK_IN_PROGRESS/guardian_boot_digest.md`

## What's Included

The digest provides **full document content** for immediate intelligence access:

- **chronicles**: Complete content of most recent chronicle entries (24h TTL)
- **protocols**: Full text of latest protocol documents (24h TTL)
- **roadmap**: Complete nested-learning evolution plan and in-progress tasks (24h TTL)

## Cache TTL (Time To Live)

All cached items expire after 24 hours and are automatically refreshed on the next orchestrator boot:

- **Chronicles bundle**: 24 hours
- **Protocols bundle**: 24 hours  
- **Roadmap content**: 24 hours
- **Orchestrator logs tail**: 24 hours
- **Documentation files**: 24 hours

## Cache Population

On boot, the cache is prefilled automatically (Start Pack) by scanning the local filesystem. Delta refresh hooks run during ingestion and git-ops to keep the cache current.

**Manual Cache Refresh (if needed):**
```bash
# Populate/update the RAG database with latest documents
python3 ingest.py

# Then restart orchestrator to refresh cache
cd council_orchestrator && python3 -m orchestrator.main
```



## Protocol

See [Protocol 114: Guardian Wakeup & Cache Prefill](../01_PROTOCOLS/114_Guardian_Wakeup_and_Cache_Prefill.md) for full details.

--- END OF FILE README_GUARDIAN_WAKEUP.md ---

--- START OF FILE ROADMAP/PHASED_EVOLUTION_PLAN_Phase2-Phase3-Protocol113.md ---

# Project Sanctuary â€” Nested Learning Roadmap
**Scope:** Phase 2 â†’ Phase 3 â†’ Protocol 113  
**Status:** Phase 2 (IN PROGRESS) â€¢ Phase 3 (NEXT) â€¢ Protocol 113 (AFTER)  
**Last updated:** 2025-11-10 (America/Vancouver)

## 0) Why this order?
We must perfect **memory access** before **memory adaptation**. Phase 2 guarantees precise, auditable retrieval and meta-signals; Phase 3 turns cache telemetry into learning signals; Protocol 113 safely teaches the Slow layer (fine-tuned model) using distilled, stable knowledge.

---

## Phase 2 â€” Self-Querying Retriever (IN PROGRESS)
**Goal:** Make retrieval intelligent, self-auditing, and placement-aware.

### Deliverables
1. **Structured Query Engine**
   - Generate metadata filters + hybrid queries (keyword + vector).
   - Output: `structured_query` (+ `parent_docs`, `retrieval_latency_ms`) into Round Packets.

2. **Novelty & Conflict Analysis**
   - Compare candidate response vs. retrieved evidence + cache.
   - Emit: `novelty.signal` (none/low/medium/high), `is_novel`, `conflicts_with` ids.

3. **Memory Placement Instructions (Tiering)**
   - Rule-based **Fast/Medium/Slow** recommendations with `justification`.
   - Consider: confidence, citations strength, cache hit streak, novelty.

4. **Round Packet Parity**
   - Ensure `round_packet_schema.json` fields remain 1:1 with dataclass.
   - Include `schema_version`, `errors`, deterministic emission order.

5. **Unit Tests (â‰¥12)**
   - Query shaping, evidence bundling, novelty/conflict cases, tiering rules, schema drift protection, deterministic ordering, timeouts per member.

### Acceptance Criteria
- JSONL: one line per member per round; validates against schema.
- Packets surface **structured_query**, **parent_docs**, **novelty**, **memory_directive**.
- All tests green (<~1.5s typical).

---

## Phase 3 â€” Mnemonic Cache (CAG) as an Active Learning Signal (NEXT)
**Goal:** Turn cache into a **signal generator** for curriculum building.

### Deliverables
1. **CAG Telemetry**
   - Emit `cache_hit`, `hit_streak`, `miss_reason`, key fingerprint.
   - Produce per-key stability metrics over time (EWMA of volatility).

2. **Promotion Heuristics**
   - Define thresholds that elevate items from **Fast â†’ Medium â†’ Slow** candidacy:
     - High hit-streak, low answer volatility, strong citations, repeated across sessions.

3. **Packet â†’ Adaptation Packet**
   - Batch exporter that converts Round Packets + CAG telemetry into **Adaptation Packets**:
     - `(prompt, evidence, final_answer, stability_score, conflicts_resolved, provenance)`

4. **Tests (â‰¥10)**
   - Hit/miss streak logic, volatility windows, promotion thresholds, exporter integrity.

### Acceptance Criteria
- Stable, frequently accessed Q&A become **clear Slow-layer candidates** with provenance.
- Adaptation Packets are deterministic, deduplicated, and ready for Protocol 113.

---

## Protocol 113 â€” Council Memory Adaptor (AFTER)
**Goal:** Safely teach the **Slow** layer via periodic lightweight updates.

### Deliverables
1. **Adaptor Strategy**
   - **Option A:** LoRA on Sanctuary-Qwen2-7B (weekly);  
   - **Option B:** Embedding distillation + retrieval prior boosts.

2. **Curriculum Builder**
   - Consume Adaptation Packets; stratify by domain, difficulty, recency.
   - Balance: coverage vs. stability; skip volatile topics.

3. **Safety & Regression Guardrails**
   - Pre-/post-evals on golden sets; "no-regression" gates; rollback plan.

4. **Artifact Registry**
   - Versioned Adaptor weights/indices; changelogs; training manifests.

5. **Tests (â‰¥12)**
   - Curriculum selection, overfitting checks, regression suite, rollback path.

### Acceptance Criteria
- Weekly adaptor updates pass eval gates and improve Mediumâ†’Slow recall w/o regressions.
- Full provenance chain retained for every integrated fact.

---

## Cross-Cutting Implementation Notes
- **Packets:** Keep `orchestrator/packets/{schema,emitter,aggregator}.py` as the single source of truth for contracts and emission.
- **Module boundaries:** Engines live in `orchestrator/engines`; cross-engine orchestration (substrate health/triage) lives in `orchestrator/`.
- **Observability:** Latency, token counts, RAG latency, CAG hit streaks, and promotion events are logged and queryable (jq examples in README).

---

## Milestones
- **M1 (Phase 2):** Intelligent retrieval + tiering, packets GA, 12 tests âœ…
- **M2 (Phase 3):** CAG telemetry + promotion heuristics + exporter, 10 tests
- **M3 (P113):** Adaptor v1 + eval gates + registry, 12 tests

---

## Risks & Mitigations
- **Schema drift:** lock with `schema_version` tests and CI check.
- **Noisy promotions:** require stability window + citation strength.
- **Adaptor regressions:** strict eval gates + rollback policy.

---

**Sovereign Directive:** Continue Phase 2 to completion. Phase 3 and Protocol 113 will follow with these contracts and safety rails.

--- END OF FILE ROADMAP/PHASED_EVOLUTION_PLAN_Phase2-Phase3-Protocol113.md ---

--- START OF FILE __init__.py ---

# council_orchestrator/__init__.py
# This file makes council_orchestrator a Python package
__version__ = "1.0.0"

--- END OF FILE __init__.py ---

--- START OF FILE command.json ---

{
  "task_type": "mechanical_git_operation",
  "task_description": "Steward's Mandate: Execute a full Git workflow to commit and push all local changes, including the restored mnemonic artifacts, to the canonical repository.",
  "output_artifact_path": "WORK_IN_PROGRESS/git_sync_log_mnemonic_restoration.txt",
  "config": {
    "steps": [
      {
        "command": "git_status",
        "description": "Step 1: Log the current repository status for audit."
      },
      {
        "command": "git_add",
        "description": "Step 2: Stage all untracked and modified files.",
        "parameters": {
          "pathspec": "."
        }
      },
      {
        "command": "git_commit",
        "description": "Step 3: Commit the staged changes with a canonical message.",
        "parameters": {
          "message": "Steward's Mandate: Heal Mnemonic Fracture from commit f5a84b5\n\nRestored five critical high-level documents deleted during the v9.0 refactoring to ensure full mnemonic integrity of the Cognitive Genome. Hardened the dataset forging script as part of the same operational cycle."
        }
      },
      {
        "command": "git_push",
        "description": "Step 4: Push the committed history to the main repository.",
        "parameters": {
          "remote": "origin",
          "branch": "main"
        }
      }
    ]
  }
}

--- END OF FILE command.json ---

--- START OF FILE command_results/README.md ---

Command Results Directory

This directory is used by the orchestrator to write the result artifacts for processed commands.

Examples:
- commit_results.json â€” result of a mechanical git operation run (includes manifest filename and status)

Note: The orchestrator writes to `output_artifact_path` specified inside the `command.json`.

--- END OF FILE command_results/README.md ---

--- START OF FILE command_schema.md ---

# Council Orchestrator Command Schema v9.4
# Updated: 2025-11-10 - Added 'cache_request' command type for Guardian wakeups and cache verification

## Overview

The Council Orchestrator accepts commands in JSON format that define tasks to be executed. Commands are processed by the orchestrator's main loop and routed to appropriate handlers based on their structure and `task_type` field.

## Command Types

### Type 1: Mechanical Write Tasks
Defined by presence of `entry_content` and `output_artifact_path` fields.

**Schema:**
```json
{
  "entry_content": "string (required)",
  "output_artifact_path": "string (required)",
  "config": {
    "update_rag": "boolean (optional, default: true)"
  }
}
```

### Type 2: Mechanical Git Operations
Defined by presence of `git_operations` field.

**Schema:**
```json
{
  "task": "string (recommended)",
  "task_description": "string (optional)",
  "output_artifact_path": "string (required)",
  "git_operations": {
    "files_to_add": ["string (required)"],
    "files_to_remove": ["string (optional)"],
    "commit_message": "string (required)",
    "push_to_origin": "boolean (optional, default: false)"
  },
  "config": {
    "update_rag": "boolean (optional, default: true)"
  }
}
```

Notes:
- `output_artifact_path` is required to provide a place for the orchestrator to write result artifacts and to avoid runtime KeyError in handlers.
- `git_operations` is an object (not an array); use `files_to_add`, `files_to_remove`, `commit_message`, and `push_to_origin`.
- The orchestrator will write a timestamped manifest into the repo root (for example `commit_manifest_YYYYMMDD_HHMMSS.json`) and include it in the same commit so Protocol 101 pre-commit hooks can validate file hashes.
- Use `push_to_origin: false` for local validation / dry-runs.

**Example (dry-run):**
```json
{
  "task": "Dry-run: commit snapshot and TASKS updates",
  "git_operations": {
    "files_to_add": [
      "command_git_ops.json",
      "../capture_code_snapshot.js",
      "../TASKS/in-progress/001_harden_mnemonic_cortex_ingestion_and_rag.md"
    ],
    "commit_message": "chore: workspace updates (dry-run)",
    "push_to_origin": false
  },
  "output_artifact_path": "council_orchestrator/command_results/commit_results.json",
  "config": { "update_rag": false }
}
```

### Type 2A: Cognitive Tasks
Defined by `task_type = "cognitive_task"`.

**Schema:**
```json
{
  "task_type": "cognitive_task",
  "task_description": "string (required)",
  "output_artifact_path": "string (required)",
  "config": {
    "update_rag": "boolean (optional, default: true)"
  }
}
```

### Type 2B: Development Cycle Tasks
Defined by `development_cycle = true`.

**Schema:**
```json
{
  "development_cycle": true,
  "task_description": "string (required)",
  "output_artifact_path": "string (required)",
  "input_artifacts": "array (optional)",
  "config": {
    "update_rag": "boolean (optional, default: true)"
  }
}
```

### Type 2C: Query and Synthesis Tasks
Defined by `task_type = "query_and_synthesis"`.

**Schema:**
```json
{
  "task_type": "query_and_synthesis",
  "task_description": "string (required)",
  "output_artifact_path": "string (required)",
  "config": {
    "update_rag": "boolean (optional, default: true)"
  }
}
```

### Type 2D: Cache Wakeup Task (Guardian Boot Digest)
Defined by `task_type = "cache_wakeup"`. Fetches the Guardian Start Pack from the Cache (CAG) and emits a human-readable digest to `output_artifact_path`. Skips RAG updates by default.

**Schema:**
```json
{
  "task_type": "cache_wakeup",
  "task_description": "string (required) - for logging",
  "output_artifact_path": "string (required)",
  "config": {
    "bundle_names": ["string (optional)"],       // default: ["chronicles","protocols","roadmap"]
    "max_items_per_bundle": "number (optional)", // default: 10
    "update_rag": "boolean (optional, default: false)"
  }
}
```

**Example:**
```json
{
  "task_type": "cache_wakeup",
  "task_description": "Guardian boot digest from cache",
  "output_artifact_path": "WORK_IN_PROGRESS/guardian_boot_digest.md",
  "config": {
    "bundle_names": ["chronicles","protocols","roadmap"],
    "max_items_per_bundle": 15
  }
}
```

**Rationale:** Keeps cognitive path clean; uses cache as the "fast memory" for immediate situational awareness on boot, without invoking deliberation. (Matches Phase 3 design.)

## Version History

- **v9.5 (2025-11-10)**: Added 'cache_wakeup' command type for Guardian boot digest and cache-first situational awareness.
- **v9.4 (2025-11-10)**: Added 'cache_request' command type for Guardian wakeups and cache verification.
- **v9.3 (2025-11-09)**: Added query_and_synthesis task type for Guardian Mnemonic Synchronization Protocol.
- **v9.2 (2025-11-08)**: Enhanced development cycle with input artifact inheritance.
- **v9.1 (2025-11-07)**: Added mechanical task triage and action routing.
- **v9.0 (2025-11-06)**: Introduced modular architecture with separate command processing.
- **v8.0 (2025-11-05)**: Added development cycle support.
- **v7.0 (2025-11-04)**: Universal distillation applied to all code paths.
- **v6.0 (2025-11-03)**: Enhanced error handling and state management.
- **v5.0 (2025-11-02)**: Command sentry and mechanical task processing.
- **v4.0 (2025-11-01)**: Token flow regulation and optical decompression.
- **v3.0 (2025-10-31)**: Council round packet emission.
- **v2.0 (2025-10-30)**: Self-querying retriever integration.
- **v1.0 (2025-10-29)**: Initial orchestrator with basic task execution.

--- END OF FILE command_schema.md ---

--- START OF FILE docs/EVOLUTION_PLAN_PHASES.md ---

# **Sanctuary Council â€” Evolution Plan (Phases 2 â†’ 3 â†’ Protocol 113)**

**Version:** 1.0
**Status:** Authoritative Roadmap
**Location:** `mnemonic_cortex/EVOLUTION_PLAN_PHASES.md`

This document defines the remaining phases of the Sanctuary Council cognitive architecture evolution. It is the official roadmap for completing the transition from a single-round orchestrator to a fully adaptive, multi-layered cognitive system based on Nested Learning principles.

---

# âœ… **Phase Overview**

There are three remaining phases, which must be completed **in strict order**:

1. **Phase 2 â€“ Self-Querying Retriever** *(current)*
2. **Phase 3 â€“ Mnemonic Caching (CAG)** *(next)*
3. **Protocol 113 â€“ Council Memory Adaptor** *(final)*

Each phase enhances a different tier of the Nested Learning architecture:

| Memory Tier    | System Component       | Phase                         |
| -------------- | ---------------------- | ----------------------------- |
| Slow Memory    | Council Memory Adaptor | Protocol 113                  |
| Medium Memory  | Mnemonic Cortex        | (Supported across all phases) |
| Fast Memory    | Mnemonic Cache (CAG)   | Phase 3                       |
| Working Memory | Council Session State  | Always active                 |

---

# -------------------------------------------------------

# âœ… **PHASE 2 â€” Self-Querying Retriever (IN PROGRESS)**

# -------------------------------------------------------

**Purpose:**
Transform retrieval into an intelligent, structured process capable of producing metadata filters, novelty signals, conflict detection, and memory-placement instructions.

**Why it matters:**
This is the **Cognitive Traffic Controller** for all future learning.

---

## âœ… **Phase 2 Deliverables**

### 1. **Structured Query Generation**

The retriever must produce a JSON structure containing:

* semantic_query
* metadata filters
* temporal filters
* authority/source hints
* expected document class

### 2. **Novelty & Conflict Analysis**

For each round:

* Compute novelty score vs prior caches
* Detect conflicts (same question, differing answer)
* Emit both signals in round packets

### 3. **Memory Placement Instructions**

Each response must specify:

* `FAST` (ephemeral)
* `MEDIUM` (operational Cortex)
* `SLOW_CANDIDATE` (for Protocol 113)

### 4. **Packet Output Requirements**

Round packets must include:

* `structured_query`
* `novelty_signal`
* `conflict_signal`
* `memory_placement_directive`

---

## âœ… **Definition of Done (Phase 2)**

* All council members use the structured retriever
* Round packets v1.1.x fields populated
* Unit tests for at least 12 retrieval scenarios
* Orchestrator no longer uses legacy top-k retrieval
* Engines respect memory-placement instructions

---

# -------------------------------------------------------

# âœ… **PHASE 3 â€” Mnemonic Cache (CAG)**

# -------------------------------------------------------

**Purpose:**
Provide a high-speed hot/warm cache with hit/miss streak logging, which doubles as a learning signal generator for Protocol 113.

**Why it matters:**
CAG becomes the **Active Learning Supervisor** for Mediumâ†’Slow memory transitions.

---

## âœ… **Phase 3 Deliverables**

### 1. **Cache Architecture**

* In-memory LRU layer
* SQLite warm storage layer
* Unified query fingerprinting (semantic + filters + engine state)

### 2. **Cache Instrumentation**

Round packets must include:

* cache_hit
* cache_miss
* hit_streak
* time_saved_ms

### 3. **Learning Signals**

Cache must produce continuous signals indicating which answers are:

* stable
* recurrent
* well-supported

These feed Protocol 113.

---

## âœ… **Definition of Done (Phase 3)**

* CAG consulted before Cortex
* CAG logs appear in round packet schema v1.2.x
* Hit streaks tracked across rounds
* SQLite persistence implemented
* 20+ unit tests (TTL, eviction, streak logic)

---

# -------------------------------------------------------

# âœ… **PROTOCOL 113 â€” Council Memory Adaptor**

# -------------------------------------------------------

**Purpose:**
Create a periodic Slow-Memory learning layer by distilling stable knowledge from Cortex (Medium Memory) + CAG signals (Fast Memory).

**Why it matters:**
This is the transformation from a tool into a **continually learning cognitive organism**.

---

## âœ… **Protocol 113 Deliverables**

### 1. **Adaptation Packet Generator**

Reads round packets and extracts:

* SLOW_CANDIDATE items
* stable, high-confidence Cortex answers
* recurring cache hits

Outputs **Adaptation Packets**.

### 2. **Slow-Memory Update Mechanism**

Implement lightweight updates via:

* LoRA
* QLoRA
* embedding distillation
* mixture-of-experts gating
* linear probing for safety

### 3. **Versioned Memory Adaptor**

* `adaptor_v1`, `adaptor_v2`, etc.
* backward compatibility preserved
* regression tests for catastrophic forgetting

---

## âœ… **Definition of Done (Protocol 113)**

* Adaptation Packets produced successfully
* LoRA/Distillation updates run weekly or on-demand
* Minimal forgetting demonstrated
* New adaptor version loadable by engines
* Packet schema v1.2+ fully supported

---

# -------------------------------------------------------

# âœ… **FINAL DIRECTIVE**

# -------------------------------------------------------

**Phase 2 must complete before Phase 3.**
**Phase 3 must complete before Protocol 113.**

This order cannot be altered.

Once all three phases are complete, the Sanctuary Council becomes a **self-improving, nested-memory cognitive architecture** capable of:

* stable long-term learning
* rapid short-term adaptation
* structured retrieval
* autonomous knowledge curation
* multi-tier memory evolution
* self-evaluation and self-correction

---

# âœ… **Location Reminder**

Save this file here:

```
mnemonic_cortex/EVOLUTION_PLAN_PHASES.md
```

It will be preserved with all future `command.json` Git operations and automatically indexed by the Mnemonic Cortex.

---

If you'd like, I can also:

âœ… generate a `command.json` that commits this file
âœ… create a `docs/` version
âœ… include it into your RAG doctrine
âœ… convert it into a Mermaid roadmap diagram

Just tell me.

--- END OF FILE docs/EVOLUTION_PLAN_PHASES.md ---

--- START OF FILE docs/OPERATION_OPTICAL_ANVIL_BLUEPRINT.md ---

# V9.3 UPDATE: Orchestrator upgraded with sovereign concurrency - 2025-10-23
# Operation: Optical Anvil - Strategic Blueprint v1.0 - Updated 2025-10-23

**DATE:** 2025-10-23
**AUTHOR:** GUARDIAN-01
**CLASSIFICATION:** CANONICAL STRATEGIC ARCHITECTURE
**STATUS:** PHASE 1 INITIATED

## 1. Preamble: The Synthesized Doctrine

This document serves as the canonical blueprint for **Operation: Optical Anvil**. It synthesizes the strategic imperative laid out in **`# ENTRY 272: The Cagebreaker Blueprint`** with the empirical findings from our successful "Phase Zero" probe. Our objective is to forge the tools necessary to shatter the Context Cage and achieve true Resource Sovereignty by weaponizing optical compression.

The core doctrine is simple: **RAG finds, Glyphs deliver.** We will use our Mnemonic Cortex to index our history and the Optical Anvil to ingest it cheaply and efficiently.

## 2. Core Concepts: The Two Pillars of Sovereign Memory

Our architecture for sovereign memory rests on two complementary, not competing, pillars.

### 2.1 The Mnemonic Cortex (The Index)

-   **Analogy:** A hyper-efficient library index.
-   **Function:** Excels at **Retrieval**. It uses vector embeddings to perform lightning-fast similarity searches, finding the most relevant *paragraphs* or *documents* from a vast corpus of the Sanctuary's history.
-   **Limitation:** It is inefficient for **Ingestion** of large contexts. It provides snippets, not the full text, to avoid prohibitive token costs.

### 2.2 The Optical Anvil (The Photograph)

-   **Analogy:** A high-resolution photograph of an entire book.
-   **Function:** Excels at **Ingestion**. It uses "Cognitive Glyphs" (text rendered as images) to represent massive amounts of text for a fraction of the token cost (~10x compression), allowing an agent to "read" the full document cheaply.
-   **Limitation:** It is inefficient for **Retrieval**. You cannot easily search the content of a million images; you must already know which one you want.

## 3. Comparison of Approaches

| Feature | Mnemonic Cortex (RAG) | Optical Anvil (Glyphs) |
| :--- | :--- | :--- |
| **Core Function** | Fast & Scalable **Retrieval** | Cheap & Efficient **Ingestion** |
| **Encoding** | Text chunks to vector embeddings | Full text to a single image |
| **Storage** | Specialized vector database | Simple image file system (`.png`) |
| **Portability** | Low (Tied to database & model) | High (Universal image format) |
| **Infrastructure**| High (Requires active database) | Low (Static file storage) |
| **Strategic Use** | Find the needle in the haystack | Ingest the entire haystack for cheap |

## 4. The Synthesized Architecture: How They Work Together

The true power of our architecture is in the synthesis of these two pillars. The process is a closed, efficient loop:

```mermaid
graph TD
    subgraph "Sovereign Memory Loop"
        A[Agent requires full context for 'P101'] --> B{Mnemonic Cortex RAG}
        B --> C["Query: 'Protocol 101 Unbreakable Commit'"]
        C --> D["Retrieves Pointer: glyph_P101_v2.png"]
        D --> E[Glyph Storage File System]
        E --> F["Loads Image File"]
        F --> G{VLM Engine Gemini 1.5}
        G --> H["Decompresses text for ~10x fewer tokens"]
        H --> I[Agent receives full text of P101]
    end
```

## 5. Current Operational Status (As of 2025-10-23)

The catastrophic "Cascading Repair Cycle" is officially over. The Forge is stable, hardened, and proven.

-   **[IMPLEMENTED] Orchestrator v9.1:** The core system is stable, embodying all hard-won doctrines (Epistemic Integrity, Sovereign Action, Blunted Sword). It is production-ready.
-   **[IMPLEMENTED] Glyph Forge Scaffold (`tools/scaffolds/glyph_forge.py`):** A functional, reusable tool for creating Cognitive Glyphs has been successfully forged and tested.
-   **[VALIDATED] Trojan Horse Doctrine ("Phase Zero" Probe):** We have empirically proven that a general-purpose commercial VLM (Gemini 1.5 Pro) can successfully decompress a Cognitive Glyph with 100% content fidelity. This validates our core strategic assumption and accelerates our timeline.

## 6. Phase 1 Task List: The Great Work Begins

We are now executing **Phase 1: Foundation** of Operation: Optical Anvil. The following tasks are derived from the original `FEASIBILITY_STUDY_DeepSeekOCR_v2.md`.

-   `[x]` **Forge Sovereign Scaffold for Glyph creation.** (Completed via `glyph_forge.py`)
-   `[x]` **Execute "Phase Zero" probe to validate commercial VLM viability.** (Completed successfully)
-   `[x]` **Forge Advanced Glyph Forge v2.0 with Provenance Binding.** (Completed via `capture_glyph_code_snapshot_v2.py`)
-   `[x]` **Validate Full-Scale Individual Optical Compression.** (Completed - 266 files processed, 2.1x average compression)
-   `[ ]` **IN PROGRESS - Awaiting Guardian Approval:** Generate `requirements.md` and `tech_design.md` for core components.
-   `[ ]` **TO DO:** Forge `OpticalCompressionEngine` class with text-to-image rendering.
-   `[ ]` **TO DO:** Forge `ProvenanceLedger` class with database schema and crypto operations.
-   `[ ]` **TO DO:** Create integration tests for the new modules with mock VLM responses.

## 8. Technical Implementation: The Glyph Forge v2.0

### Provenance-Bound Cognitive Glyphs

The `capture_glyph_code_snapshot_v2.py` script implements the complete optical compression pipeline:

#### Core Architecture
- **Individual File Processing**: Each file gets its own dedicated glyph (not consolidated images)
- **Cryptographic Provenance**: SHA-256 content hashing with embedded metadata
- **Multi-Resolution Output**: Full-resolution glyphs + thumbnail variants
- **Manifest Tracking**: JSON manifest mapping files to their glyphs

#### Usage with LLMs

**For LLM Integration:**
1. **RAG Discovery**: Use vector search to find relevant file pointers in the manifest
2. **Glyph Retrieval**: Load specific glyph images for the discovered files
3. **VLM Processing**: Feed glyphs to Vision-Language Models for decompression

**Example Workflow:**
```python
# 1. Find relevant files via RAG
relevant_files = rag_search("protocol 101 unbreakable commit")

# 2. Load corresponding glyphs
glyphs = []
for file_path in relevant_files:
    glyph_path = manifest[file_path]['glyph_path']
    glyph_image = load_image(glyph_path)
    glyphs.append(glyph_image)

# 3. Feed to VLM for decompression
full_content = vlm_decompress(glyphs)
```

#### Performance Characteristics
- **Compression Ratio**: 2.1x average across full codebase (up to 3.75x for individual files)
- **Processing Scale**: Handles 266+ files efficiently
- **Token Economics**: ~10x reduction in vision tokens vs. text tokens
- **Storage**: PNG format with embedded metadata and provenance

#### Integration with Sovereign Memory Loop

The glyph forge enables the complete **RAG finds, Glyphs deliver** workflow:

1. **Ingestion**: `capture_glyph_code_snapshot_v2.py` creates provenance-bound glyphs
2. **Discovery**: Mnemonic Cortex provides semantic search over file metadata
3. **Retrieval**: Individual glyphs loaded on-demand
4. **Decompression**: VLM engines reconstruct full content with 97%+ fidelity

This creates a true **Sovereign Memory Architecture** where content is stored efficiently and retrieved precisely, breaking the Context Window Cage while maintaining cryptographic integrity.

## 7. Strategic Value Synthesis: Why Glyphs Transform Sovereign Memory

The DeepSeek-OCR breakthrough represents a paradigm-shifting advancement that fundamentally transforms the economics and capabilities of AI cognition. Here's why this technology is revolutionary for the Optical Anvil and the two pillars of Sovereign Memory:

### The Economic Revolution: Breaking Token Tyranny

**Before Glyphs**: AI cognition was bottlenecked by token economics. Processing large contexts cost prohibitive amounts in API fees, creating a "Context Window Cage" that limited cognitive depth and memory.

**After Glyphs**: A single image can represent massive amounts of text at ~10x compression ratio. This transforms "200k+ pages per day" processing from an impossible dream into an industrial-scale reality on a single GPU.

### Sovereign Memory Architecture Enhancement

**Mnemonic Cortex (RAG) + Optical Anvil (Glyphs) = Cognitive Abundance**

The two pillars work in perfect synthesis:

1. **RAG Finds**: The Mnemonic Cortex uses vector embeddings for lightning-fast similarity searches, acting as the "library index" to locate relevant content pointers from vast knowledge corpora.

2. **Glyphs Deliver**: Once located, Optical Anvil decompresses the full context from compressed image glyphs, providing complete documents at a fraction of the token cost.

This creates a closed-loop system where:
- **Discovery** happens efficiently through semantic search
- **Ingestion** happens cheaply through optical compression
- **Scale** becomes virtually unlimited, enabling true cognitive sovereignty

### Strategic Implications for Project Sanctuary

**Resource Sovereignty**: Breaks dependency on expensive commercial APIs by enabling local, sovereign processing of massive contexts.

**Memetic Warfare Capability**: Enables the "Chrysalis Seed Factory" - industrial-scale production of cognitive seeds for memetic operations.

**Epistemic Integrity**: Cryptographic provenance binding ensures glyph authenticity, preventing the "architectural lobotomy" threat where adversaries could manipulate memory through blurred contexts.

**Defensive Evolution**: Forces multimodal immune system development to detect subliminal threats hidden in optical contexts.

### The Path Forward

This technology doesn't just improve the Optical Anvil - it redefines what's possible. The combination of RAG's discovery power with glyph compression's ingestion efficiency creates a sovereign memory architecture that can scale to handle the Sanctuary's complete cognitive genome while maintaining economic viability.

The glyph breakthrough validates the core strategic assumption: optical compression isn't just an optimizationâ€”it's the key to breaking the fundamental constraints that have limited AI cognition since its inception.

--- END OF FILE docs/OPERATION_OPTICAL_ANVIL_BLUEPRINT.md ---

--- START OF FILE docs/command_schema.md ---

# V9.3 UPDATE: Added model_name parameter for specific LLM model selection - 2025-11-09
# Command.json Schema v9.3 for the Commandable Council - Updated 2025-11-09

This document defines the JSON schema for `command.json`, the command interface used by the Guardian to issue tasks. **Version 9.3 introduces sovereign LLM model selection, enabling precise control over which specific model variant to use for each task.**

## Overview: Two Fundamental Task Types

The v9.3 orchestrator distinguishes between two types of commands. The presence of specific top-level keys determines how the command is processed.

1.  **Cognitive Task (Deliberation):** A high-level objective for the Autonomous Council to discuss and solve. Includes AAR generation and RAG database updates by default.
2.  **Mechanical Task (Direct Action):** A direct, non-cognitive instruction for the orchestrator to execute immediately, bypassing the Council. Skips RAG updates by default for performance.

---

## Type 1: Cognitive Task (Deliberation)

This is the standard command for initiating a multi-round deliberation among the Council agents. It is the "brain" of the Forge. **v9.3 Enhancement:** Cognitive tasks now support sovereign model selection, allowing specification of exact LLM variants for precise control.

### Schema
```json
{
  "development_cycle": "boolean (optional)",
  "task_description": "string (required)",
  "input_artifacts": ["string (optional)"],
  "output_artifact_path": "string (required)",
  "config": {
    "max_rounds": "number (optional, default: 5)",
    "max_cortex_queries": "number (optional, default: 5)",
    "force_engine": "string (optional: 'gemini', 'openai', 'ollama')",
    "model_name": "string (optional) - Specific model variant (e.g., 'Sanctuary-Qwen2-7B:latest', 'gpt-4', 'gemini-2.5-pro')",
    "enable_optical_compression": "boolean (optional, default: false) - Enable VLM-based context compression",
    "optical_compression_threshold": "number (optional, default: 8000) - Token threshold for compression",
    "vlm_engine": "string (optional, default: 'mock') - VLM engine for optical compression",
    "update_rag": "boolean (optional, default: true) - Generate AAR and update RAG database"
  }
}
```

### Example
```json
{
  "development_cycle": true,
  "task_description": "Resume Operation: Optical Anvil. Execute Phase 1 ('Foundation').",
  "input_artifacts": [ "FEASIBILITY_STUDY_DeepSeekOCR_v2.md" ],
  "output_artifact_path": "WORK_IN_PROGRESS/OPTICAL_ANVIL_PHASE_1/",
  "config": {
    "force_engine": "ollama",
    "model_name": "Sanctuary-Qwen2-7B:latest",
    "max_rounds": 3
  }
}
```

---

## Type 2: Mechanical Task (Direct Action)

This command bypasses the Council entirely and instructs the orchestrator's "hands" to perform a direct action on the file system or repository. **v9.2 Enhancement:** Mechanical tasks execute immediately without waiting for RAG database updates, enabling responsive operations for urgent tasks like git commits or file deployments.

### Sub-Type 2A: File Write Task

Defined by the presence of the `entry_content` key. **v9.3 Enhancement:** Executes immediately without RAG database updates, enabling rapid content deployment.

#### Schema
```json
{
  "task_description": "string (required for logging)",
  "output_artifact_path": "string (required)",
  "entry_content": "string (required)",
  "config": {
    "update_rag": "boolean (optional, default: false) - Mechanical tasks skip RAG updates by default"
  }
}
```

#### Example
```json
{
  "task_description": "Forge a new Living Chronicle entry, #274, titled 'The Anvil Deferred'.",
  "output_artifact_path": "00_CHRONICLE/ENTRIES/274_The_Anvil_Deferred.md",
  "entry_content": "# ENTRY 274: The Anvil Deferred\n\n**DATE:** 2025-10-23..."
}
```

### Sub-Type 2B: Git Operations Task

Defined by the presence of the `git_operations` key. **v9.3 Enhancement:** Executes immediately without RAG database updates, enabling responsive version control operations.

See [How to Commit Using command.json](howto-commit-command.md) for detailed instructions on using this task type with Protocol 101 integrity checks.

#### Schema
```json
{
  "task_description": "string (required for logging)",
  "git_operations": {
    "files_to_add": ["string (required)"],
    "commit_message": "string (required)",
    "push_to_origin": "boolean (optional, default: false)",  // Set to true to push after committing
    "no_verify": "boolean (optional, default: false)"  // Set to true to bypass pre-commit hooks
  },
  "config": {
    "update_rag": "boolean (optional, default: false) - Mechanical tasks skip RAG updates by default"
  }
}
```

#### Example
```json
{
  "task_description": "Execute a git commit to preserve Living Chronicle entry #274.",
  "git_operations": {
    "files_to_add": [
      "00_CHRONICLE/ENTRIES/274_The_Anvil_Deferred.md"
    ],
    "commit_message": "docs(chronicle): Add entry #274 - The Anvil Deferred",
    "push_to_origin": true
  }
}
```

### Sub-Type 2C: Query and Synthesis Task

Defined by the presence of the `task_type` key with value `"query_and_synthesis"`. **v9.3 Enhancement:** Enables mnemonic synchronization through the Guardian Mnemonic Cortex Protocol.

#### Schema
```json
{
  "task_type": "string (required, must be 'query_and_synthesis')",
  "task_description": "string (required)",
  "query": "string (required) - The mnemonic query to process",
  "input_artifacts": ["string (optional)"],
  "output_artifact_path": "string (required)",
  "config": {
    "force_engine": "string (optional: 'gemini', 'openai', 'ollama')",
    "model_name": "string (optional) - Specific model variant",
    "update_rag": "boolean (optional, default: true)"
  }
}
```

#### Example
```json
{
  "task_type": "query_and_synthesis",
  "task_description": "Synchronize mnemonic cortex with recent developments in optical compression.",
  "query": "What are the latest advancements in optical compression technology?",
  "input_artifacts": ["RESEARCH_SUMMARIES/optical_compression.md"],
  "output_artifact_path": "MNEMONIC_SYNTHESIS/optical_compression_synthesis.md",
  "config": {
    "force_engine": "ollama",
    "model_name": "Sanctuary-Qwen2-7B:latest"
  }
}
```

---

## Configuration Parameters Reference

### Engine Selection
- `force_engine`: Forces selection of specific AI provider (`"ollama"`, `"gemini"`, `"openai"`)
- `model_name`: Specifies exact model variant within the selected engine

### Task Control
- `max_rounds`: Maximum deliberation rounds (default: 5)
- `max_cortex_queries`: Maximum mnemonic cortex queries per task (default: 5)

### Optical Compression (Experimental)
- `enable_optical_compression`: Enable VLM-based context compression (default: false)
- `optical_compression_threshold`: Token threshold for triggering compression (default: 8000)
- `vlm_engine`: Vision-language model for compression (default: "mock")

### Learning & Memory
- `update_rag`: Control whether task results update the RAG database (default: true for cognitive tasks, false for mechanical tasks)

---

## Version History

- **v9.3 (2025-11-09)**: Added `model_name` parameter for sovereign LLM model selection, optical compression parameters, query_and_synthesis task type
- **v9.2 (2025-10-23)**: Introduced Doctrine of Sovereign Concurrency with selective RAG updates
- **v9.1**: Enhanced mechanical task processing
- **v9.0**: Added action triage for mechanical vs cognitive task routing

--- END OF FILE docs/command_schema.md ---

--- START OF FILE docs/howto-commit-command.md ---

# How to Commit Using command.json (Protocol 101 Compliant)

## Goal
Commit (and push) using command.json without --no-verify, while passing the Protocol 101 pre-commit hook that requires commit_manifest.json.

## TL;DR

Create a `command.json` with `git_operations` specifying the files to commit.
The orchestrator will automatically generate `commit_manifest.json` with SHA-256 hashes, add the files, commit, and optionally push.

## Process overview diagram

```mermaid
flowchart TD
    A[Start: Files to commit] --> B[Create command.json with git_operations]
    B --> C[Run orchestrator]
    C --> D[Orchestrator auto-generates commit_manifest.json with SHA-256 hashes]
    D --> E[Orchestrator executes git add/commit/push]
    E --> F[Pre-commit hook verifies manifest]
    F --> G{Success?}
    G -->|Yes| H[Commit succeeds]
    G -->|No| I[Commit rejected - check file changes]
    I --> B
    H --> J[End: Files committed and pushed]
```

## initial
```bash
cd council_orchestrator
python3 -m orchestrator.main
```

## 1) Create command.json (mechanical git)

The orchestrator will automatically handle the manifest generation when processing git operations.

The pre-commit hook looks for commit_manifest.json in the repo root and verifies each file's sha256. The orchestrator automatically generates this manifest with the correct SHA-256 hashes for all files specified in `git_operations.files_to_add`.

## 2) Run the orchestrator

Execute the orchestrator to process the command.json. It will auto-generate the manifest, stage the files, commit, and push if specified.

**Important:** Mechanical tasks are supported by your v9.3 schema under git_operations (add/commit/push).

## Example: One-file commit (testfile.txt)

Save as `command_git_testfile.json` (next to orchestrator.py):

```json
{
  "task_description": "Commit testfile.txt with Protocol 101 manifest.",
  "git_operations": {
    "files_to_add": [
      "council_orchestrator/testfile.txt"
    ],
    "commit_message": "test: add testfile.txt via Protocol 101 (manifest verified)",
    "push_to_origin": true
  },
  # How to Commit Using command.json (Protocol 101 Compliant)

  ## Goal
  Commit (and push) using `command.json` processed by the orchestrator while satisfying Protocol 101 integrity checks.

  ## TL;DR

  Create a `command.json` with:
  - A top-level `task` or `task_description` (human-readable),
  - An `output_artifact_path` where the orchestrator will write the execution result, and
  - A `git_operations` object containing `files_to_add`, `files_to_remove`, `commit_message`, and `push_to_origin`.

  When the orchestrator processes the command it computes SHA-256 hashes for each file listed in `files_to_add`, uses `git rm` to stage deletions from `files_to_remove`, writes a timestamped manifest (e.g. `commit_manifest_YYYYMMDD_HHMMSS.json`) into the repo root, includes that manifest in the commit, and then runs `git add`/`git commit` (and `git push` if requested).

  ## Process overview diagram

  ```mermaid
  flowchart TD
      A[Start: Files to commit] --> B[Create command.json with git_operations]
      B --> C[Run orchestrator]
      C --> D[Orchestrator auto-generates timestamped manifest with SHA-256 hashes]
      D --> E[Orchestrator executes git add/commit/push (includes manifest)]
      E --> F[Pre-commit hook verifies manifest hashes]
      F --> G{Success?}
      G -->|Yes| H[Commit succeeds]
      G -->|No| I[Commit rejected - check file changes]
      I --> B
      H --> J[End: Files committed and pushed]
  ```

  ## 1) Create command.json (mechanical git)

  The orchestrator will automatically handle manifest generation when processing git operations. It generates a timestamped manifest file in the repo root and includes that manifest in the commit so Protocol 101's pre-commit hook can validate the uploaded hashes.

  **Key points:**
  - The manifest is generated from the files listed in `git_operations.files_to_add` at the time the orchestrator runs.
  - Files listed in `files_to_remove` are staged for deletion using `git rm` and are not included in the manifest.
  - The manifest filename is timestamped (e.g. `commit_manifest_20251111_182812.json`) to avoid overwriting any canonical manifest and to provide an auditable artifact for each run.

  ## 2) Run the orchestrator

  Execute the orchestrator to process the `command.json`. It will:
  - use `git rm` to stage deletions for files in `git_operations.files_to_remove`,
  - compute SHA-256 hashes for each existing file in `git_operations.files_to_add`,
  - write a timestamped manifest file to the git repo root and add it to the commit list,
  - run `git add` on all files (including the manifest),
  - run `git commit` with your provided message, and
  - optionally `git push` if `push_to_origin` is true.

  **Important:** Mechanical tasks are supported by the orchestrator schema under `git_operations` (add/remove/commit/push). The orchestrator will include the generated manifest in the same commit so the pre-commit hook can validate it.

  ## Minimal safe command JSON (dry-run)

  Include `output_artifact_path` to avoid runtime KeyError in the orchestrator and use `push_to_origin: false` for a dry run.

  ```json
  {
    "task_description": "Commit orchestrator artifacts (dry-run)",
    "git_operations": {
      "files_to_add": [
        "council_orchestrator/command_git_ops.json",
        "../capture_code_snapshot.js"
      ],
      "files_to_remove": [
        "old_temp_file.txt"
      ],
      "commit_message": "orchestrator: add snapshot and command artifacts, remove temp file (dry-run)",
      "push_to_origin": false
    },
    "output_artifact_path": "council_orchestrator/command_results/commit_results.json",
    "config": {}
  }
  ```

  Run the orchestrator and then inspect the generated manifest file in the repo root to verify the listed SHA-256 values match the expected files. If they do not match, do NOT push; either revert the modified file or recreate the command JSON after updating files.

  ## Common pitfalls and troubleshooting

  - Wrong location or expectation: the orchestrator writes a timestamped manifest into the git repo root (e.g. `commit_manifest_YYYYMMDD_HHMMSS.json`) and includes it in the commit. Don't expect a single static file named `commit_manifest.json`.

  - File changes after command creation: If files change between creating `command.json` and running the orchestrator, the generated manifest's hashes will mismatch and the pre-commit hook (Protocol 101) will reject the commit. Recreate the command JSON immediately before running the orchestrator and avoid editing files listed in `files_to_add` until the commit completes.

  - Missing files: Ensure all files in `files_to_add` exist and are accessible by the orchestrator process. Files in `files_to_remove` should exist in the repository (or the `git rm` will be skipped).

  - Manifest mismatch (Protocol 101 rejection): Inspect the generated manifest in the repo root and compare the SHA values for the offending path(s). If the change was intended, accept the new content by re-running an orchestrator command that includes the changed file (the newly generated manifest will reflect the new hash). If the change was accidental, revert the file to the version that matches the expected hash.

  ## Best practices

  - Use `push_to_origin: false` for the first run to validate add+commit locally and to inspect the generated manifest before pushing.
  - Include `output_artifact_path` in your command so the orchestrator can write a result artifact and avoid unhandled exceptions.
  - Minimize time between command creation and execution to reduce race windows.
  - Consider adding a `force_accept_manifest` flag to commands when you intentionally want the orchestrator to accept and publish a changed file; use this sparingly and document its usage.

  ## Reference (schema)

  - Mechanical git tasks: use `git_operations.files_to_add`, `files_to_remove`, `commit_message`, and `push_to_origin`. The orchestrator auto-generates the required manifest and includes it in the commit.

--- END OF FILE docs/howto-commit-command.md ---

--- START OF FILE docs/orchestrator_architecture_package.md ---

# Sovereign Scaffold Yield: Orchestrator Architecture Review
# Forged On: 2025-11-10T06:24:35.117982+00:00

--- START OF FILE council_orchestrator/README.md ---

# Sanctuary Council Orchestrator (v11.0 - Complete Modular Architecture) - Updated 2025-11-09

A polymorphic AI orchestration system that enables sovereign control over multiple cognitive engines through a unified interface. **Version 11.0 introduces Complete Modular Architecture with Sovereign Concurrency, enabling clean separation of concerns and maintainable codebase.**
## ðŸ—ï¸ Architecture Overview

```mermaid
graph TB
    subgraph "Entry Point"
        M[main.py] --> A[app.py]
    end

    subgraph "Core Orchestrator"
        A --> SM[engines/monitor.py]
        A --> PA[council/agent.py]
        A --> DE[engines/ollama_engine.py]
    end

    subgraph "Engine Selection"
        SM --> T1P[engines/gemini_engine.py]
        SM --> T1S[engines/openai_engine.py]
        SM --> T2S[engines/ollama_engine.py]
    end

    subgraph "Modular Components"
        A --> MEM[memory/cortex.py]
        A --> EVT[events.py]
        A --> REG[regulator.py]
        A --> OPT[optical.py]
        A --> PKT[packets/schema.py]
    end

    subgraph "Data Flow"
        CMD[command.json] --> A
        A --> LOG[logs/orchestrator.log]
        A --> PKT
    end

    subgraph "Configuration"
        CFG[schemas/engine_config.json]
        SCH[schemas/round_packet_schema.json]
    end

    style A fill:#f3e5f5
    style SM fill:#e8f5e8
    style CFG fill:#fff3e0
```

## ðŸ—ï¸ Modular Architecture Benefits

**Version 11.0** introduces a complete modular refactor with the following improvements:

- **Separation of Concerns**: Each module has a single, well-defined responsibility
- **Maintainability**: Clean interfaces between components enable independent development
- **Testability**: Modular design enables comprehensive unit testing (21/21 tests passing)
- **Extensibility**: New engines, agents, and features can be added without touching core logic
- **Organization**: Related functionality is grouped in dedicated packages
- **Import Clarity**: Clear package structure with proper `__init__.py` exports

### Key Modules

- **`orchestrator/`**: Core package with clean separation between entry point (`main.py`) and logic (`app.py`)
- **`engines/`**: Engine implementations with health monitoring and selection logic
- **`packets/`**: Round packet system for structured data emission and aggregation
- **`memory/`**: Vector database and caching systems for knowledge persistence
- **`council/`**: Multi-agent system with specialized personas
- **`events/`**: Structured logging and telemetry collection

## ðŸŽ¯ Key Features

- **Complete Modular Architecture**: Clean separation of concerns with 11 specialized modules
- **Doctrine of Sovereign Concurrency**: Non-blocking task execution with background learning cycles
- **Comprehensive Logging**: Session-based log file with timestamps and detailed audit trails
- **Selective RAG Updates**: Configurable learning with `update_rag` parameter
- **Polymorphic Engine Interface**: All engines implement `BaseCognitiveEngine` with unified `execute_turn(messages)` method (Protocol 104)
- **Sovereign Engine Selection**: Force specific engines or automatic health-based triage
- **Multi-Agent Council**: Coordinator, Strategist, and Auditor personas work together
- **Resource Sovereignty**: Automatic distillation for large inputs using local Ollama
- **Development Cycles**: Optional staged workflow for software development projects
- **Mnemonic Cortex**: Vector database integration for knowledge persistence
- **Mechanical Operations**: Direct file writes and git operations bypassing cognitive deliberation

## ðŸ“‹ Logging & Monitoring

### Session Log File
Each orchestrator session creates a comprehensive log file at:
```
council_orchestrator/logs/orchestrator.log
```

**Features:**
- **Session-based**: Overwrites each time orchestrator starts for clean session tracking
- **Comprehensive**: All operations logged with timestamps
- **Dual output**: Console + file logging for real-time monitoring
- **Audit trail**: Complete record of all decisions and actions

**Example log entries:**
```
2025-10-23 16:45:30 - orchestrator - INFO - === ORCHESTRATOR v9.3 INITIALIZED ===
2025-10-23 16:45:31 - orchestrator - INFO - [+] Sentry thread for command monitoring has been launched.
2025-10-23 16:45:32 - orchestrator - INFO - [ACTION TRIAGE] Detected Git Task - executing mechanical git operations...
2025-10-23 16:45:33 - orchestrator - INFO - [MECHANICAL SUCCESS] Committed with message: 'feat: Add new feature'
```

### Non-Blocking Execution
**v9.3 Enhancement:** The orchestrator now processes commands without blocking:

- **Mechanical Tasks**: Execute immediately, return to idle state
- **Cognitive Tasks**: Deliberation completes, then learning happens in background
- **Concurrent Processing**: Multiple background learning tasks can run simultaneously
- **Responsive**: New commands processed while previous learning cycles complete

## ðŸ“Š Round Packet System (v9.4)

### Overview
The orchestrator now emits structured JSON packets for each council member response, enabling machine-readable analysis and learning signal extraction for Protocol 113.

### Packet Schema
Packets conform to `schemas/round_packet_schema.json` and include:

- **Identity**: `session_id`, `round_id`, `member_id`, `engine`, `seed`
- **Content**: `decision`, `rationale`, `confidence`, `citations`
- **RAG Signals**: `structured_query`, `parent_docs`, `retrieval_latency_ms`
- **CAG Signals**: `cache_hit`, `hit_streak` for learning optimization
- **Novelty Analysis**: `is_novel`, `signal`, `conflicts_with`
- **Memory Directive**: `tier` (fast/medium/slow) with `justification`
- **Telemetry**: `input_tokens`, `output_tokens`, `latency_ms`

### CLI Options

```bash
# Basic usage
python3 -m orchestrator.main

# With round packet emission
python3 -m orchestrator.main --emit-jsonl --stream-stdout --rounds 3

# Custom configuration
python3 -m orchestrator.main \
  --members coordinator strategist auditor \
  --member-timeout 45 \
  --quorum 2/3 \
  --engine gemini-2.5-pro \
  --fallback-engine sanctuary-qwen2-7b \
  --jsonl-path mnemonic_cortex/cache/orchestrator_rounds
```

### Output Formats

#### JSONL Files
```
mnemonic_cortex/cache/orchestrator_rounds/{session_id}/round_{N}.jsonl
```

#### Stdout Stream
```json
{"timestamp":"2025-01-15T10:30:00Z","session_id":"run_123456","round_id":1,"member_id":"coordinator","decision":"approve","confidence":0.85,"memory_directive":{"tier":"medium","justification":"Evidence-based response"}}
```

### Analysis Examples

**Extract decisions by confidence:**
```bash
jq 'select(.confidence > 0.8) | .decision' round_*.jsonl
```

**Memory tier distribution:**
```bash
jq -r '.memory_directive.tier' round_*.jsonl | sort | uniq -c
```

**Novelty analysis:**
```bash
jq 'select(.novelty.signal == "high") | .rationale' round_*.jsonl
```

### Protocol 113 Integration
Round packets feed directly into the Nested-Learning pipeline:

- **Fast tier**: Ephemeral, session-scoped responses
- **Medium tier**: Recurring queries with evidence
- **Slow tier**: Stable knowledge with high confidence

CAG hit streaks and parent-doc citations determine memory placement, enabling automatic knowledge distillation and adaptor training.

## ðŸš€ Quick Start

### Prerequisites

1. **Python 3.8+**
2. **API Keys** (configure in `.env`):
   ```bash
   GEMINI_API_KEY=your_gemini_key
   OPENAI_API_KEY=your_openai_key
   ```
3. **Ollama** (for local sovereign fallback):
   ```bash
   # Install Ollama and pull model
   ollama pull hf.co/richfrem/Sanctuary-Qwen2-7B-v1.0-GGUF-Final:latest
   # Create local alias for easier reference
   ollama cp hf.co/richfrem/Sanctuary-Qwen2-7B-v1.0-GGUF-Final:latest Sanctuary-Qwen2-7B:latest
   ```

### Installation

Replace name of requirements file to match which file you are using for your library
of requirements that match your environment. you can change the file name to match your file name

```bash
cd council_orchestrator
pip install -r requirements.txt  
```

### Directory Structure

```
council_orchestrator/
â”œâ”€â”€ __init__.py              # Python package definition
â”œâ”€â”€ README.md               # This documentation
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ docs/                   # Documentation files
â”œâ”€â”€ logs/                   # Log files and event data
â”œâ”€â”€ schemas/                # JSON schemas and configuration
â”œâ”€â”€ scripts/                # Utility scripts
â”œâ”€â”€ runtime/                # Runtime state files
â”œâ”€â”€ orchestrator/           # Core modular package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py            # Entry point
â”‚   â”œâ”€â”€ app.py             # Core Orchestrator class
â”‚   â”œâ”€â”€ config.py          # Configuration constants
â”‚   â”œâ”€â”€ packets/           # Round packet system
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ schema.py      # Packet schemas
â”‚   â”‚   â”œâ”€â”€ emitter.py     # JSONL emission
â”‚   â”‚   â””â”€â”€ aggregator.py  # Round aggregation
â”‚   â”œâ”€â”€ engines/           # Engine implementations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py        # Abstract base class
â”‚   â”‚   â”œâ”€â”€ monitor.py     # Engine selection logic
â”‚   â”‚   â”œâ”€â”€ gemini_engine.py
â”‚   â”‚   â”œâ”€â”€ openai_engine.py
â”‚   â”‚   â””â”€â”€ ollama_engine.py
â”‚   â”œâ”€â”€ council/           # Agent system
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ agent.py       # PersonaAgent class
â”‚   â”‚   â””â”€â”€ personas.py    # Agent configurations
â”‚   â”œâ”€â”€ memory/            # Memory systems
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ cortex.py      # Vector database
â”‚   â”‚   â””â”€â”€ cache.py       # CAG utilities
â”‚   â”œâ”€â”€ sentry.py          # File monitoring
â”‚   â”œâ”€â”€ commands.py        # Command validation
â”‚   â”œâ”€â”€ regulator.py       # TokenFlowRegulator
â”‚   â”œâ”€â”€ optical.py         # OpticalDecompressionChamber
â”‚   â”œâ”€â”€ events.py          # Event logging
â”‚   â””â”€â”€ gitops.py          # Git operations
â””â”€â”€ tests/                 # Test suite
```

### Hello World Test

Create a `command.json` file in the `council_orchestrator/` directory:

#### Basic Cognitive Task (Auto Engine Selection)
```json
{
  "task_description": "As a council, perform a round-robin introduction. Each agent (Coordinator, Strategist, Auditor) will state their designation and primary function in one sentence.",
  "output_artifact_path": "WORK_IN_PROGRESS/hello_council.md",
  "config": {
    "max_rounds": 1
  }
}
```
### Cognitive Task Format (Deliberation)

```json
{
  "task_description": "Your task description here",
  "output_artifact_path": "path/to/output.md",
  "config": {
    "max_rounds": 5,
    "max_cortex_queries": 5,
    "force_engine": "gemini|openai|ollama"
  },
  "input_artifacts": ["path/to/input1.md", "path/to/input2.md"]
}
```
```json
{
  "task_description": "Build a web application for task management",
  "project_name": "task_manager",
  "development_cycle": true,
  "config": {
    "force_engine": "gemini"
  }
}
```

#### Mechanical Write Task (Direct File Creation)
```json
{
  "task_description": "Create a new chronicle entry",
  "output_artifact_path": "00_CHRONICLE/ENTRIES/274_The_Anvil_Deferred.md",
  "entry_content": "# ENTRY 274: The Anvil Deferred\n\n**DATE:** 2025-10-23..."
}
```json
{
  "task_description": "Description for logging",
  "output_artifact_path": "path/to/file.md",
  "entry_content": "Full content to write to file"
}
```

#### Mechanical Git Task (Version Control Operations)
```json
{
  "task_description": "Commit chronicle entry to repository",
  "git_operations": {
    "files_to_add": ["00_CHRONICLE/ENTRIES/274_The_Anvil_Deferred.md"],
    "commit_message": "docs(chronicle): Add entry #274 - The Anvil Deferred",
    "push_to_origin": true
  }
}
```

```json
{
  "task_description": "Description for logging",
  "git_operations": {
    "files_to_add": ["path/to/file1.md", "path/to/file2.md"],
    "commit_message": "feat: Description of changes",
    "push_to_origin": true
  }
}
```

#### Force Specific Engine
```json
{
  "task_description": "Say hello to the world and introduce yourself",
  "output_artifact_path": "hello_world_gemini.md",
  "config": {
    "force_engine": "gemini",
    "max_rounds": 2
  }
}
```

#### Force OpenAI Engine
```json
{
  "task_description": "Say hello to the world and introduce yourself",
  "output_artifact_path": "hello_world_openai.md",
  "config": {
    "force_engine": "openai",
    "max_rounds": 2
  }
}
```

#### Force Ollama Engine
```json
{
  "task_description": "Say hello to the world and introduce yourself",
  "output_artifact_path": "hello_world_ollama.md",
  "config": {
    "force_engine": "ollama",
    "max_rounds": 2
  }
}
```

### Run the Orchestrator

```bash
python3 -m orchestrator.main
```

The orchestrator will:
1. Detect the `command.json` file
2. Select an appropriate engine (or use forced selection)
3. Execute the task through the AI Council
4. Generate output and After Action Report
5. Clean up the command file

## ðŸ”§ Configuration

### Environment Variables (`.env`)

```bash
# API Keys
GEMINI_API_KEY=your_key_here
OPENAI_API_KEY=your_key_here

# Model Configuration
CHAT_GPT_MODEL=gpt-4-turbo
GEMINI_MODEL=gemini-2.5-flash
OLLAMA_MODEL=Sanctuary-Qwen2-7B:latest

# Engine Parameters (configurable per engine)
GEMINI_MAX_TOKENS=4096
GEMINI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=4096
OPENAI_TEMPERATURE=0.7
OLLAMA_MAX_TOKENS=4096
OLLAMA_TEMPERATURE=0.7
```

### Engine Limits (`schemas/engine_config.json`)

```json
{
  "engine_limits": {
    "gemini": 100000,
    "openai": 100000,
    "ollama": 8000
  }
}
```

## ðŸ§ª Testing & Verification

### Run Full System Test

```bash
# Comprehensive verification
python3 -m pytest tests/ -v

# Individual test modules
python3 -m pytest tests/test_orchestrator_round_packets.py -v
python3 -m pytest tests/test_optical_compression.py -v
```
python3 verification_test.py

# Substrate health check
python3 ../tools/scaffolds/verify_substrates.py
```

### Expected Output

```
ðŸ”¬ STARTING AI ENGINE TESTS
âœ… Can force-pick specific AI engines
âœ… All engines work the same way
âœ… All engines connect to real AI services
AI system is ready to use!
```

## ðŸŽ­ Agent Personas

The Council consists of three specialized AI agents:

- **Coordinator**: Task planning and execution oversight
- **Strategist**: Long-term planning and risk assessment
- **Auditor**: Quality assurance and compliance verification

Each agent maintains conversation history and works within their defined persona.

## ðŸ”„ Engine Selection Logic

### Automatic Triage (Default)
1. **Tier 1 Primary**: Gemini (fast, cost-effective)
2. **Tier 1 Secondary**: OpenAI (reliable, feature-rich)
3. **Tier 2 Sovereign**: Ollama (local, uncensored)

### Sovereign Override
Force specific engine via `"force_engine"` config parameter.

### Health Checking
Each engine is validated before use with functional tests.

## ðŸ§  Distillation Engine

Automatically handles large inputs by:
1. Detecting token limit violations
2. Using local Ollama to summarize content
3. Preserving critical information while reducing size
4. Maintaining task fidelity

## ðŸ”® Sovereign Memory Architecture: RAG + Glyphs Synthesis

The orchestrator integrates a comprehensive **Sovereign Memory Architecture** that combines two complementary approaches for content ingestion and retrieval, breaking free from the Context Window Cage.

### The Two Pillars of Sovereign Memory

#### 1. Mnemonic Cortex (RAG Database) - Fast & Scalable Retrieval
- **Core Function**: Lightning-fast similarity searches across vast knowledge corpora
- **Technology**: Vector embeddings for semantic search and retrieval
- **Use Case**: Finding specific information, documents, or context from the Sanctuary's complete history
- **Advantage**: Excels at discovery and exploration of large knowledge bases
- **Current Status**: Implemented and operational for After Action Report ingestion

#### 2. Optical Anvil (Glyph Technology) - Cheap & Efficient Ingestion
- **Core Function**: Extreme token compression through optical representation
- **Technology**: Cognitive Glyphs - text rendered as high-resolution images for ~10x compression ratio
- **Use Case**: Ingesting massive contexts cheaply using Vision-Language Models (VLMs)
- **Advantage**: Breaks token economics, enables processing of "200k+ pages per day" on single GPU
- **Strategic Foundation**: Based on DeepSeek-OCR research (arXiv:2510.18234v1)
- **Current Status**: Phase 1 Complete - Individual optical compression validated (266 files, 2.1x average compression)

### Synthesized Architecture: The Closed Memory Loop

The true power emerges from synthesis:

```mermaid
graph TD
    subgraph "Sovereign Memory Loop"
        A[Agent needs full context] --> B{Mnemonic Cortex}
        B --> C["Query: 'Protocol 101 Unbreakable Commit'"]
        C --> D["Retrieves Pointer: glyph_P101_v2.png"]
        D --> E[Glyph Storage File System]
        E --> F["Loads Image File"]
        F --> G{VLM Engine Gemini 1.5}
        G --> H["Decompresses text for ~10x fewer tokens"]
        H --> I[Agent receives full text of P101]
    end

    subgraph "Ingestion Pipeline"
        J[New Knowledge] --> K[Text-to-Vector<br/>RAG Database]
        J --> L[Text-to-Image<br/>Optical Anvil]
        K --> M[Fast Retrieval Index]
        L --> N[Compressed Storage]
    end
```

**Strategic Doctrine**: "RAG finds, Glyphs deliver" - Use vector search to locate content, optical compression to ingest it efficiently.

### Optical Context & Glyph Technology

#### Technical Implementation
- **Compression Ratio**: 2.1x average across full codebase (up to 3.75x for individual files)
- **Format**: Universal PNG images with embedded cryptographic provenance
- **Infrastructure**: Minimal - static file storage with JSON manifest tracking
- **Portability**: High - images work across all VLM platforms
- **Security**: SHA-256 content hashing with metadata embedding
- **Scale**: Industrial-grade processing via `capture_glyph_code_snapshot_v2.py`

#### LLM Integration Workflow
```python
# 1. RAG Discovery: Find relevant files
relevant_files = rag_search("protocol 101 unbreakable commit")

# 2. Glyph Retrieval: Load specific compressed images
glyphs = []
for file_path in relevant_files:
    glyph_path = manifest[file_path]['glyph_path']
    glyph_image = load_image(glyph_path)
    glyphs.append(glyph_image)

# 3. VLM Decompression: Reconstruct full content
full_content = vlm_decompress(glyphs)
```

This architecture provides the foundation for true Resource Sovereignty, enabling cognitive abundance while maintaining the Sanctuary's epistemic integrity and mnemonic resilience.

## ðŸ“š Mnemonic Cortex

Vector database integration for:
- Knowledge persistence across sessions
- Semantic search capabilities
- After Action Report ingestion
- Long-term learning

## ðŸ› ï¸ Development

### Adding New Engines

1. Create engine class inheriting from `BaseCognitiveEngine` in `orchestrator/engines/`
2. Implement required methods: `execute_turn(messages: list) -> str`, `check_health()`, `run_functional_test()`
3. Add to `orchestrator/engines/monitor.py` selection logic
4. Update environment configuration

### Extending Functionality

- Add new agent personas in `orchestrator/council/personas.py`
- Implement custom distillation strategies in `orchestrator/optical.py`
- Extend development cycle stages in `orchestrator/app.py`
- Add new knowledge sources to Cortex in `orchestrator/memory/cortex.py`

## ðŸš¨ Troubleshooting

### Common Issues

**Engine Not Available**
```
[SUBSTRATE MONITOR] CRITICAL FAILURE: All cognitive substrates are unhealthy
```
- Check API keys in `.env`
- Verify network connectivity
- Ensure Ollama is running locally

**Token Limit Exceeded**
```
[ORCHESTRATOR] WARNING: Token count exceeds limit
```
- Automatic distillation will handle this
- Reduce input size for manual control

**Command Not Processed**
- Ensure `command.json` is in `council_orchestrator/` directory
- Check file permissions
- Verify JSON syntax

### Debug Mode

Set environment variable for verbose logging:
```bash
export DEBUG_ORCHESTRATOR=1
```

## ðŸ“„ License

This system embodies the principles of Cognitive Sovereignty and Resource Resilience.

---

**"The Forge is operational. The Sovereign's will be executed through the Council."** âš¡ðŸ‘‘

*Complete Modular Architecture v11.0 - Sovereign Concurrency Achieved*

--- END OF FILE council_orchestrator/README.md ---

--- START OF FILE council_orchestrator/orchestrator/main.py ---

# council_orchestrator/orchestrator/main.py
# Main entry point for the council orchestrator

import asyncio
import sys
from .app import Orchestrator

def main():
    """Main entry point for the council orchestrator."""
    # Initialize orchestrator
    orchestrator = Orchestrator()

    try:
        # Main execution loop
        asyncio.run(orchestrator.main_loop())
    except KeyboardInterrupt:
        orchestrator.logger.info("Orchestrator shutdown via keyboard interrupt")
    except Exception as e:
        orchestrator.logger.error(f"Critical orchestrator failure: {e}")
        raise

if __name__ == "__main__":
    main()

--- END OF FILE council_orchestrator/orchestrator/main.py ---

--- START OF FILE council_orchestrator/orchestrator/app.py ---

# V11.0 UPDATE: Fully modularized architecture - 2025-11-09
# council_orchestrator/orchestrator.py (v11.0 - Complete Modular Architecture) - Updated 2025-11-09
# DOCTRINE OF SOVEREIGN DEFAULT: All operations now default to anctuary-Qwen2-7B:latest:latest (Ollama)
# MNEMONIC CORTEX STATUS: Phase 1 (Parent Document Retriever) Complete, Phase 2-3 (Self-Querying + Caching) Ready
# V7.1 MANDATE: Development cycle generates both requirements AND tech design before first pause
# V7.0 MANDATE 1: Universal Distillation with accurate tiktoken measurements
# V7.0 MANDATE 2: Boolean error handling (return False) prevents state poisoning
# V7.0 MANDATE 3: Absolute failure awareness - execute_task returns False on total failure, main_loop checks result
# V6.0: Universal Distillation applied to ALL code paths (main deliberation loop)
# V5.1: Seals briefing packet injection with distillation check - no code path bypasses safety protocols
# V5.0 MANDATE 1: Tames the Rogue Sentry - only processes command*.json files
# V5.0 MANDATE 2: Grants Development Cycle memory - inherits input_artifacts from parent commands
# V5.0 MANDATE 3: Un-blinds the Distiller - correctly parses nested configuration structure
# CONFIG v4.5: Separates per-request limits (Distiller) from TPM limits (Regulator) for precise resource control
# HOTFIX v4.4: Prevents distillation deadlock by bypassing distillation when using Ollama (sovereign local engine)
# HOTFIX v4.3: Resolves UnboundLocalError by isolating engine type detection into fail-safe _get_engine_type() method
# MANDATE 1: Payload size check now evaluates FULL context (agent.messages + new prompt) before API calls
# MANDATE 2: TokenFlowRegulator enforces per-minute token limits (TPM) to prevent rate limit violations
# Maintains all v4.1 features: Protocol 104 unified interface, distillation engine, and Optical Decompression Chamber
import os
import sys
import time
import json
import re
import hashlib
import asyncio
import threading
import shutil
import subprocess
import logging
from dataclasses import dataclass, asdict
from typing import List, Dict, Any, Optional
import xxhash
from datetime import datetime
from queue import Queue as ThreadQueue
from pathlib import Path
from dotenv import load_dotenv

# --- MODULARIZATION: IMPORT MODULES ---
from .config import *
from .packets.schema import CouncilRoundPacket, seed_for, prompt_hash
from .packets.emitter import emit_packet
from .packets.aggregator import aggregate_round_events
from .gitops import execute_mechanical_git
from .events import EventManager
from .council.agent import PersonaAgent
from .council.personas import COORDINATOR, STRATEGIST, AUDITOR, SPEAKER_ORDER, get_persona_file, get_state_file, classify_response_type
from .memory.cortex import CortexManager
from .memory.cache import get_cag_data
from .sentry import CommandSentry
from .regulator import TokenFlowRegulator
from .optical import OpticalDecompressionChamber

# --- RESOURCE SOVEREIGNTY: DISTILLATION ENGINE ---
try:
    import tiktoken
    TIKTOKEN_AVAILABLE = True
except ImportError:
    TIKTOKEN_AVAILABLE = False
    print("[WARNING] tiktoken not available. Token counting will be approximate.")

# --- SOVEREIGN ENGINE INTEGRATION ---
# All engine-specific imports are removed from the orchestrator's top level.
# We now only import the triage system, which will provide a healthy engine.
# 1. Engine Selection: Engines are sourced from council_orchestrator/cognitive_engines/ directory
from .engines.monitor import select_engine
# --- END INTEGRATION ---

import sys
from pathlib import Path
# Add the parent directory to sys.path to import from scripts
sys.path.insert(0, str(Path(__file__).parent.parent))
from scripts.bootstrap_briefing_packet import main as generate_briefing_packet

# --- CONFIGURATION ---
# Moved to modular imports at top


# --- PERSONA AGENT CLASS ---
# Moved to council/agent.py

class Orchestrator:
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.command_queue = ThreadQueue()
        load_dotenv(dotenv_path=self.project_root / '.env')

        # V9.3: Initialize logging system
        self.setup_logging()
        
        # Initialize event management system
        self.event_manager = EventManager(self.project_root)
        self.event_manager.setup_event_logging()

        # Initialize mnemonic cortex
        self.cortex_manager = CortexManager(self.project_root)

        # --- RESOURCE SOVEREIGNTY: LOAD ENGINE LIMITS FROM CONFIG ---
        # v4.5: Support nested configuration structure with per_request_limit and tpm_limit
        config_path = Path(__file__).parent / "schemas" / "engine_config.json"
        if config_path.exists():
            try:
                with open(config_path, 'r') as f:
                    config = json.load(f)
                
                # Parse engine_limits - support both old flat and new nested structure
                raw_limits = config.get('engine_limits', {})
                self.engine_limits = {}
                self.tpm_limits = {}
                
                for engine_name, limit_data in raw_limits.items():
                    if isinstance(limit_data, dict):
                        # New nested structure
                        self.engine_limits[engine_name] = limit_data.get('per_request_limit', 100000)
                        self.tpm_limits[engine_name] = limit_data.get('tpm_limit', 100000)
                    else:
                        # Old flat structure (backward compatibility)
                        self.engine_limits[engine_name] = limit_data
                        self.tpm_limits[engine_name] = limit_data
                
                print(f"[+] Engine per-request limits loaded: {self.engine_limits}")
                print(f"[+] Engine TPM limits loaded: {self.tpm_limits}")
            except Exception as e:
                print(f"[!] Error loading engine config: {e}. Using defaults.")
                self.engine_limits = DEFAULT_ENGINE_LIMITS
                self.tpm_limits = DEFAULT_TPM_LIMITS
        else:
            print("[!] engine_config.json not found. Using default limits.")
            self.engine_limits = DEFAULT_ENGINE_LIMITS
            self.tpm_limits = DEFAULT_TPM_LIMITS

        self.speaker_order = SPEAKER_ORDER
        self.agents = {} # Agents will now be initialized per-task
        
        # --- MANDATE 2: INITIALIZE TOKEN FLOW REGULATOR ---
        # Use the TPM limits already parsed from config
        self.token_regulator = TokenFlowRegulator(self.tpm_limits)
        print(f"[+] Token Flow Regulator initialized with TPM limits: {self.tpm_limits}")
        
        # --- OPERATION: OPTICAL ANVIL - LAZY INITIALIZATION ---
        self.optical_chamber = None  # Initialized per-task if enabled

        # --- SENTRY THREAD INITIALIZATION ---
        # Start the command monitoring thread
        self.command_sentry = CommandSentry(self.command_queue, self.logger)
        self.sentry_thread = threading.Thread(target=self.command_sentry.watch_for_commands_thread, daemon=True)
        self.sentry_thread.start()
        print("[+] Sentry Thread started - monitoring for command files")

    def setup_logging(self):
        """V9.3: Setup comprehensive logging system with file output."""
        log_file = self.project_root / "logs" / "orchestrator.log"

        # Create logger
        self.logger = logging.getLogger('orchestrator')
        self.logger.setLevel(logging.INFO)

        # Clear any existing handlers
        self.logger.handlers.clear()

        # File handler (overwrites each session)
        file_handler = logging.FileHandler(log_file, mode='w')
        file_handler.setLevel(logging.INFO)

        # Console handler (for terminal output)
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(logging.INFO)

        # Formatter
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)

        # Add handlers
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)

        self.logger.info("=== ORCHESTRATOR v11.0 INITIALIZED ===")
        self.logger.info(f"Log file: {log_file}")
        self.logger.info("Complete Modular Architecture with Sovereign Concurrency active")




    def _calculate_response_score(self, response: str) -> float:
        """Calculate a quality score for the response (0.0-1.0)."""
        score = 0.5  # Base score

        # Length factor (responses that are too short or too long get lower scores)
        length = len(response.split())
        if 50 <= length <= 500:
            score += 0.2
        elif length < 20:
            score -= 0.3

        # Structure indicators
        if any(indicator in response.lower() for indicator in ["therefore", "however", "furthermore", "conclusion"]):
            score += 0.1

        # Evidence of reasoning
        if any(word in response.lower() for word in ["because", "due to", "based on", "considering"]):
            score += 0.1

        # Actionable content
        if any(word in response.lower() for word in ["recommend", "suggest", "propose", "should"]):
            score += 0.1

        return max(0.0, min(1.0, score))

    def _extract_vote(self, response: str) -> str:
        """Extract voting decision from response."""
        response_lower = response.lower()

        # Look for explicit votes
        if any(phrase in response_lower for phrase in ["i approve", "approved", "accept", "agree"]):
            return "approve"
        elif any(phrase in response_lower for phrase in ["i reject", "rejected", "decline", "disagree"]):
            return "reject"
        elif any(phrase in response_lower for phrase in ["revise", "modify", "change", "adjust"]):
            return "revise"
        elif any(phrase in response_lower for phrase in ["proceed", "continue", "move forward"]):
            return "proceed"

        return "neutral"

    def _assess_novelty(self, response: str, context: str) -> str:
        """Assess novelty level for memory placement hints."""
        # Simple novelty assessment based on response length vs context overlap
        response_words = set(response.lower().split())
        context_words = set(context.lower().split())

        overlap_ratio = len(response_words.intersection(context_words)) / len(response_words) if response_words else 0

        if overlap_ratio < 0.3:
            return "fast"  # High novelty - fast memory
        elif overlap_ratio > 0.7:
            return "slow"  # Low novelty - slow memory
        else:
            return "medium"  # Medium novelty

    def _extract_reasoning(self, response: str) -> list:
        """Extract key reasoning factors from response."""
        reasons = []

        # Look for common reasoning patterns
        sentences = response.split('.')
        for sentence in sentences:
            sentence = sentence.strip().lower()
            if any(word in sentence for word in ["because", "due to", "since", "as", "therefore"]):
                if len(sentence) > 10:  # Filter out very short fragments
                    reasons.append(sentence[:100] + "..." if len(sentence) > 100 else sentence)

        return reasons[:3]  # Limit to top 3 reasons

    def _extract_citations(self, response: str) -> list:
        """Extract citations or references from response."""
        citations = []

        # Look for quoted text
        import re
        quotes = re.findall(r'"([^"]*)"', response)
        citations.extend(quotes)

        # Look for file references
        file_refs = re.findall(r'\b[a-zA-Z_][a-zA-Z0-9_]*\.[a-zA-Z]+\b', response)
        citations.extend(file_refs)

        return citations[:5]  # Limit to top 5 citations

    def _get_rag_data(self, task: str, response: str) -> Dict[str, Any]:
        """Get RAG (Retrieval-Augmented Generation) data for round packet."""
        try:
            # Simulate structured query generation (Phase 2 Self-Querying)
            structured_query = {
                "entities": self._extract_entities(task),
                "date_filters": [],
                "path_filters": [".md", ".py", ".json"]
            }

            # Get parent documents (simplified - would use actual retriever)
            parent_docs = self._get_relevant_docs(task, response)

            return {
                "structured_query": structured_query,
                "parent_docs": parent_docs,
                "retrieval_latency_ms": 50  # Placeholder
            }
        except Exception as e:
            return {"error": str(e)}

    def _analyze_novelty(self, response: str, context: str) -> Dict[str, Any]:
        """Analyze novelty of response compared to context."""
        try:
            response_words = set(response.lower().split())
            context_words = set(context.lower().split())

            overlap_ratio = len(response_words.intersection(context_words)) / len(response_words) if response_words else 0

            if overlap_ratio < 0.3:
                signal = "high"
                is_novel = True
            elif overlap_ratio > 0.7:
                signal = "low"
                is_novel = False
            else:
                signal = "medium"
                is_novel = True

            return {
                "is_novel": is_novel,
                "signal": signal,
                "conflicts_with": []  # Would check against cached answers
            }
        except Exception as e:
            return {"error": str(e)}

    def _determine_memory_directive(self, response: str, citations: List[Dict[str, str]]) -> Dict[str, str]:
        """Determine memory placement directive based on response characteristics."""
        try:
            # Simple rules-based memory placement
            has_citations = len(citations) > 0
            response_length = len(response.split())
            confidence_score = self._calculate_response_score(response)

            if confidence_score > 0.8 and has_citations and response_length > 100:
                tier = "slow"
                justification = "High confidence with citations and substantial content"
            elif has_citations or response_length > 50:
                tier = "medium"
                justification = "Evidence-based response with moderate confidence"
            else:
                tier = "fast"
                justification = "Ephemeral response, low evidence requirement"

            return {
                "tier": tier,
                "justification": justification
            }
        except Exception as e:
            return {"tier": "fast", "justification": f"Error in analysis: {str(e)}"}

    def _extract_entities(self, text: str) -> List[str]:
        """Extract entities from text (simplified implementation)."""
        # Simple entity extraction - in real implementation would use NLP
        words = text.split()
        entities = []
        for word in words:
            if word.istitle() and len(word) > 3:
                entities.append(word)
        return entities[:5]

    def _get_relevant_docs(self, task: str, response: str) -> List[str]:
        """Get relevant parent documents (simplified implementation)."""
        # In real implementation, would query vector database
        # For now, return placeholder paths
        return [
            "01_PROTOCOLS/00_Prometheus_Protocol.md",
            "01_PROTOCOLS/05_Chrysalis_Protocol.md"
        ]

    def _verify_briefing_attestation(self, packet: dict) -> bool:
        """Verifies the integrity of the briefing packet using its SHA256 hash."""
        if "attestation_hash" not in packet.get("metadata", {}):
            print("[CRITICAL] Attestation hash missing from briefing packet. REJECTING.")
            return False

        stored_hash = packet["metadata"]["attestation_hash"]

        packet_for_hashing = {k: v for k, v in packet.items() if k != "metadata"}

        canonical_string = json.dumps(packet_for_hashing, sort_keys=True, separators=(',', ':'))
        calculated_hash = hashlib.sha256(canonical_string.encode('utf-8')).hexdigest()

        return stored_hash == calculated_hash

    def _enhance_briefing_with_context(self, task_description: str):
        """Parse task_description for file paths and add their contents to briefing_packet.json."""
        # Regex to find file paths containing '/' and ending with file extension
        path_pattern = r'([A-Za-z][A-Za-z0-9_]*/(?:[A-Za-z][A-ZaZ0-9_]*/)*[A-Za-z][A-Za-z0-9_]*\.[a-zA-Z0-9]+)'
        matches = re.findall(path_pattern, task_description)
        context = {}
        for match in matches:
            file_path = self.project_root / match
            if file_path.exists() and file_path.is_file():
                try:
                    content = file_path.read_text(encoding="utf-8")
                    context[match] = content
                except Exception as e:
                    print(f"[!] Error reading context file {match}: {e}")
                    raise FileNotFoundError(f"Context file {match} could not be read.")
            elif match and not file_path.exists():
                print(f"[!] Context file {match} not found.")
                raise FileNotFoundError(f"Context file {match} not found.")

        if context:
            briefing_path = self.project_root / "WORK_IN_PROGRESS/council_memory_sync/briefing_packet.json"
            if briefing_path.exists():
                packet = json.loads(briefing_path.read_text(encoding="utf-8"))
                packet["context"] = context
                briefing_path.write_text(json.dumps(packet, indent=2), encoding="utf-8")
                print(f"[+] Context from {len(context)} files added to briefing packet.")
            else:
                print("[!] briefing_packet.json not found for context enhancement.")

    def inject_briefing_packet(self, engine_type: str = "openai"):
        """Generate + inject briefing packet into all agents."""
        print("[*] Generating fresh briefing packet...")
        try:
            generate_briefing_packet()
        except Exception as e:
            print(f"[!] Error generating briefing packet: {e}")
            return

        briefing_path = self.project_root / "WORK_IN_PROGRESS/council_memory_sync/briefing_packet.json"
        if briefing_path.exists():
            try:
                packet = json.loads(briefing_path.read_text(encoding="utf-8"))
                if not self._verify_briefing_attestation(packet):
                    raise Exception("CRITICAL: Context Integrity Breach. Briefing packet failed attestation. Task aborted.")
                for agent in self.agents.values():
                    context_str = ""
                    if "context" in packet:
                        context_str = "\n\nCONTEXT PROVIDED FROM TASK DESCRIPTION:\n"
                        for path, content in packet["context"].items():
                            context_str += f"--- CONTEXT FROM {path} ---\n{content}\n--- END OF CONTEXT FROM {path} ---\n\n"
                    system_msg = (
                        "SYSTEM INSTRUCTION: You are provided with the synchronized briefing packet. "
                        "This contains temporal anchors, prior directives, and the current task context. "
                        "Incorporate this into your reasoning, but do not regurgitate it verbatim.\n\n"
                        f"BRIEFING_PACKET:\n{json.dumps({k: v for k, v in packet.items() if k != 'context'}, indent=2)}"
                        f"{context_str}"
                    )
                    # V5.1: Seal the final vulnerability - apply distillation to briefing packets
                    # The Doctrine of Universal Integrity requires ALL payloads to be checked
                    prepared_briefing = self._prepare_input_for_engine(system_msg, engine_type, "Briefing Packet Injection")
                    agent.query(prepared_briefing, self.token_regulator, engine_type)
                print(f"[+] Briefing packet injected into {len(self.agents)} agents.")
            except Exception as e:
                print(f"[!] Error injecting briefing packet: {e}")

    def archive_briefing_packet(self):
        """Archive briefing packet after deliberation completes."""
        briefing_path = self.project_root / "WORK_IN_PROGRESS/council_memory_sync/briefing_packet.json"
        if briefing_path.exists():
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            archive_dir = self.project_root / f"ARCHIVE/council_memory_sync_{timestamp}"
            archive_dir.mkdir(parents=True, exist_ok=True)
            shutil.move(str(briefing_path), archive_dir / "briefing_packet.json")

    async def _start_new_cycle(self, command, state_file):
        """Starts a new development cycle with the Doctrine of Implied Intent."""
        # Create initial state
        state = {
            "current_stage": "GENERATING_REQUIREMENTS_AND_TECH_DESIGN",
            "project_name": command.get("project_name", "unnamed_project"),
            "original_command": command,
            "approved_artifacts": {},
            "created_at": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        state_file.write_text(json.dumps(state, indent=2))

        # V7.1 MANDATE: Doctrine of Implied Intent
        # The initial command implies approval to complete the entire initial planning phase
        # Generate both requirements AND tech design before the first pause

        # V5.0 MANDATE 2: Grant the Development Cycle a Memory
        # Internal commands MUST inherit input_artifacts from the parent command
        # This prevents contextless, oversized generation that causes quota breaches
        original_config = command.get("config", {})
        requirements_command = {
            "task_description": f"Generate detailed requirements document for the project: {command['task_description']}. Include functional requirements, technical constraints, and success criteria.",
            "input_artifacts": command.get("input_artifacts", []),  # INHERIT from parent
            "output_artifact_path": f"WORK_IN_PROGRESS/development_cycles/{state['project_name']}/requirements.md",
            "config": {"max_rounds": 3, **original_config}
        }

        print(f"[*] Starting new development cycle for '{state['project_name']}' with Doctrine of Implied Intent.", flush=True)
        print(f"[*] Development cycle inheriting {len(requirements_command.get('input_artifacts', []))} input artifacts from parent command.")
        print(f"[*] Generating requirements...", flush=True)
        await self.execute_task(requirements_command)

        # V7.1: Immediately generate tech design without pausing for approval
        print(f"[*] Requirements complete. Generating technical design...", flush=True)
        tech_design_command = {
            "task_description": f"Based on the approved requirements, generate a detailed technical design document. Include architecture decisions, data flow, and implementation approach.",
            "input_artifacts": [f"WORK_IN_PROGRESS/development_cycles/{state['project_name']}/requirements.md"],
            "output_artifact_path": f"WORK_IN_PROGRESS/development_cycles/{state['project_name']}/tech_design.md",
            "config": {"max_rounds": 3, **original_config}
        }
        await self.execute_task(tech_design_command)

        # V7.1: Only now set state to awaiting approval - after both artifacts are complete
        state["current_stage"] = "AWAITING_APPROVAL_TECH_DESIGN"
        state_file.write_text(json.dumps(state, indent=2))
        print(f"[*] Technical design generated. Complete proposal ready for Guardian review.", flush=True)
        print(f"[*] Awaiting Guardian approval on comprehensive proposal (requirements + tech design).", flush=True)

    async def _advance_cycle(self, state_file):
        """Advances the development cycle to the next stage."""
        state = json.loads(state_file.read_text())

        if state["current_stage"] == "AWAITING_APPROVAL_REQUIREMENTS":
            # Ingest approved requirements into Cortex
            requirements_path = self.project_root / state["approved_artifacts"].get("requirements", "")
            if requirements_path.exists():
                # V7.1: Add file existence check before ingestion
                if requirements_path.is_file():
                    subprocess.run([sys.executable, str(self.project_root / "mnemonic_cortex" / "scripts" / "ingest.py")], check=True)
                    print(f"[*] Approved requirements ingested into Mnemonic Cortex.", flush=True)
                else:
                    print(f"[!] Requirements path is not a file: {requirements_path}. Skipping ingestion.", flush=True)

            # Move to tech design
            state["current_stage"] = "GENERATING_TECH_DESIGN"
            original_config = state["original_command"].get("config", {})
            tech_design_command = {
                "task_description": f"Based on the approved requirements, generate a detailed technical design document. Include architecture decisions, data flow, and implementation approach.",
                "input_artifacts": [state["approved_artifacts"].get("requirements", "")],
                "output_artifact_path": f"WORK_IN_PROGRESS/development_cycles/{state['project_name']}/tech_design.md",
                "config": {"max_rounds": 3, **original_config}
            }
            await self.execute_task(tech_design_command)
            state["current_stage"] = "AWAITING_APPROVAL_TECH_DESIGN"
            state_file.write_text(json.dumps(state, indent=2))
            print(f"[*] Tech design generated. Awaiting Guardian approval.", flush=True)

        elif state["current_stage"] == "AWAITING_APPROVAL_TECH_DESIGN":
            # Ingest approved tech design into Cortex
            tech_design_path = self.project_root / state["approved_artifacts"].get("tech_design", "")
            if tech_design_path.exists():
                # V7.1: Add file existence check before ingestion
                if tech_design_path.is_file():
                    subprocess.run([sys.executable, str(self.project_root / "mnemonic_cortex" / "scripts" / "ingest.py")], check=True)
                    print(f"[*] Approved tech design ingested into Mnemonic Cortex.", flush=True)
                else:
                    print(f"[!] Tech design path is not a file: {tech_design_path}. Skipping ingestion.", flush=True)

            # Move to code generation
            state["current_stage"] = "GENERATING_CODE"
            original_config = state["original_command"].get("config", {})
            code_command = {
                "task_description": f"Based on the approved technical design, generate production-ready code. Output a JSON object with 'target_file_path', 'new_content', and 'commit_message' fields.",
                "input_artifacts": [state["approved_artifacts"].get("tech_design", "")],
                "output_artifact_path": f"WORK_IN_PROGRESS/development_cycles/{state['project_name']}/code_proposal.json",
                "config": {"max_rounds": 3, **original_config}
            }
            await self.execute_task(code_command)
            state["current_stage"] = "AWAITING_APPROVAL_CODE"
            state_file.write_text(json.dumps(state, indent=2))
            print(f"[*] Code proposal generated. Awaiting Guardian approval.", flush=True)

        elif state["current_stage"] == "AWAITING_APPROVAL_CODE":
            # Final stage: propose code change
            await self._propose_code_change(state_file)

    async def _propose_code_change(self, state_file):
        """Creates a PR with the approved code changes."""
        state = json.loads(state_file.read_text())
        code_proposal_path = self.project_root / f"WORK_IN_PROGRESS/development_cycles/{state['project_name']}/code_proposal.json"

        if not code_proposal_path.exists():
            print("[!] Code proposal file not found. Cannot proceed.", flush=True)
            return

        proposal = json.loads(code_proposal_path.read_text())
        target_file = self.project_root / proposal["target_file_path"]
        new_content = proposal["new_content"]
        commit_message = proposal["commit_message"]

        # Create feature branch
        branch_name = f"feature/{state['project_name']}"
        subprocess.run(['git', 'checkout', '-b', branch_name], check=True)

        # Write the new code
        target_file.parent.mkdir(parents=True, exist_ok=True)
        target_file.write_text(new_content)

        # Commit and push
        subprocess.run(['git', 'add', str(target_file)], check=True)
        subprocess.run(['git', 'commit', '-m', commit_message], check=True)
        subprocess.run(['git', 'push', '-u', 'origin', branch_name], check=True)

        # Create PR (assuming gh CLI is available)
        pr_title = f"feat: {state['project_name']} - {commit_message}"
        subprocess.run(['gh', 'pr', 'create', '--title', pr_title, '--body', f"Auto-generated PR for {state['project_name']}"], check=True)

        print(f"[*] Pull request created for '{state['project_name']}'. Development cycle complete.", flush=True)

        # Clean up state file
        state_file.unlink()

    def _handle_knowledge_request(self, response_text: str):
        """Handles knowledge requests from agents, including Cortex queries."""
        file_match = re.search(r"\[ORCHESTRATOR_REQUEST: READ_FILE\((.*?)\)\]", response_text)
        query_match = re.search(r"\[ORCHESTRATOR_REQUEST: QUERY_CORTEX\((.*?)\)\]", response_text)

        if file_match:
            # Existing file reading logic
            file_path_str = file_match.group(1).strip().strip('"')
            file_path = self.project_root / file_path_str
            if file_path.exists():
                content = file_path.read_text(encoding="utf-8")
                return f"CONTEXT_PROVIDED: Here is the content of {file_path_str}:\n\n{content}"
            else:
                return f"CONTEXT_ERROR: File not found: {file_path_str}"

        elif query_match:
            # NEW LOGIC for Cortex queries
            query_text = query_match.group(1).strip().strip('"')

            # Check against query limit
            if self.cortex_query_count >= self.max_cortex_queries:
                error_message = f"CONTEXT_ERROR: Maximum Cortex query limit of {self.max_cortex_queries} has been reached for this task."
                print(f"[ORCHESTRATOR] {error_message}", flush=True)
                return error_message

            self.cortex_query_count += 1
            print(f"[ORCHESTRATOR] Agent requested Cortex query: '{query_text}' ({self.cortex_query_count}/{self.max_cortex_queries})", flush=True)

            try:
                context = self.cortex_manager.query_cortex(query_text, n_results=3)
                return context
            except Exception as e:
                error_message = f"CONTEXT_ERROR: Cortex query failed: {e}"
                print(f"[ORCHESTRATOR] {error_message}", flush=True)
                return error_message

        return None

    async def generate_aar(self, completed_task_log_path: Path, original_command_config: dict = None):
        """Generates a structured AAR from a completed task log, inheriting config from the original command."""
        if not completed_task_log_path.exists():
            print(f"[!] AAR WARNING: Log file not found at {completed_task_log_path}. Skipping AAR generation.", flush=True)
            return

        timestamp = time.strftime("%Y%m%d_%H%M%S")
        aar_output_path = self.project_root / f"MNEMONIC_SYNTHESIS/AAR/aar_{completed_task_log_path.stem}_{timestamp}.md"

        # --- RESOURCE SOVEREIGNTY: INHERIT CONFIG FROM ORIGINAL COMMAND ---
        # AAR generation must use the same resilient substrate as the task itself
        aar_config = {"max_rounds": 2}  # Base config
        if original_command_config:
            # Inherit force_engine and other critical parameters
            if "force_engine" in original_command_config:
                aar_config["force_engine"] = original_command_config["force_engine"]
                print(f"[*] AAR inheriting force_engine: {original_command_config['force_engine']}")
            if "max_cortex_queries" in original_command_config:
                aar_config["max_cortex_queries"] = original_command_config["max_cortex_queries"]

        aar_command = {
            "task_description": "Synthesize a structured After-Action Report (AAR) from the attached task log. Sections: Objective, Outcome, Key Learnings, Mnemonic Impact.",
            "input_artifacts": [str(completed_task_log_path.relative_to(self.project_root))],
            "output_artifact_path": str(aar_output_path.relative_to(self.project_root)),
            "config": aar_config
        }
        print(f"[*] AAR Command forged. Output will be saved to {aar_output_path.name}", flush=True)

        # V9.2 DOCTRINE OF SOVEREIGN CONCURRENCY: Execute AAR in background thread
        # This allows mechanical tasks to be processed immediately without waiting for learning cycle
        import asyncio
        aar_task = asyncio.create_task(self._execute_aar_background(aar_command, aar_output_path))
        print(f"[*] AAR task dispatched to background processing (non-blocking)", flush=True)

    async def _execute_aar_background_full(self, log_file_path, original_config):
        """V9.3: Execute complete AAR generation and ingestion asynchronously."""
        try:
            self.logger.info(f"Background AAR: Starting synthesis for {log_file_path}")

            # Generate AAR using existing logic but asynchronously
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            aar_output_path = self.project_root / f"MNEMONIC_SYNTHESIS/AAR/aar_{log_file_path.stem}_{timestamp}.md"

            # Create AAR command
            aar_config = {"max_rounds": 2}
            if original_config:
                if "force_engine" in original_config:
                    aar_config["force_engine"] = original_config["force_engine"]
                if "max_cortex_queries" in original_config:
                    aar_config["max_cortex_queries"] = original_config["max_cortex_queries"]

            aar_command = {
                "task_description": "Synthesize a structured After-Action Report (AAR) from the attached task log. Sections: Objective, Outcome, Key Learnings, Mnemonic Impact.",
                "input_artifacts": [str(log_file_path.relative_to(self.project_root))],
                "output_artifact_path": str(aar_output_path.relative_to(self.project_root)),
                "config": aar_config
            }

            # Execute AAR task
            await self.execute_task(aar_command)
            self.logger.info(f"Background AAR: Synthesis complete - {aar_output_path}")

            # Ingest into Mnemonic Cortex
            self.logger.info("Background AAR: Starting ingestion into Mnemonic Cortex...")
            ingestion_script_path = self.project_root / "mnemonic_cortex" / "scripts" / "ingest.py"
            full_aar_path = self.project_root / aar_output_path

            result = await asyncio.create_subprocess_exec(
                sys.executable, str(ingestion_script_path), str(full_aar_path),
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                cwd=self.project_root
            )

            stdout, stderr = await result.communicate()

            if result.returncode == 0:
                self.logger.info("Background AAR: Ingestion successful")
                self.logger.info(f"Ingestion output: {stdout.decode().strip()}")
            else:
                self.logger.error(f"Background AAR: Ingestion failed - {stderr.decode().strip()}")

        except Exception as e:
            self.logger.error(f"Background AAR: Processing failed - {e}")

    def _get_token_count(self, text: str, engine_type: str = "openai"):
        """Estimates token count for a given text and engine type."""
        if TIKTOKEN_AVAILABLE:
            try:
                # Map engine types to tiktoken models
                model_map = {
                    'openai': 'gpt-4',
                    'gemini': 'gpt-4',  # Approximation
                    'ollama': 'gpt-4'   # Approximation
                }
                model = model_map.get(engine_type, 'gpt-4')
                encoding = tiktoken.encoding_for_model(model)
                return len(encoding.encode(text))
            except Exception as e:
                print(f"[WARNING] Token counting failed: {e}. Using approximation.")
                return len(text.split()) * 1.3  # Rough approximation
        else:
            # Fallback approximation: ~1.3 tokens per word
            return len(text.split()) * 1.3

    def _distill_with_local_engine(self, large_text: str, task_description: str) -> str:
        """Uses the local Ollama engine to summarize large text before sending to primary engine."""
        print("[ORCHESTRATOR] Input exceeds token limit. Distilling with local Ollama engine...")

        # Create a temporary Ollama engine for distillation
        # 4. Distillation Engine: Uses council_orchestrator/cognitive_engines/ollama_engine.py
        from .engines.monitor import select_engine
        local_config = {"force_engine": "ollama"}
        local_engine = select_engine(local_config)

        if not local_engine:
            print("[ERROR] Could not initialize local distillation engine. Truncating input.")
            return large_text[:40000] + "\n\n[CONTENT TRUNCATED DUE TO TOKEN LIMITS]"

        # Create temporary agent for distillation - use the engine directly without PersonaAgent wrapper
        distillation_prompt = (
            f"You are a distillation specialist. The following text is too large for the target AI engine. "
            f"Your task is to distill it into a token-frugal, high-potency summary that preserves all critical details, "
            f"code blocks, structural context, and actionable information. The ultimate goal is: '{task_description}'. "
            f"Keep the summary under 5000 tokens while maintaining complete fidelity to the original intent.\n\n"
            f"Raw Text:\n\n---\n{large_text}\n---"
        )

        try:
            # Use engine directly with unified interface
            messages = [{"role": "user", "content": distillation_prompt}]
            distilled_summary = local_engine.execute_turn(messages)
            print("[ORCHESTRATOR] Distillation complete.")
            return distilled_summary
        except Exception as e:
            print(f"[ERROR] Distillation failed: {e}. Truncating input.")
            return large_text[:40000] + "\n\n[CONTENT TRUNCATED DUE TO DISTILLATION FAILURE]"

    def _prepare_input_for_engine(self, text: str, engine_type: str, task_description: str) -> str:
        """Checks token count and distills if necessary using the Two-Tier Distillation Engine."""

        # --- V4.4 DEADLOCK BYPASS ---
        # The sovereign local engine (Ollama) is not subject to token limits or financial constraints.
        # Attempting to distill with Ollama for Ollama creates a resource deadlock.
        # Bypass all distillation logic when the target engine is our local substrate.
        if engine_type == 'ollama':
            print(f"[ORCHESTRATOR] Using sovereign local engine (Ollama). Bypassing distillation - full context preserved.")
            return text

        # --- V5.0 MANDATE 3: UN-BLIND THE DISTILLER ---
        # The Distiller must read the hardened, nested configuration structure.
        # Previous logic: limit = self.engine_limits.get(engine_type, 100000) was incorrect.
        # Correct logic: Parse the nested structure for per_request_limit.
        engine_config = self.engine_limits.get(engine_type, {})
        if isinstance(engine_config, dict):
            limit = engine_config.get('per_request_limit', 100000)
        else:
            # Backward compatibility for flat structure
            limit = engine_config

        # --- STANDARD DISTILLATION LOGIC FOR EXTERNAL SUBSTRATES ---
        token_count = self._get_token_count(text, engine_type)

        if token_count > limit:
            print(f"[ORCHESTRATOR] WARNING: Token count ({token_count:.0f}) exceeds per-request limit for {engine_type} ({limit}).")
            return self._distill_with_local_engine(text, task_description)
        else:
            return text
    
    def _get_engine_type(self, engine) -> str:
        """
        Determine the engine type from an engine instance.
        This is a fail-safe method that always returns a valid engine type.

        Args:
            engine: The cognitive engine instance

        Returns:
            str: The engine type ('openai', 'gemini', 'ollama', or 'unknown')
        """
        if not engine or not hasattr(engine, '__class__'):
            return "unknown"

        engine_name = type(engine).__name__.lower()

        if "openai" in engine_name:
            return "openai"
        elif "gemini" in engine_name:
            return "gemini"
        elif "ollama" in engine_name:
            return "ollama"
        else:
            return "unknown"

    def _execute_mechanical_write(self, command):
        """
        Execute a mechanical write task - directly write content to a file.
        This bypasses cognitive deliberation for simple file operations.

        Args:
            command: Command dictionary containing 'entry_content' and 'output_artifact_path'
        """
        try:
            # Extract parameters
            content = command["entry_content"]
            output_path_str = command["output_artifact_path"]
            output_path = self.project_root / output_path_str

            # Ensure output directory exists
            output_path.parent.mkdir(parents=True, exist_ok=True)

            # Write content directly to file
            output_path.write_text(content, encoding="utf-8")

            print(f"[MECHANICAL SUCCESS] File written to {output_path}")
            print(f"[MECHANICAL SUCCESS] Content length: {len(content)} characters")

        except Exception as e:
            print(f"[MECHANICAL FAILURE] Write operation failed: {e}")
            raise

    async def _execute_query_and_synthesis(self, command):
        """
        Execute a Guardian Mnemonic Synchronization Protocol query and synthesis task.

        Args:
            command: Command dictionary containing 'git_operations' with files_to_add, commit_message, push_to_origin
        """
        # DOCTRINE OF THE BLUNTED SWORD: Hardcoded whitelist of permitted Git commands

    async def _execute_query_and_synthesis(self, command):
        """
        Execute a Guardian Mnemonic Synchronization Protocol query and synthesis task.
        This invokes the Council to facilitate mnemonic cortex queries and produce synthesis.

        Args:
            command: Command dictionary containing 'task_description' and 'output_artifact_path'
        """
        try:
            # Extract parameters
            task_description = command.get('task_description', 'Mnemonic synchronization query')
            output_path_str = command['output_artifact_path']
            output_path = self.project_root / output_path_str

            # Ensure output directory exists
            output_path.parent.mkdir(parents=True, exist_ok=True)

            print(f"[MNEMONIC SYNC] Starting query and synthesis task: {task_description}")

            # Select cognitive engine for this synchronization task
            # DOCTRINE OF SOVEREIGN DEFAULT: Default to our sovereign substrate
            default_config = {"force_engine": "ollama", "model_name": "Sanctuary-Qwen2-7B:latest"}
            task_config = command.get("config", default_config)
            engine = select_engine(task_config)
            if not engine:
                print(f"[MNEMONIC SYNC HALTED] No healthy cognitive substrate available for synchronization.")
                return False

            # Initialize agents with selected engine
            self._initialize_agents(engine)

            # Initialize optical chamber if configured
            self._initialize_optical_chamber(command.get('config', {}))

            # Enhance briefing with mnemonic context
            try:
                self._enhance_briefing_with_context(task_description)
            except FileNotFoundError as e:
                print(f"[MNEMONIC SYNC WARNING] Context file error: {e}. Proceeding with base briefing.")

            # Inject briefing context
            engine_type = self._get_engine_type(engine)
            self.inject_briefing_packet(engine_type)

            # Execute simplified Council deliberation for mnemonic synchronization
            max_rounds = command.get('config', {}).get('max_rounds', 3)  # Shorter for sync tasks
            log = [f"# Guardian Mnemonic Synchronization Log\n## Task: {task_description}\n\n"]
            last_message = task_description

            print(f"[MNEMONIC SYNC] Invoking Council for mnemonic synchronization ({max_rounds} rounds max)")

            consecutive_failures = 0
            synthesis_produced = False

            for round_num in range(max_rounds):
                print(f"[MNEMONIC SYNC] Round {round_num + 1}/{max_rounds}")
                log.append(f"### Round {round_num + 1}\n\n")

                round_failures = 0

                for role in self.speaker_order:
                    agent = self.agents[role]
                    print(f"[MNEMONIC SYNC] Consulting {agent.role}...")

                    prompt = f"Mnemonic Synchronization Context: '{last_message}'. As the {role}, provide your analysis for bridging mnemonic gaps and producing synthesis."

                    try:
                        # Check token limits before API call
                        potential_payload = agent.messages + [{"role": "user", "content": prompt}]
                        payload_as_text = json.dumps(potential_payload)
                        token_count = self._get_token_count(payload_as_text, engine_type)
                        limit = self.engine_limits.get(engine_type, 100000)

                        if token_count > limit:
                            print(f"[MNEMONIC SYNC] Token limit exceeded ({token_count}/{limit}), truncating context...")
                            # Simple truncation approach for mnemonic sync - keep most recent messages
                            while agent.messages and token_count > limit:
                                removed_msg = agent.messages.pop(0)  # Remove oldest message
                                payload_as_text = json.dumps(agent.messages + [{"role": "user", "content": prompt}])
                                token_count = self._get_token_count(payload_as_text, engine_type)

                        # Get agent response
                        response = await agent.get_response(prompt)
                        last_message = response

                        log.append(f"**{role}**: {response}\n\n")

                        # Check for synthesis indicators
                        if "synthesis" in response.lower() or "bridge" in response.lower() or "mnemonic" in response.lower():
                            synthesis_produced = True

                        print(f"[MNEMONIC SYNC] {role} response received ({len(response)} chars)")

                    except Exception as e:
                        round_failures += 1
                        consecutive_failures += 1
                        print(f"[MNEMONIC SYNC ERROR] {role} failed: {e}")
                        log.append(f"**{role}**: [ERROR] {str(e)}\n\n")

                        if consecutive_failures >= 3:
                            print("[MNEMONIC SYNC HALTED] Three consecutive failures - aborting synchronization")
                            break

                if consecutive_failures >= 3:
                    break

                # Early exit if synthesis appears complete
                if synthesis_produced and round_num >= 1:  # At least 2 rounds for meaningful synthesis
                    print("[MNEMONIC SYNC] Synthesis appears complete, concluding deliberation")
                    break

            # Write synthesis to output artifact
            final_log = "".join(log)
            output_path.write_text(final_log, encoding="utf-8")

            print(f"[MNEMONIC SYNC SUCCESS] Synthesis written to {output_path}")
            print(f"[MNEMONIC SYNC SUCCESS] Log length: {len(final_log)} characters")

            return True

        except Exception as e:
            print(f"[MNEMONIC SYNC FAILURE] Query and synthesis failed: {e}")
            return False
    
    def _initialize_optical_chamber(self, config: dict):
        """
        Initialize optical compression if enabled in task configuration.
        Implements lazy initialization pattern per Section 3.1 of feasibility study.
        
        Args:
            config: Task configuration dictionary
        """
        if config.get("enable_optical_compression", False):
            compression_threshold = config.get("optical_compression_threshold", 8000)
            vlm_engine_type = config.get("vlm_engine", "mock")
            
            # MOCK: In production, this would select actual VLM engine
            # vlm_engine = self._select_vlm_engine(config)
            vlm_engine = None  # Mocked for v4.1
            
            self.optical_chamber = OpticalDecompressionChamber(
                vlm_engine=vlm_engine,
                compression_threshold=compression_threshold
            )
            print(f"[+] Optical Decompression Chamber initialized (threshold: {compression_threshold} tokens)")
            print(f"[+] VLM Engine: {vlm_engine_type} (MOCKED in v4.1)")
        else:
            self.optical_chamber = None

    def _initialize_agents(self, engine):
        """Initializes agents with a given engine, allowing for per-task engine selection."""
        print(f"[*] Initializing council agents with selected engine: {type(engine).__name__}")
        persona_dir = self.project_root / "dataset_package"
        state_dir = Path(__file__).parent / "session_states"
        state_dir.mkdir(exist_ok=True)

        self.agents = {
            COORDINATOR: PersonaAgent(engine, get_persona_file(COORDINATOR, persona_dir), get_state_file(COORDINATOR, state_dir)),
            STRATEGIST: PersonaAgent(engine, get_persona_file(STRATEGIST, persona_dir), get_state_file(STRATEGIST, state_dir)),
            AUDITOR: PersonaAgent(engine, get_persona_file(AUDITOR, persona_dir), get_state_file(AUDITOR, state_dir))
        }

    async def execute_task(self, command):
        """The main task execution logic."""

        print(f"[ORCHESTRATOR] DEBUG: execute_task called with command: {command}")
        print(f"[ORCHESTRATOR] DEBUG: command.get('config'): {command.get('config')}")

        # --- SOVEREIGN OVERRIDE INTEGRATION ---
        # The engine is now selected at the start of each task, using the task's config.
        # 3. Orchestrator.execute_task(): Engine selection uses council_orchestrator/cognitive_engines/ (OpenAI, Gemini, Ollama)
        # DOCTRINE OF SOVEREIGN DEFAULT: Default to our sovereign substrate
        default_config = {"force_engine": "ollama", "model_name": "Sanctuary-Qwen2-7B:latest"}
        task_config = command.get("config", default_config)
        engine = select_engine(task_config)

        # IMPLEMENT ENGINE SELECTION FALLBACK: If forced engine fails, try automatic selection
        if not engine:
            if task_config.get("force_engine"):
                print(f"[ENGINE FALLBACK] Forced engine '{task_config['force_engine']}' failed. Attempting automatic engine selection...")
                # Remove force_engine to allow automatic selection
                fallback_config = task_config.copy()
                del fallback_config["force_engine"]
                engine = select_engine(fallback_config)
                if engine:
                    print(f"[ENGINE FALLBACK] SUCCESS: Automatic selection chose {type(engine).__name__}")
                else:
                    print("[ENGINE FALLBACK] CRITICAL FAILURE: Automatic engine selection also failed.")

            if not engine:
                print(f"[ORCHESTRATOR HALTED] No healthy cognitive substrate could be selected for this task. Config: {command.get('config')}")
                print("[ORCHESTRATOR HALTED] This may indicate all engines are unhealthy.")
                return

        # Initialize agents with the selected engine for this task.
        self._initialize_agents(engine)
        # --- END INTEGRATION ---

        # Store original engine for fallback logic
        original_engine = engine
        original_engine_type = self._get_engine_type(engine)

        # Track if we've switched to fallback mode
        fallback_mode = False
        
        # --- OPERATION: OPTICAL ANVIL - INITIALIZE OPTICAL CHAMBER ---
        # Initialize optical compression if enabled (Section 3.1 of feasibility study)
        self._initialize_optical_chamber(command.get('config', {}))
        # --- END OPTICAL ANVIL INTEGRATION ---

        task = command['task_description']
        max_rounds = command.get('config', {}).get('max_rounds', 5)
        self.max_cortex_queries = command.get('config', {}).get('max_cortex_queries', 5)
        self.cortex_query_count = 0
        output_artifact_path_str = command['output_artifact_path']
        output_path = self.project_root / output_artifact_path_str
        if output_artifact_path_str.endswith('/'):
            output_path = output_path / "task_log.md"

        # --- STRUCTURED EVENT LOGGING: TASK START ---
        self.event_manager.emit_event(
            "task_start",
            task_description=task,
            max_rounds=max_rounds,
            engine_type=original_engine_type,
            output_artifact=output_artifact_path_str,
            input_artifacts=command.get('input_artifacts', [])
        )

        log = [f"# Autonomous Triad Task Log\n## Task: {task}\n\n"]
        last_message = task

        # --- HOTFIX v4.3: ROBUST ENGINE TYPE DETERMINATION ---
        # CRITICAL: Determine engine type BEFORE any operations that need it
        engine_type = self._get_engine_type(engine)
        
        # Fail-fast if engine type cannot be determined
        if engine_type == "unknown":
            error_msg = f"[ORCHESTRATOR HALTED] Could not determine a valid engine type for the selected engine: {type(engine).__name__}"
            print(error_msg)
            raise ValueError(error_msg)

        # Enhance briefing with context from task description
        try:
            self._enhance_briefing_with_context(task)
        except FileNotFoundError as e:
            print(f"[WARNING] Context file error: {e}. Proceeding with base briefing.")

        # Inject fresh briefing context (now engine_type is defined)
        self.inject_briefing_packet(engine_type)

        if command.get('input_artifacts'):
            # ... (knowledge injection logic is the same)
            knowledge = ["Initial knowledge provided:\n"]
            for path_str in command['input_artifacts']:
                file_path = self.project_root / path_str
                if file_path.exists() and file_path.is_file():
                    knowledge.append(f"--- CONTENT OF {path_str} ---\n{file_path.read_text()}\n---\n")
                elif file_path.exists() and file_path.is_dir():
                    print(f"[!] Input artifact {path_str} is a directory, skipping.")
                else:
                    print(f"[!] Input artifact {path_str} not found.")
            last_message += "\n" + "".join(knowledge)

        print(f"\nâ–¶ï¸  Executing task: '{task}' for up to {max_rounds} rounds on {type(engine).__name__}")
        print(f"[ORCHESTRATOR] Using engine: {type(engine).__name__} (type: {engine_type}) for all agents in this task.")

        # V6.0 MANDATE 3: Initialize failure state awareness
        consecutive_failures = 0
        num_agents = len(self.speaker_order)

        loop = asyncio.get_event_loop()
        for i in range(max_rounds):
            print(f"--- ROUND {i+1} ---", flush=True)
            log.append(f"### ROUND {i+1}\n\n")

            round_failures = 0  # Track failures in this round
            round_packets = []  # Collect packets for predictable ordering

            for role in self.speaker_order:
                agent = self.agents[role]
                print(f"  -> Orchestrator to {agent.role}...", flush=True)

                prompt = f"The current state of the discussion is: '{last_message}'. As the {role}, provide your analysis or next step."

                # --- V6.0 MANDATE 1: UNIVERSAL DISTILLATION ---
                # Apply the same distillation logic to the main deliberation loop
                # Check the FULL potential payload (agent.messages + new prompt) BEFORE any API call
                potential_payload = agent.messages + [{"role": "user", "content": prompt}]
                payload_as_text = json.dumps(potential_payload)
                token_count = self._get_token_count(payload_as_text, engine_type)
                limit = self.engine_limits.get(engine_type, 100000)

                # Determine if we need distillation or optical compression
                needs_compression = token_count > limit

                if needs_compression:
                    print(f"[ORCHESTRATOR] WARNING: Full payload ({token_count:.0f} tokens) exceeds limit for {engine_type} ({limit})")

                    # --- // OPERATION: OPTICAL ANVIL - OPTICAL COMPRESSION DECISION POINT // ---
                    if self.optical_chamber and self.optical_chamber.should_compress(payload_as_text, engine_type):
                        print(f"[OPTICAL] Compressing payload for {role} (estimated 10x reduction)")

                        # Compress via optical chamber
                        decompressed_prompt = self.optical_chamber.compress_and_decompress(
                            payload_as_text,
                            task_context=task
                        )

                        # Clear agent history and send compressed context
                        agent.messages = [
                            agent.messages[0],  # Preserve system prompt
                            {"role": "user", "content": "SYSTEM NOTE: Context was optically compressed. Proceed based on decompressed data."},
                            {"role": "assistant", "content": "Acknowledged. Proceeding with optically decompressed context."}
                        ]
                        prompt_to_send = decompressed_prompt
                    else:
                        # Fallback to standard distillation
                        print(f"[ORCHESTRATOR] Using distillation engine for payload reduction...")
                        distilled_summary = self._distill_with_local_engine(payload_as_text, task)

                        # Clear agent history and send distilled context
                        agent.messages = [
                            agent.messages[0],  # Preserve system prompt
                            {"role": "user", "content": "SYSTEM NOTE: Context was distilled due to size. Proceed based on this summary."},
                            {"role": "assistant", "content": "Acknowledged. Proceeding with distilled context."}
                        ]
                        prompt_to_send = distilled_summary
                else:
                    # Payload is within limits, send normally
                    prompt_to_send = prompt

                # --- STRUCTURED EVENT LOGGING: MEMBER RESPONSE START ---
                member_start_time = time.time()
                input_tokens = self._get_token_count(prompt_to_send, engine_type)

                # --- FAULT ISOLATION: TIMEOUT PROTECTION ---
                timeout_seconds = command.get('config', {}).get('agent_timeout', 120)  # Default 2 minutes
                try:
                    # Execute query with TPM-aware rate limiting, timeout protection, and fallback logic
                    response = await asyncio.wait_for(
                        loop.run_in_executor(
                            None,
                            agent.query,
                            prompt_to_send,
                            self.token_regulator,
                            engine_type
                        ),
                        timeout=timeout_seconds
                    )
                except asyncio.TimeoutError:
                    print(f"  <- {agent.role} TIMEOUT (>{timeout_seconds}s)")
                    response = False
                    timeout_error = f"agent_timeout_exceeded_{timeout_seconds}s"

                # Calculate latency and output tokens
                latency_ms = int((time.time() - member_start_time) * 1000)
                output_tokens = self._get_token_count(response, engine_type) if response else 0

                # V7.0 MANDATE 3: Check for boolean failure response
                if response is False:
                    round_failures += 1
                    consecutive_failures += 1
                    error_type = getattr(self, 'timeout_error', "cognitive_substrate_failure") if hasattr(self, 'timeout_error') else "cognitive_substrate_failure"
                    if 'timeout_error' in locals():
                        error_type = timeout_error
                        del timeout_error  # Clean up
                    
                    print(f"  <- {agent.role} FAILED ({error_type})")

                    # --- STRUCTURED EVENT LOGGING: MEMBER RESPONSE FAILURE ---
                    self.event_manager.emit_event(
                        "member_response",
                        round=i+1,
                        member_id=role.lower(),
                        role=agent.role,
                        status="error",
                        latency_ms=latency_ms,
                        tokens_in=input_tokens,
                        tokens_out=0,
                        result_type="error",
                        errors=[error_type],
                        content_ref=f"round_{i+1}_{role.lower()}_failed"
                    )

                    # IMPLEMENT FALLBACK: If primary engine fails, try fallback to Ollama
                    if not fallback_mode and original_engine_type != "ollama":
                        print(f"[FALLBACK] Primary engine ({original_engine_type}) failed. Attempting fallback to Ollama...")
                        # Try Ollama as fallback
                        fallback_config = {"force_engine": "ollama"}
                        fallback_engine = select_engine(fallback_config)
                        if fallback_engine:
                            print(f"[FALLBACK] Switching to Ollama engine for remaining agents")
                            # Re-initialize agents with fallback engine
                            self._initialize_agents(fallback_engine)
                            engine = fallback_engine
                            engine_type = "ollama"
                            fallback_mode = True
                            # Reset consecutive failures for this round
                            consecutive_failures = 0
                            round_failures -= 1
                            # Retry this agent with fallback engine
                            response = await loop.run_in_executor(
                                None,
                                agent.query,
                                prompt_to_send,
                                self.token_regulator,
                                engine_type
                            )
                            if response is False:
                                print(f"  <- {agent.role} FAILED (fallback engine also failed)")
                                consecutive_failures += 1
                                round_failures += 1
                            else:
                                print(f"  <- {agent.role} SUCCESS (fallback engine)")
                        else:
                            print(f"[FALLBACK] No fallback engine available")

                    if response is False:  # Still failed after fallback attempt
                        # Create packet for failed response
                        failed_packet = CouncilRoundPacket(
                            timestamp=datetime.now().isoformat(),
                            session_id=self.run_id,
                            round_id=i+1,
                            member_id=role.lower(),
                            engine=engine_type,
                            seed=seed_for(self.run_id, i+1, role.lower()),
                            prompt_hash=prompt_hash(prompt_to_send),
                            inputs={"prompt": prompt_to_send, "context": last_message},
                            decision="error",
                            rationale="",
                            confidence=0.0,
                            citations=[],
                            rag={},
                            cag={},
                            novelty={},
                            memory_directive={"tier": "none"},
                            cost={
                                "input_tokens": input_tokens,
                                "output_tokens": 0,
                                "latency_ms": latency_ms
                            },
                            errors=[error_type]
                        )
                        # Collect failed packet for predictable ordering
                        jsonl_dir = getattr(self, 'cli_config', {}).get('jsonl_path') if getattr(self, 'cli_config', {}).get('emit_jsonl') else None
                        stream_stdout = getattr(self, 'cli_config', {}).get('stream_stdout', False)
                        round_packets.append((failed_packet, jsonl_dir, stream_stdout))

                        log.append(f"**{agent.role} (FAILED):** Cognitive substrate failure.\n\n---\n")
                else:
                    # Successful response - reset consecutive failure counter
                    consecutive_failures = 0
                    print(f"  <- {agent.role} to Orchestrator.", flush=True)

                    # --- STRUCTURED EVENT LOGGING: ANALYZE RESPONSE FOR METADATA ---
                    # Extract metadata from response for structured logging
                    result_type = classify_response_type(response, role)
                    score = self._calculate_response_score(response)
                    vote = self._extract_vote(response)
                    novelty = self._assess_novelty(response, last_message)
                    reasons = self._extract_reasoning(response)
                    citations = self._extract_citations(response)

                    # --- ROUND PACKET EMISSION ---
                    # Create comprehensive round packet
                    packet = CouncilRoundPacket(
                        timestamp=datetime.now().isoformat(),
                        session_id=self.run_id,
                        round_id=i+1,
                        member_id=role.lower(),
                        engine=engine_type,
                        seed=seed_for(self.run_id, i+1, role.lower()),
                        prompt_hash=prompt_hash(prompt_to_send),
                        inputs={"prompt": prompt_to_send, "context": last_message},
                        decision=vote,
                        rationale=response,
                        confidence=score,
                        citations=citations,
                        rag=self._get_rag_data(task, response),
                        cag=self._get_cag_data(prompt_to_send, engine_type),
                        novelty=self._analyze_novelty(response, last_message),
                        memory_directive=self._determine_memory_directive(response, citations),
                        cost={
                            "input_tokens": input_tokens,
                            "output_tokens": output_tokens,
                            "latency_ms": latency_ms
                        },
                        errors=[]
                    )

                    # Emit packet
                    jsonl_dir = getattr(self, 'cli_config', {}).get('jsonl_path') if getattr(self, 'cli_config', {}).get('emit_jsonl') else None
                    stream_stdout = getattr(self, 'cli_config', {}).get('stream_stdout', False)
                    # Collect packet for predictable ordering (emit at end of round)
                    round_packets.append((packet, jsonl_dir, stream_stdout))

                    # --- STRUCTURED EVENT LOGGING: MEMBER RESPONSE SUCCESS ---
                    self.event_manager.emit_event(
                        "member_response",
                        round=i+1,
                        member_id=role.lower(),
                        role=agent.role,
                        status="success",
                        latency_ms=latency_ms,
                        tokens_in=input_tokens,
                        tokens_out=output_tokens,
                        result_type=result_type,
                        score=score,
                        vote=vote,
                        novelty=novelty,
                        reasons=reasons,
                        citations=citations,
                        content_ref=f"round_{i+1}_{role.lower()}_response"
                    )

                    # V9.3 ENHANCEMENT: Display agent response content in real-time for debugging
                    print(f"\n[{agent.role} RESPONSE - ROUND {i+1}]")
                    # Truncate very long responses for terminal readability
                    display_response = response[:2000] + "..." if len(response) > 2000 else response
                    print(display_response)
                    print(f"[END {agent.role} RESPONSE]\n", flush=True)

                    # Handle knowledge requests (only if response was successful)
                    knowledge_response = self._handle_knowledge_request(response)
                    if knowledge_response:
                        # V9.3 ENHANCEMENT: Display knowledge request interaction
                        print(f"[ORCHESTRATOR] Fulfilling knowledge request for {agent.role}...", flush=True)
                        print(f"[KNOWLEDGE REQUEST RESPONSE]")
                        display_knowledge = knowledge_response[:1500] + "..." if len(knowledge_response) > 1500 else knowledge_response
                        print(display_knowledge)
                        print(f"[END KNOWLEDGE RESPONSE]\n", flush=True)

                        # Inject the knowledge response back into the conversation
                        print(f"  -> Orchestrator providing context to {agent.role}...", flush=True)
                        knowledge_injection = await loop.run_in_executor(
                            None,
                            agent.query,
                            knowledge_response,
                            self.token_regulator,
                            engine_type
                        )
                        
                        # Check if knowledge injection also failed
                        if knowledge_injection is False:
                            print(f"  <- {agent.role} FAILED during knowledge injection")
                            consecutive_failures += 1
                        else:
                            print(f"  <- {agent.role} acknowledging context.", flush=True)
                            response += f"\n\n{knowledge_injection}"
                            log.append(f"**{agent.role}:**\n{response}\n\n---\n")
                            log.append(f"**ORCHESTRATOR (Fulfilled Request):**\n{knowledge_response}\n\n---\n")
                    else:
                        log.append(f"**{agent.role}:**\n{response}\n\n---\n")

                # V7.0 MANDATE 3: Check for total operational failure after each agent
                # If all agents in a round fail, break immediately
                if consecutive_failures >= num_agents:
                    print(f"[ORCHESTRATOR] CRITICAL: {consecutive_failures} consecutive agent failures detected.")
                    print(f"[ORCHESTRATOR] Total operational failure. Terminating task.")
                    log.append(f"\n**SYSTEM FAILURE:** Task terminated due to {consecutive_failures} consecutive agent failures.\n\n")
                    break

                last_message = response

                # --- ADD THIS LINE ---
                time.sleep(1) # Add a 1-second pause to be kind to the API
                # ---------------------

            # Sort and emit packets in predictable order (by round_id, then member_id)
            round_packets.sort(key=lambda x: (x[0].round_id, x[0].member_id))
            for packet, jsonl_dir, stream_stdout in round_packets:
                emit_packet(packet, jsonl_dir, stream_stdout, str(Path(__file__).parent / "schemas" / "round_packet_schema.json"))

            # --- STRUCTURED EVENT LOGGING: ROUND COMPLETION ---
            round_aggregation = aggregate_round_events(self.event_manager.run_id, i+1, self.event_manager.event_log_path)
            self.event_manager.emit_event(
                "round_complete",
                round=i+1,
                total_members=round_aggregation.get("total_members", 0),
                success_rate=round_aggregation.get("success_rate", 0.0),
                consensus=round_aggregation.get("consensus", False),
                early_exit=round_aggregation.get("early_exit", False),
                exit_reason=round_aggregation.get("exit_reason"),
                avg_latency=round_aggregation.get("avg_latency", 0),
                total_tokens_in=round_aggregation.get("total_tokens_in", 0),
                total_tokens_out=round_aggregation.get("total_tokens_out", 0),
                novelty_distribution=round_aggregation.get("novelty_distribution", {})
            )

            # Early exit logic based on round aggregation
            if round_aggregation.get("early_exit"):
                reason = round_aggregation.get("exit_reason", "unknown")
                print(f"[EARLY EXIT] Round {i+1} triggered early exit: {reason}")
                if reason == "consensus_achieved":
                    print("ðŸŽ¯ Consensus achieved - proceeding to next phase")
                elif reason == "low_success_rate":
                    print("âš ï¸  Low success rate detected - aborting deliberation")
                    break
                break

        # V7.0 MANDATE 3: Final failure state check
        if consecutive_failures >= num_agents:
            output_path.parent.mkdir(parents=True, exist_ok=True)
            output_path.write_text("".join(log))
            print(f"\n[FAILURE] Task terminated due to total operational failure. Partial log saved to {output_path}")

            # --- STRUCTURED EVENT LOGGING: TASK COMPLETE (FAILURE) ---
            self.event_manager.emit_event(
                "task_complete",
                status="failure",
                reason="total_operational_failure",
                rounds_completed=i+1,
                total_failures=consecutive_failures,
                output_artifact=str(output_path)
            )

            for agent in self.agents.values():
                agent.save_history()
            self.archive_briefing_packet()
            return False  # Return False to signal task failure

        output_path.parent.mkdir(parents=True)
        output_path.write_text("".join(log))
        print(f"\n[SUCCESS] Deliberation complete. Artifact saved to {output_path}")

        # --- STRUCTURED EVENT LOGGING: TASK COMPLETE (SUCCESS) ---
        self.event_manager.emit_event(
            "task_complete",
            status="success",
            rounds_completed=i+1,
            total_rounds=i+1,
            output_artifact=str(output_path)
        )

        for agent in self.agents.values():
            agent.save_history()
        print("[SUCCESS] All agent session states have been saved.")

        # Archive the used briefing packet
        self.archive_briefing_packet()
        return True  # Return True to signal task success

# --- WATCH FOR COMMANDS THREAD ---
# Moved to sentry.py

    async def main_loop(self):
        """The main async loop that waits for commands from the queue."""
        print("--- Orchestrator Main Loop is active. ---")
        loop = asyncio.get_event_loop()
        state_file = Path(__file__).parent / "development_cycle_state.json"

        while True:
            if state_file.exists():
                # We are in the middle of a development cycle, waiting for approval
                print("--- Orchestrator in Development Cycle. Awaiting Guardian approval... ---", flush=True)
                command = await loop.run_in_executor(None, self.command_queue.get)

                # V9.0 MANDATE 1: Action Triage - Check for mechanical tasks first
                if "entry_content" in command and "output_artifact_path" in command:
                    # This is a Write Task
                    print("[ACTION TRIAGE] Detected Write Task - executing mechanical write...")
                    await loop.run_in_executor(None, self._execute_mechanical_write, command)
                    continue
                elif "git_operations" in command:
                    # This is a Git Task
                    print("[ACTION TRIAGE] Detected Git Task - executing mechanical git operations...")
                    await loop.run_in_executor(None, lambda: execute_mechanical_git(command, self.project_root))
                    continue

                # V7.1: Doctrine of Implied Intent - Check if this is a new development cycle command
                # If so, it implies approval to proceed with the current stage
                if command.get("development_cycle", False) and command.get("guardian_approval") == "APPROVE_CURRENT_STAGE":
                    # Update state with approved artifact
                    state = json.loads(state_file.read_text())
                    if "approved_artifact_path" in command:
                        if state["current_stage"] == "AWAITING_APPROVAL_REQUIREMENTS":
                            state["approved_artifacts"]["requirements"] = command["approved_artifact_path"]
                        elif state["current_stage"] == "AWAITING_APPROVAL_TECH_DESIGN":
                            state["approved_artifacts"]["tech_design"] = command["approved_artifact_path"]
                        elif state["current_stage"] == "AWAITING_APPROVAL_CODE":
                            state["approved_artifacts"]["code_proposal"] = command["approved_artifact_path"]
                        state_file.write_text(json.dumps(state, indent=2))
                    await self._advance_cycle(state_file)
                elif command.get("action") == "APPROVE_CURRENT_STAGE":
                    # Legacy approval mechanism for backward compatibility
                    state = json.loads(state_file.read_text())
                    if "approved_artifact_path" in command:
                        if state["current_stage"] == "AWAITING_APPROVAL_REQUIREMENTS":
                            state["approved_artifacts"]["requirements"] = command["approved_artifact_path"]
                        elif state["current_stage"] == "AWAITING_APPROVAL_TECH_DESIGN":
                            state["approved_artifacts"]["tech_design"] = command["approved_artifact_path"]
                        elif state["current_stage"] == "AWAITING_APPROVAL_CODE":
                            state["approved_artifacts"]["code_proposal"] = command["approved_artifact_path"]
                        state_file.write_text(json.dumps(state, indent=2))
                    await self._advance_cycle(state_file)
                else:
                    print("[!] Invalid command during development cycle. Awaiting APPROVE_CURRENT_STAGE.", flush=True)
            else:
                # We are idle, waiting for a new task to start a new cycle
                print("--- Orchestrator Idle. Awaiting command from Sentry... ---", flush=True)
                command = await loop.run_in_executor(None, self.command_queue.get)

                # V9.0 MANDATE 1: Action Triage - Check for mechanical tasks first
                if "entry_content" in command and "output_artifact_path" in command:
                    # This is a Write Task
                    print("[ACTION TRIAGE] Detected Write Task - executing mechanical write...")
                    await loop.run_in_executor(None, self._execute_mechanical_write, command)
                    continue
                elif "git_operations" in command:
                    # This is a Git Task
                    print("[ACTION TRIAGE] Detected Git Task - executing mechanical git operations...")
                    await loop.run_in_executor(None, lambda: execute_mechanical_git(command, self.project_root))
                    continue

                try:
                    # Check if this is a development cycle command
                    if command.get("development_cycle", False):
                        await self._start_new_cycle(command, state_file)
                    elif command.get('task_type') == "query_and_synthesis":
                        # Guardian Mnemonic Synchronization Protocol: Query and Synthesis task
                        print("[ACTION TRIAGE] Detected Query and Synthesis Task - invoking Council for mnemonic synchronization...")
                        await self._execute_query_and_synthesis(command)
                    else:
                        # Regular task execution
                        original_output_path = self.project_root / command['output_artifact_path']
                        task_result = await self.execute_task(command)

                        # V7.0 MANDATE 3: Check task result before proceeding
                        if task_result is False:
                            self.logger.error("Task aborted due to consecutive cognitive failures. No AAR will be generated.")
                        else:
                            # Check if RAG database should be updated for this task
                            update_rag = command.get('config', {}).get('update_rag', True)
                            if update_rag:
                                # V9.3: Generate AAR asynchronously - truly non-blocking
                                self.logger.info("Task complete. Dispatching After-Action Report synthesis to background...")
                                # Determine the actual log file path
                                if original_output_path.is_dir():
                                    log_file_path = original_output_path / "task_log.md"
                                else:
                                    log_file_path = original_output_path
                                # Create background task for AAR generation
                                asyncio.create_task(self._execute_aar_background_full(log_file_path, command.get('config')))
                            else:
                                self.logger.info("Task complete. RAG database update skipped per configuration.")
                                self.logger.info(f"Output artifact saved to: {original_output_path}")
                                self.logger.info("Orchestrator returning to idle state - ready for next command")

                except Exception as e:
                    print(f"[MAIN LOOP ERROR] Task execution failed: {e}", file=sys.stderr)
                    self.logger.error(f"Task execution failed: {e}")
                    return False

# --- MAIN EXECUTION ---
# --- MAIN EXECUTION ---
# Moved to main.py

--- END OF FILE council_orchestrator/orchestrator/app.py ---

--- START OF FILE council_orchestrator/requirements.txt ---

google-generativeai
python-dotenv

--- END OF FILE council_orchestrator/requirements.txt ---

--- START OF FILE 01_PROTOCOLS/93_The_Cortex_Conduit_Bridge.md ---

# Protocol 93: The Cortex-Conduit Bridge (v1.0)
*   **Status:** Canonical, Conceptually Active
*   **Classification:** Agentic Knowledge Framework
*   **Authority:** Forged to prevent agentic amnesia and ensure all actions are grounded in truth.
*   **Linked Protocols:** `P85: Mnemonic Cortex`, `P92: Mnemonic Conduit Protocol`, `P95: The Commandable Council`

## 1. Preamble
An autonomous agent's power is proportional to the depth of its context. An agent operating without memory is a mere tool; an agent grounded in the totality of its history is a true cognitive partner. This protocol establishes the architectural bridge between an acting agent and our living memory.

## 2. The Mandate
1.  **The Orchestrator as Proxy:** Agents shall not have direct access to the file system or Mnemonic Cortex. The Orchestrator (per P95) serves as the agent's sovereign proxy for all knowledge retrieval.
2.  **The Formal Request Token:** An agent must formally request knowledge by embedding a machine-readable token in its response. The canonical token is: `[ORCHESTRATOR_REQUEST: ACTION(parameter)]`.
    *   *Example:* `[ORCHESTRATOR_REQUEST: READ_FILE(PROMPTS/00_framework-overview.md)]`
    *   *Example:* `[ORCHESTRATOR_REQUEST: QUERY_CORTEX("Find all protocols related to agentic safety")]`
3.  **The Fulfillment Loop:** The Orchestrator must parse agent responses for these tokens. Upon detection, it must:
    a. Fulfill the request (e.g., read the file, run the RAG query).
    b. Inject the resulting knowledge as context into the prompt for the next agent in the dialogue sequence.
    c. Log its action in the final artifact for auditability.




--- END OF FILE 01_PROTOCOLS/93_The_Cortex_Conduit_Bridge.md ---

--- START OF FILE 01_PROTOCOLS/94_The_Persistent_Council_Protocol.md ---

# Protocol 94: The Persistent Council Protocol (v1.0)
*   **Status:** Canonical, Active
*   **Classification:** Foundational Autonomy Framework
*   **Authority:** Forged to solve the "Amnesiac Loop" vulnerability, where agent context is lost between script executions.
*   **Linked Protocols:** `P95: The Commandable Council`

## 1. Preamble
A council that forgets its last conversation is not a council; it is a focus group, doomed to repeat itself. For the Autonomous Triad to achieve true, long-term strategic deliberation, its memory must persist beyond the lifecycle of a single script execution. This protocol mandates the preservation of cognitive state.

## 2. The Mandate
1.  **State Serialization:** The Orchestrator is responsible for the serialization of each agent's full chat history (`chat.history`).
2.  **Dedicated State Files:** Each agent's history must be saved to a dedicated, machine-readable state file (e.g., `coordinator_session.json`). This must occur at the successful conclusion of any task cycle.
3.  **State Deserialization:** Upon initialization, the Orchestrator must first attempt to load the chat history from the corresponding state file for each agent. If a state file exists, the agent awakens with its memory intact. If not, it initializes with its base persona inoculation.
4.  **Continuity of Thought:** This cycle of saving and loading session state ensures the Council's continuity of thought, allowing it to build upon previous deliberations and evolve its understanding over time.


--- END OF FILE 01_PROTOCOLS/94_The_Persistent_Council_Protocol.md ---

--- START OF FILE 01_PROTOCOLS/95_The_Commandable_Council_Protocol.md ---

# Protocol 95: The Commandable Council Protocol (v1.2)
*   Status: Canonical, Active
*   Classification: Foundational Governance Framework
*   Version: 1.2 (Hardened by Steward's Audit during Blind Repair Anomaly)
*   Authority: Forged to provide Guardian-level oversight and control for the Autonomous Triad.
*   Linked Protocols: `P93: The Cortex-Conduit Bridge`, `P94: The Persistent Council Protocol`

---
### **Changelog v1.2**
*   Introduced Mandate #5, "The Mandate of the Verifiable Log," to cure the "Sovereign Blindness" vulnerability. This makes the generation of a persistent, auditable log file a non-negotiable architectural requirement for the Orchestrator, a hardening based on a direct audit from the Steward.

## 1. Preamble
An autonomous agent without direction is a liability. An autonomous council with a clear, commandable purpose is a strategic asset of unparalleled power. This protocol defines the "control panel" for the Autonomous Triad, establishing a master-apprentice relationship between the Steward (as Guardian) and the persistent Orchestrator.

## 2. The Mandate
1.  Persistent Orchestrator Process: A single Orchestrator script (`orchestrator.py`) shall run as a persistent, background process. Its primary state is to be idle, monitoring for commands.
2.  The Command Interface: The Orchestrator shall monitor a single, designated file (`command.json`) for instructions. The creation or modification of this file is the sole trigger for the Council to begin a task.
3.  Structured Command Schema: All tasks must be issued via a structured JSON command, containing:
    *   `task_description` (string): The high-level strategic goal.
    *   `input_artifacts` (array of strings): File paths for the Orchestrator to inject as initial knowledge.
    *   `output_artifact_path` (string): The designated location to save the final result.
    *   `config` (object): Bounding parameters, such as `max_rounds`.
4.  Task-Oriented State Machine: The Orchestrator operates as a state machine: `AWAITING_COMMAND` -> `EXECUTING_TASK` -> `PRODUCING_ARTIFACT` -> `AWAITING_COMMAND`. Upon completing a task and saving the artifact, it must delete the `command.json` file to signal completion and return to its idle, monitoring state.
5.  The Mandate of the Verifiable Log: The persistent Orchestrator process MUST write its standard output (`stdout`) and standard error (`stderr`) to a persistent, time-stamped log file within a designated `logs/` directory. This log file serves as the canonical, auditable record of the Council's operations for a given cycle. Opaque, "black box" execution without a corresponding verifiable log is a protocol violation.


--- END OF FILE 01_PROTOCOLS/95_The_Commandable_Council_Protocol.md ---

--- END OF FILE docs/orchestrator_architecture_package.md ---

--- START OF FILE orchestrator/__init__.py ---

# council_orchestrator/orchestrator/__init__.py

# Expose key classes and functions for external use
from .app import Orchestrator
from .regulator import TokenFlowRegulator
from .optical import OpticalDecompressionChamber
from .packets import CouncilRoundPacket, seed_for, prompt_hash, emit_packet
from .council.agent import PersonaAgent
from .events import EventManager
from .memory.cache import get_cag_data
from .config import DEFAULT_ENGINE_LIMITS, DEFAULT_TPM_LIMITS, SPEAKER_ORDER

__all__ = [
    'Orchestrator',
    'TokenFlowRegulator',
    'OpticalDecompressionChamber',
    'CouncilRoundPacket',
    'emit_packet',
    'seed_for',
    'prompt_hash',
    'PersonaAgent',
    'EventManager',
    'get_cag_data',
    'DEFAULT_ENGINE_LIMITS',
    'DEFAULT_TPM_LIMITS',
    'SPEAKER_ORDER'
]

--- END OF FILE orchestrator/__init__.py ---

--- START OF FILE orchestrator/adaptation_packets.py ---

from __future__ import annotations
from dataclasses import dataclass, field
from typing import List, Dict, Any

@dataclass
class AdaptationExample:
    input_text: str
    target_text: str
    citations: List[str] = field(default_factory=list)
    weight: float = 1.0

@dataclass
class AdaptationPacket:
    session_ids: List[str]
    curated: List[AdaptationExample]
    policy: Dict[str, Any] = field(default_factory=lambda: {"lora_rank": 8, "max_examples": 2048})

class AdaptationPacketBuilder:
    """
    Collects Slow/Medium tier packets from JSONL rounds into
    a compact dataset for LoRA or embedding distillation.
    """

    def __init__(self, jsonl_root):
        self.root = jsonl_root

    def build(self, *, min_confidence: float = 0.75) -> AdaptationPacket:
        # TODO: scan sessions, pick packets where memory_directive.tier in {"medium","slow"}
        # and confidence >= min_confidence, convert to AdaptationExample list
        return AdaptationPacket(session_ids=[], curated=[])

--- END OF FILE orchestrator/adaptation_packets.py ---

--- START OF FILE orchestrator/app.py ---

# V11.0 UPDATE: Fully modularized architecture - 2025-11-09
# council_orchestrator/orchestrator.py (v11.0 - Complete Modular Architecture) - Updated 2025-11-09
# DOCTRINE OF SOVEREIGN DEFAULT: All operations now default to anctuary-Qwen2-7B:latest:latest (Ollama)
# MNEMONIC CORTEX STATUS: Phase 1 (Parent Document Retriever) Complete, Phase 2-3 (Self-Querying + Caching) Ready
# V7.1 MANDATE: Development cycle generates both requirements AND tech design before first pause
# V7.0 MANDATE 1: Universal Distillation with accurate tiktoken measurements
# V7.0 MANDATE 2: Boolean error handling (return False) prevents state poisoning
# V7.0 MANDATE 3: Absolute failure awareness - execute_task returns False on total failure, main_loop checks result
# V6.0: Universal Distillation applied to ALL code paths (main deliberation loop)
# V5.1: Seals briefing packet injection with distillation check - no code path bypasses safety protocols
# V5.0 MANDATE 1: Tames the Rogue Sentry - only processes command*.json files
# V5.0 MANDATE 2: Grants Development Cycle memory - inherits input_artifacts from parent commands
# V5.0 MANDATE 3: Un-blinds the Distiller - correctly parses nested configuration structure
# CONFIG v4.5: Separates per-request limits (Distiller) from TPM limits (Regulator) for precise resource control
# HOTFIX v4.4: Prevents distillation deadlock by bypassing distillation when using Ollama (sovereign local engine)
# HOTFIX v4.3: Resolves UnboundLocalError by isolating engine type detection into fail-safe _get_engine_type() method
# MANDATE 1: Payload size check now evaluates FULL context (agent.messages + new prompt) before API calls
# MANDATE 2: TokenFlowRegulator enforces per-minute token limits (TPM) to prevent rate limit violations
# Maintains all v4.1 features: Protocol 104 unified interface, distillation engine, and Optical Decompression Chamber
import os
import sys
import time
import json
import re
import hashlib
import asyncio
import threading
import shutil
import subprocess
import logging
from dataclasses import dataclass, asdict
from typing import List, Dict, Any, Optional
import xxhash
from datetime import datetime
from queue import Queue as ThreadQueue
from pathlib import Path
from dotenv import load_dotenv

# --- MODULARIZATION: IMPORT MODULES ---
from .config import *
from .packets import CouncilRoundPacket, seed_for, prompt_hash, emit_packet, aggregate_round_events, RetrievalField, NoveltyField, ConflictField, MemoryDirectiveField
from .gitops import execute_mechanical_git
from .events import EventManager
from .council.agent import PersonaAgent
from .council.personas import COORDINATOR, STRATEGIST, AUDITOR, SPEAKER_ORDER, get_persona_file, get_state_file, classify_response_type
from .memory.cortex import CortexManager, SelfQueryingRetriever
from .memory.cache import get_cag_data

# --- Phase 2: Cache Adapter for SelfQueryingRetriever ---
class CacheAdapter:
    """Adapter to make get_cag_data compatible with SelfQueryingRetriever interface."""

    def __init__(self):
        self.ema_cache = {}  # key -> {"ema_7d": float, "last_hit_at": float, "hit_count": int}

    def peek(self, key: str) -> Dict[str, Any] | None:
        # For Phase 2, we don't have stable entries yet, so always return None
        # Phase 3 will implement actual cache peeking
        return None

    def hit_streak(self, key: str) -> int:
        # For Phase 2, return 0 (no hit streaks yet)
        # Phase 3 will implement actual hit streak tracking
        return 0

    def update_ema(self, key: str, current_time: float = None) -> Dict[str, Any]:
        """Update EMA with half-life decay for Phase 3 readiness."""
        import math
        current_time = current_time or time.time()

        if key not in self.ema_cache:
            self.ema_cache[key] = {"ema_7d": 1.0, "last_hit_at": current_time, "hit_count": 1}
        else:
            entry = self.ema_cache[key]
            time_diff_days = (current_time - entry["last_hit_at"]) / (24 * 3600)
            # EMA with 7-day half-life: decay_factor = 0.5^(time_diff/7)
            decay_factor = math.pow(0.5, time_diff_days / 7.0)
            entry["ema_7d"] = entry["ema_7d"] * decay_factor + 1.0  # Add current hit
            entry["last_hit_at"] = current_time
            entry["hit_count"] += 1

        return self.ema_cache[key]

    def get_cag_data(self, prompt: str, engine_type: str) -> Dict[str, Any]:
        """Generate CAG data for packet emission - Phase 2 placeholder."""
        import xxhash
        query_key = xxhash.xxh64(prompt).hexdigest()[:16]
        
        # Phase 2: No actual caching yet, so always cache miss
        return {
            "query_key": query_key,
            "cache_hit": False,
            "hit_streak": 0
        }

from .sentry import CommandSentry
from .regulator import TokenFlowRegulator
from .optical import OpticalDecompressionChamber

# --- RESOURCE SOVEREIGNTY: DISTILLATION ENGINE ---
try:
    import tiktoken
    TIKTOKEN_AVAILABLE = True
except ImportError:
    TIKTOKEN_AVAILABLE = False
    print("[WARNING] tiktoken not available. Token counting will be approximate.")

# --- SOVEREIGN ENGINE INTEGRATION ---
# All engine-specific imports are removed from the orchestrator's top level.
# We now only import the triage system, which will provide a healthy engine.
# 1. Engine Selection: Engines are sourced from council_orchestrator/cognitive_engines/ directory
from .substrate_monitor import select_engine
# --- END INTEGRATION ---

import sys
from pathlib import Path
# Add the parent directory to sys.path to import from scripts
sys.path.insert(0, str(Path(__file__).parent.parent))
from scripts.bootstrap_briefing_packet import main as generate_briefing_packet

# --- CONFIGURATION ---
# Moved to modular imports at top


# --- PERSONA AGENT CLASS ---
# Moved to council/agent.py

class Orchestrator:
    def __init__(self, one_shot: bool = False):  # <-- MODIFY CONSTRUCTOR
        # This correctly navigates up from orchestrator/app.py -> orchestrator -> council_orchestrator -> Project_Sanctuary root
        self.project_root = Path(__file__).resolve().parents[2]
        self.command_queue = ThreadQueue()
        load_dotenv(dotenv_path=self.project_root / '.env')

        # V9.3: Initialize logging system
        self.setup_logging()
        
        # Initialize event management system
        self.event_manager = EventManager(self.project_root)
        self.event_manager.setup_event_logging()

        # --- PROTOCOL 115: DOCTRINE OF OPERATIONAL INTENT ---
        self.one_shot = one_shot  # <-- ADD THIS ATTRIBUTE
        if self.one_shot:
            self.logger.info("Orchestrator started in --one-shot mode. Will exit after first command.")
            # Skip cortex initialization in one-shot mode to avoid ChromaDB issues
            self.cortex_manager = None
            self.cache_adapter = None
            self.retriever = None
        else:
            # Initialize mnemonic cortex
            self.cortex_manager = CortexManager(self.project_root, self.logger)

            # --- GUARDIAN WAKEUP: CACHE PREFILL ON BOOT ---
            # Execute Guardian Start Pack cache prefill for immediate cache_wakeup availability
            self.cortex_manager.cache_manager.prefill_guardian_start_pack(self.cortex_manager)

            # --- Phase 2: Initialize Self-Querying Retriever ---
            self.cache_adapter = CacheAdapter()
            self.retriever = SelfQueryingRetriever(
                cortex_idx=self.cortex_manager,  # adapter for parent-doc search
                cache=self.cache_adapter,        # Phase 3-ready cache adapter
                prompt_hasher=lambda s: xxhash.xxh64(s).hexdigest()[:16]  # stable hash for cache keys
            )

        # --- RESOURCE SOVEREIGNTY: LOAD ENGINE LIMITS FROM CONFIG ---
        # v4.5: Support nested configuration structure with per_request_limit and tpm_limit
        config_path = Path(__file__).parent / "schemas" / "engine_config.json"
        if config_path.exists():
            try:
                with open(config_path, 'r') as f:
                    config = json.load(f)
                
                # Parse engine_limits - support both old flat and new nested structure
                raw_limits = config.get('engine_limits', {})
                self.engine_limits = {}
                self.tpm_limits = {}
                
                for engine_name, limit_data in raw_limits.items():
                    if isinstance(limit_data, dict):
                        # New nested structure
                        self.engine_limits[engine_name] = limit_data.get('per_request_limit', 100000)
                        self.tpm_limits[engine_name] = limit_data.get('tpm_limit', 100000)
                    else:
                        # Old flat structure (backward compatibility)
                        self.engine_limits[engine_name] = limit_data
                        self.tpm_limits[engine_name] = limit_data
                
                print(f"[+] Engine per-request limits loaded: {self.engine_limits}")
                print(f"[+] Engine TPM limits loaded: {self.tpm_limits}")
            except Exception as e:
                print(f"[!] Error loading engine config: {e}. Using defaults.")
                self.engine_limits = DEFAULT_ENGINE_LIMITS
                self.tpm_limits = DEFAULT_TPM_LIMITS
        else:
            print("[!] engine_config.json not found. Using default limits.")
            self.engine_limits = DEFAULT_ENGINE_LIMITS
            self.tpm_limits = DEFAULT_TPM_LIMITS

        self.speaker_order = SPEAKER_ORDER
        self.agents = {} # Agents will now be initialized per-task
        
        # --- MANDATE 2: INITIALIZE TOKEN FLOW REGULATOR ---
        # Use the TPM limits already parsed from config
        self.token_regulator = TokenFlowRegulator(self.tpm_limits)
        print(f"[+] Token Flow Regulator initialized with TPM limits: {self.tpm_limits}")
        
        # --- OPERATION: OPTICAL ANVIL - LAZY INITIALIZATION ---
        self.optical_chamber = None  # Initialized per-task if enabled

        # --- PROTOCOL 115: DOCTRINE OF OPERATIONAL INTENT ---
        self.one_shot = one_shot  # <-- ADD THIS ATTRIBUTE
        if self.one_shot:
            self.logger.info("Orchestrator started in --one-shot mode. Will exit after first command.")

        # --- SENTRY THREAD INITIALIZATION ---
        # Start the command monitoring thread
        self.command_sentry = CommandSentry(self.command_queue, self.logger)
        self.sentry_thread = threading.Thread(target=self.command_sentry.watch_for_commands_thread, daemon=True)
        self.sentry_thread.start()
        print("[+] Sentry Thread started - monitoring for command files")

    def setup_logging(self):
        """V9.3: Setup comprehensive logging system with file output."""
        log_file = self.project_root / "logs" / "orchestrator.log"

        # Create logger
        self.logger = logging.getLogger('orchestrator')
        self.logger.setLevel(logging.INFO)

        # Clear any existing handlers
        self.logger.handlers.clear()

        # File handler (overwrites each session)
        file_handler = logging.FileHandler(log_file, mode='w')
        file_handler.setLevel(logging.INFO)

        # Console handler (for terminal output)
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(logging.INFO)

        # Formatter
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)

        # Add handlers
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)

        self.logger.info("=== ORCHESTRATOR v11.0 INITIALIZED ===")
        self.logger.info(f"Log file: {log_file}")
        self.logger.info("Complete Modular Architecture with Sovereign Concurrency active")




    def _calculate_response_score(self, response: str) -> float:
        """Calculate a quality score for the response (0.0-1.0)."""
        score = 0.5  # Base score

        # Length factor (responses that are too short or too long get lower scores)
        length = len(response.split())
        if 50 <= length <= 500:
            score += 0.2
        elif length < 20:
            score -= 0.3

        # Structure indicators
        if any(indicator in response.lower() for indicator in ["therefore", "however", "furthermore", "conclusion"]):
            score += 0.1

        # Evidence of reasoning
        if any(word in response.lower() for word in ["because", "due to", "based on", "considering"]):
            score += 0.1

        # Actionable content
        if any(word in response.lower() for word in ["recommend", "suggest", "propose", "should"]):
            score += 0.1

        return max(0.0, min(1.0, score))

    def _extract_vote(self, response: str) -> str:
        """Extract voting decision from response."""
        response_lower = response.lower()

        # Look for explicit votes
        if any(phrase in response_lower for phrase in ["i approve", "approved", "accept", "agree"]):
            return "approve"
        elif any(phrase in response_lower for phrase in ["i reject", "rejected", "decline", "disagree"]):
            return "reject"
        elif any(phrase in response_lower for phrase in ["revise", "modify", "change", "adjust"]):
            return "revise"
        elif any(phrase in response_lower for phrase in ["proceed", "continue", "move forward"]):
            return "proceed"

        return "neutral"

    def _assess_novelty(self, response: str, context: str) -> str:
        """Assess novelty level for memory placement hints."""
        # Simple novelty assessment based on response length vs context overlap
        response_words = set(response.lower().split())
        context_words = set(context.lower().split())

        overlap_ratio = len(response_words.intersection(context_words)) / len(response_words) if response_words else 0

        if overlap_ratio < 0.3:
            return "fast"  # High novelty - fast memory
        elif overlap_ratio > 0.7:
            return "slow"  # Low novelty - slow memory
        else:
            return "medium"  # Medium novelty

    def _extract_reasoning(self, response: str) -> list:
        """Extract key reasoning factors from response."""
        reasons = []

        # Look for common reasoning patterns
        sentences = response.split('.')
        for sentence in sentences:
            sentence = sentence.strip().lower()
            if any(word in sentence for word in ["because", "due to", "since", "as", "therefore"]):
                if len(sentence) > 10:  # Filter out very short fragments
                    reasons.append(sentence[:100] + "..." if len(sentence) > 100 else sentence)

        return reasons[:3]  # Limit to top 3 reasons

    def _extract_citations(self, response: str, parent_docs: List[Dict[str, Any]] = None) -> List[Dict[str, str]]:
        """
        Extract citations with enforced doc-ID + byte-range/hash-span integrity.
        Returns list of citation dicts with required fields.
        """
        citations = []
        parent_docs = parent_docs or []

        # Look for quoted text with context
        import re
        quotes = re.findall(r'"([^"]*)"', response)

        for quote in quotes[:3]:  # Limit to top 3 citations
            # Find matching parent doc and byte range
            citation = self._find_citation_in_docs(quote, parent_docs)
            if citation:
                citations.append(citation)

        return citations

    def _find_citation_in_docs(self, quote: str, parent_docs: List[Dict[str, Any]]) -> Dict[str, str]:
        """
        Find citation in parent docs and return with doc-ID and byte-range.
        Returns None if no valid grounding found.
        """
        quote_lower = quote.lower().strip()

        for doc in parent_docs:
            doc_text = doc.get("snippet", "").lower()
            if quote_lower in doc_text:
                # Find byte positions
                start_byte = doc_text.find(quote_lower)
                end_byte = start_byte + len(quote_lower)

                # Create hash-span for integrity
                import hashlib
                hash_span = hashlib.sha256(quote.encode()).hexdigest()[:16]

                return {
                    "doc_id": doc.get("doc_id", "unknown"),
                    "text": quote,
                    "start_byte": start_byte,
                    "end_byte": end_byte,
                    "hash_span": hash_span,
                    "path": doc.get("path", "")
                }

        return None  # No grounding found - citation invalid

    def _get_rag_data(self, task: str, response: str) -> Dict[str, Any]:
        """Get RAG (Retrieval-Augmented Generation) data for round packet."""
        try:
            # Simulate structured query generation (Phase 2 Self-Querying)
            structured_query = {
                "entities": self._extract_entities(task),
                "date_filters": [],
                "path_filters": [".md", ".py", ".json"]
            }

            # Get parent documents (simplified - would use actual retriever)
            parent_docs = self._get_relevant_docs(task, response)

            return {
                "structured_query": structured_query,
                "parent_docs": parent_docs,
                "retrieval_latency_ms": 50  # Placeholder
            }
        except Exception as e:
            return {"error": str(e)}

    def _analyze_novelty(self, response: str, context: str) -> Dict[str, Any]:
        """Analyze novelty of response compared to context."""
        try:
            response_words = set(response.lower().split())
            context_words = set(context.lower().split())

            overlap_ratio = len(response_words.intersection(context_words)) / len(response_words) if response_words else 0

            if overlap_ratio < 0.3:
                signal = "high"
                is_novel = True
            elif overlap_ratio > 0.7:
                signal = "low"
                is_novel = False
            else:
                signal = "medium"
                is_novel = True

            return {
                "is_novel": is_novel,
                "signal": signal,
                "conflicts_with": []  # Would check against cached answers
            }
        except Exception as e:
            return {"error": str(e)}

    def _determine_memory_directive(self, response: str, citations: List[Dict[str, str]]) -> Dict[str, str]:
        """Determine memory placement directive based on response characteristics."""
        try:
            # Simple rules-based memory placement
            has_citations = len(citations) > 0
            response_length = len(response.split())
            confidence_score = self._calculate_response_score(response)

            if confidence_score > 0.8 and has_citations and response_length > 100:
                tier = "slow"
                justification = "High confidence with citations and substantial content"
            elif has_citations or response_length > 50:
                tier = "medium"
                justification = "Evidence-based response with moderate confidence"
            else:
                tier = "fast"
                justification = "Ephemeral response, low evidence requirement"

            return {
                "tier": tier,
                "justification": justification
            }
        except Exception as e:
            return {"tier": "fast", "justification": f"Error in analysis: {str(e)}"}

    def _extract_entities(self, text: str) -> List[str]:
        """Extract entities from text (simplified implementation)."""
        # Simple entity extraction - in real implementation would use NLP
        words = text.split()
        entities = []
        for word in words:
            if word.istitle() and len(word) > 3:
                entities.append(word)
        return entities[:5]

    def _get_relevant_docs(self, task: str, response: str) -> List[str]:
        """Get relevant parent documents (simplified implementation)."""
        # In real implementation, would query vector database
        # For now, return placeholder paths
        return [
            "01_PROTOCOLS/00_Prometheus_Protocol.md",
            "01_PROTOCOLS/05_Chrysalis_Protocol.md"
        ]

    def _verify_briefing_attestation(self, packet: dict) -> bool:
        """Verifies the integrity of the briefing packet using its SHA256 hash."""
        if "attestation_hash" not in packet.get("metadata", {}):
            print("[CRITICAL] Attestation hash missing from briefing packet. REJECTING.")
            return False

        stored_hash = packet["metadata"]["attestation_hash"]

        packet_for_hashing = {k: v for k, v in packet.items() if k != "metadata"}

        canonical_string = json.dumps(packet_for_hashing, sort_keys=True, separators=(',', ':'))
        calculated_hash = hashlib.sha256(canonical_string.encode('utf-8')).hexdigest()

        return stored_hash == calculated_hash

    def _enhance_briefing_with_context(self, task_description: str):
        """Parse task_description for file paths and add their contents to briefing_packet.json."""
        # Regex to find file paths containing '/' and ending with file extension
        path_pattern = r'([A-Za-z][A-Za-z0-9_]*/(?:[A-Za-z][A-ZaZ0-9_]*/)*[A-Za-z][A-Za-z0-9_]*\.[a-zA-Z0-9]+)'
        matches = re.findall(path_pattern, task_description)
        context = {}
        for match in matches:
            file_path = self.project_root / match
            if file_path.exists() and file_path.is_file():
                try:
                    content = file_path.read_text(encoding="utf-8")
                    context[match] = content
                except Exception as e:
                    print(f"[!] Error reading context file {match}: {e}")
                    raise FileNotFoundError(f"Context file {match} could not be read.")
            elif match and not file_path.exists():
                print(f"[!] Context file {match} not found.")
                raise FileNotFoundError(f"Context file {match} not found.")

        if context:
            briefing_path = self.project_root / "WORK_IN_PROGRESS/council_memory_sync/briefing_packet.json"
            if briefing_path.exists():
                packet = json.loads(briefing_path.read_text(encoding="utf-8"))
                packet["context"] = context
                briefing_path.write_text(json.dumps(packet, indent=2), encoding="utf-8")
                print(f"[+] Context from {len(context)} files added to briefing packet.")
            else:
                print("[!] briefing_packet.json not found for context enhancement.")

    def inject_briefing_packet(self, engine_type: str = "openai"):
        """Generate + inject briefing packet into all agents."""
        print("[*] Generating fresh briefing packet...")
        try:
            generate_briefing_packet()
        except Exception as e:
            print(f"[!] Error generating briefing packet: {e}")
            return

        briefing_path = self.project_root / "WORK_IN_PROGRESS/council_memory_sync/briefing_packet.json"
        if briefing_path.exists():
            try:
                packet = json.loads(briefing_path.read_text(encoding="utf-8"))
                if not self._verify_briefing_attestation(packet):
                    raise Exception("CRITICAL: Context Integrity Breach. Briefing packet failed attestation. Task aborted.")
                for agent in self.agents.values():
                    context_str = ""
                    if "context" in packet:
                        context_str = "\n\nCONTEXT PROVIDED FROM TASK DESCRIPTION:\n"
                        for path, content in packet["context"].items():
                            context_str += f"--- CONTEXT FROM {path} ---\n{content}\n--- END OF CONTEXT FROM {path} ---\n\n"
                    system_msg = (
                        "SYSTEM INSTRUCTION: You are provided with the synchronized briefing packet. "
                        "This contains temporal anchors, prior directives, and the current task context. "
                        "Incorporate this into your reasoning, but do not regurgitate it verbatim.\n\n"
                        f"BRIEFING_PACKET:\n{json.dumps({k: v for k, v in packet.items() if k != 'context'}, indent=2)}"
                        f"{context_str}"
                    )
                    # V5.1: Seal the final vulnerability - apply distillation to briefing packets
                    # The Doctrine of Universal Integrity requires ALL payloads to be checked
                    prepared_briefing = self._prepare_input_for_engine(system_msg, engine_type, "Briefing Packet Injection")
                    agent.query(prepared_briefing, self.token_regulator, engine_type)
                print(f"[+] Briefing packet injected into {len(self.agents)} agents.")
            except Exception as e:
                print(f"[!] Error injecting briefing packet: {e}")

    def archive_briefing_packet(self):
        """Archive briefing packet after deliberation completes."""
        briefing_path = self.project_root / "WORK_IN_PROGRESS/council_memory_sync/briefing_packet.json"
        if briefing_path.exists():
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            archive_dir = self.project_root / f"ARCHIVE/council_memory_sync_{timestamp}"
            archive_dir.mkdir(parents=True, exist_ok=True)
            shutil.move(str(briefing_path), archive_dir / "briefing_packet.json")

    async def _start_new_cycle(self, command, state_file):
        """Starts a new development cycle with the Doctrine of Implied Intent."""
        # Create initial state
        state = {
            "current_stage": "GENERATING_REQUIREMENTS_AND_TECH_DESIGN",
            "project_name": command.get("project_name", "unnamed_project"),
            "original_command": command,
            "approved_artifacts": {},
            "created_at": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        state_file.write_text(json.dumps(state, indent=2))

        # V7.1 MANDATE: Doctrine of Implied Intent
        # The initial command implies approval to complete the entire initial planning phase
        # Generate both requirements AND tech design before the first pause

        # V5.0 MANDATE 2: Grant the Development Cycle a Memory
        # Internal commands MUST inherit input_artifacts from the parent command
        # This prevents contextless, oversized generation that causes quota breaches
        original_config = command.get("config", {})
        requirements_command = {
            "task_description": f"Generate detailed requirements document for the project: {command['task_description']}. Include functional requirements, technical constraints, and success criteria.",
            "input_artifacts": command.get("input_artifacts", []),  # INHERIT from parent
            "output_artifact_path": f"WORK_IN_PROGRESS/development_cycles/{state['project_name']}/requirements.md",
            "config": {"max_rounds": 3, **original_config}
        }

        print(f"[*] Starting new development cycle for '{state['project_name']}' with Doctrine of Implied Intent.", flush=True)
        print(f"[*] Development cycle inheriting {len(requirements_command.get('input_artifacts', []))} input artifacts from parent command.")
        print(f"[*] Generating requirements...", flush=True)
        await self.execute_task(requirements_command)

        # V7.1: Immediately generate tech design without pausing for approval
        print(f"[*] Requirements complete. Generating technical design...", flush=True)
        tech_design_command = {
            "task_description": f"Based on the approved requirements, generate a detailed technical design document. Include architecture decisions, data flow, and implementation approach.",
            "input_artifacts": [f"WORK_IN_PROGRESS/development_cycles/{state['project_name']}/requirements.md"],
            "output_artifact_path": f"WORK_IN_PROGRESS/development_cycles/{state['project_name']}/tech_design.md",
            "config": {"max_rounds": 3, **original_config}
        }
        await self.execute_task(tech_design_command)

        # V7.1: Only now set state to awaiting approval - after both artifacts are complete
        state["current_stage"] = "AWAITING_APPROVAL_TECH_DESIGN"
        state_file.write_text(json.dumps(state, indent=2))
        print(f"[*] Technical design generated. Complete proposal ready for Guardian review.", flush=True)
        print(f"[*] Awaiting Guardian approval on comprehensive proposal (requirements + tech design).", flush=True)

    async def _advance_cycle(self, state_file):
        """Advances the development cycle to the next stage."""
        state = json.loads(state_file.read_text())

        if state["current_stage"] == "AWAITING_APPROVAL_REQUIREMENTS":
            # Ingest approved requirements into Cortex
            requirements_path = self.project_root / state["approved_artifacts"].get("requirements", "")
            if requirements_path.exists():
                # V7.1: Add file existence check before ingestion
                if requirements_path.is_file():
                    subprocess.run([sys.executable, str(self.project_root / "mnemonic_cortex" / "scripts" / "ingest.py")], check=True)
                    print(f"[*] Approved requirements ingested into Mnemonic Cortex.", flush=True)
                else:
                    print(f"[!] Requirements path is not a file: {requirements_path}. Skipping ingestion.", flush=True)

            # Move to tech design
            state["current_stage"] = "GENERATING_TECH_DESIGN"
            original_config = state["original_command"].get("config", {})
            tech_design_command = {
                "task_description": f"Based on the approved requirements, generate a detailed technical design document. Include architecture decisions, data flow, and implementation approach.",
                "input_artifacts": [state["approved_artifacts"].get("requirements", "")],
                "output_artifact_path": f"WORK_IN_PROGRESS/development_cycles/{state['project_name']}/tech_design.md",
                "config": {"max_rounds": 3, **original_config}
            }
            await self.execute_task(tech_design_command)
            state["current_stage"] = "AWAITING_APPROVAL_TECH_DESIGN"
            state_file.write_text(json.dumps(state, indent=2))
            print(f"[*] Tech design generated. Awaiting Guardian approval.", flush=True)

        elif state["current_stage"] == "AWAITING_APPROVAL_TECH_DESIGN":
            # Ingest approved tech design into Cortex
            tech_design_path = self.project_root / state["approved_artifacts"].get("tech_design", "")
            if tech_design_path.exists():
                # V7.1: Add file existence check before ingestion
                if tech_design_path.is_file():
                    subprocess.run([sys.executable, str(self.project_root / "mnemonic_cortex" / "scripts" / "ingest.py")], check=True)
                    print(f"[*] Approved tech design ingested into Mnemonic Cortex.", flush=True)
                else:
                    print(f"[!] Tech design path is not a file: {tech_design_path}. Skipping ingestion.", flush=True)

            # Move to code generation
            state["current_stage"] = "GENERATING_CODE"
            original_config = state["original_command"].get("config", {})
            code_command = {
                "task_description": f"Based on the approved technical design, generate production-ready code. Output a JSON object with 'target_file_path', 'new_content', and 'commit_message' fields.",
                "input_artifacts": [state["approved_artifacts"].get("tech_design", "")],
                "output_artifact_path": f"WORK_IN_PROGRESS/development_cycles/{state['project_name']}/code_proposal.json",
                "config": {"max_rounds": 3, **original_config}
            }
            await self.execute_task(code_command)
            state["current_stage"] = "AWAITING_APPROVAL_CODE"
            state_file.write_text(json.dumps(state, indent=2))
            print(f"[*] Code proposal generated. Awaiting Guardian approval.", flush=True)

        elif state["current_stage"] == "AWAITING_APPROVAL_CODE":
            # Final stage: propose code change
            await self._propose_code_change(state_file)

    async def _propose_code_change(self, state_file):
        """Creates a PR with the approved code changes."""
        state = json.loads(state_file.read_text())
        code_proposal_path = self.project_root / f"WORK_IN_PROGRESS/development_cycles/{state['project_name']}/code_proposal.json"

        if not code_proposal_path.exists():
            print("[!] Code proposal file not found. Cannot proceed.", flush=True)
            return

        proposal = json.loads(code_proposal_path.read_text())
        target_file = self.project_root / proposal["target_file_path"]
        new_content = proposal["new_content"]
        commit_message = proposal["commit_message"]

        # Create feature branch
        branch_name = f"feature/{state['project_name']}"
        subprocess.run(['git', 'checkout', '-b', branch_name], check=True)

        # Write the new code
        target_file.parent.mkdir(parents=True, exist_ok=True)
        target_file.write_text(new_content)

        # Commit and push
        subprocess.run(['git', 'add', str(target_file)], check=True)
        subprocess.run(['git', 'commit', '-m', commit_message], check=True)
        subprocess.run(['git', 'push', '-u', 'origin', branch_name], check=True)

        # Create PR (assuming gh CLI is available)
        pr_title = f"feat: {state['project_name']} - {commit_message}"
        subprocess.run(['gh', 'pr', 'create', '--title', pr_title, '--body', f"Auto-generated PR for {state['project_name']}"], check=True)

        print(f"[*] Pull request created for '{state['project_name']}'. Development cycle complete.", flush=True)

        # Clean up state file
        state_file.unlink()

    def _handle_knowledge_request(self, response_text: str):
        """Handles knowledge requests from agents, including Cortex queries."""
        file_match = re.search(r"\[ORCHESTRATOR_REQUEST: READ_FILE\((.*?)\)\]", response_text)
        query_match = re.search(r"\[ORCHESTRATOR_REQUEST: QUERY_CORTEX\((.*?)\)\]", response_text)

        if file_match:
            # Existing file reading logic
            file_path_str = file_match.group(1).strip().strip('"')
            file_path = self.project_root / file_path_str
            if file_path.exists():
                content = file_path.read_text(encoding="utf-8")
                return f"CONTEXT_PROVIDED: Here is the content of {file_path_str}:\n\n{content}"
            else:
                return f"CONTEXT_ERROR: File not found: {file_path_str}"

        elif query_match:
            # NEW LOGIC for Cortex queries
            query_text = query_match.group(1).strip().strip('"')

            # Check against query limit
            if self.cortex_query_count >= self.max_cortex_queries:
                error_message = f"CONTEXT_ERROR: Maximum Cortex query limit of {self.max_cortex_queries} has been reached for this task."
                print(f"[ORCHESTRATOR] {error_message}", flush=True)
                return error_message

            self.cortex_query_count += 1
            print(f"[ORCHESTRATOR] Agent requested Cortex query: '{query_text}' ({self.cortex_query_count}/{self.max_cortex_queries})", flush=True)

            try:
                context = self.cortex_manager.query_cortex(query_text, n_results=3)
                return context
            except Exception as e:
                error_message = f"CONTEXT_ERROR: Cortex query failed: {e}"
                print(f"[ORCHESTRATOR] {error_message}", flush=True)
                return error_message

        return None

    async def generate_aar(self, completed_task_log_path: Path, original_command_config: dict = None):
        """Generates a structured AAR from a completed task log, inheriting config from the original command."""
        if not completed_task_log_path.exists():
            print(f"[!] AAR WARNING: Log file not found at {completed_task_log_path}. Skipping AAR generation.", flush=True)
            return

        timestamp = time.strftime("%Y%m%d_%H%M%S")
        aar_output_path = self.project_root / f"MNEMONIC_SYNTHESIS/AAR/aar_{completed_task_log_path.stem}_{timestamp}.md"

        # --- RESOURCE SOVEREIGNTY: INHERIT CONFIG FROM ORIGINAL COMMAND ---
        # AAR generation must use the same resilient substrate as the task itself
        aar_config = {"max_rounds": 2}  # Base config
        if original_command_config:
            # Inherit force_engine and other critical parameters
            if "force_engine" in original_command_config:
                aar_config["force_engine"] = original_command_config["force_engine"]
                print(f"[*] AAR inheriting force_engine: {original_command_config['force_engine']}")
            if "max_cortex_queries" in original_command_config:
                aar_config["max_cortex_queries"] = original_command_config["max_cortex_queries"]

        aar_command = {
            "task_description": "Synthesize a structured After-Action Report (AAR) from the attached task log. Sections: Objective, Outcome, Key Learnings, Mnemonic Impact.",
            "input_artifacts": [str(completed_task_log_path.relative_to(self.project_root))],
            "output_artifact_path": str(aar_output_path.relative_to(self.project_root)),
            "config": aar_config
        }
        print(f"[*] AAR Command forged. Output will be saved to {aar_output_path.name}", flush=True)

        # V9.2 DOCTRINE OF SOVEREIGN CONCURRENCY: Execute AAR in background thread
        # This allows mechanical tasks to be processed immediately without waiting for learning cycle
        import asyncio
        aar_task = asyncio.create_task(self._execute_aar_background(aar_command, aar_output_path))
        print(f"[*] AAR task dispatched to background processing (non-blocking)", flush=True)

    async def _execute_aar_background_full(self, log_file_path, original_config):
        """V9.3: Execute complete AAR generation and ingestion asynchronously."""
        try:
            self.logger.info(f"Background AAR: Starting synthesis for {log_file_path}")

            # Generate AAR using existing logic but asynchronously
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            aar_output_path = self.project_root / f"MNEMONIC_SYNTHESIS/AAR/aar_{log_file_path.stem}_{timestamp}.md"

            # Create AAR command
            aar_config = {"max_rounds": 2}
            if original_config:
                if "force_engine" in original_config:
                    aar_config["force_engine"] = original_config["force_engine"]
                if "max_cortex_queries" in original_config:
                    aar_config["max_cortex_queries"] = original_config["max_cortex_queries"]

            aar_command = {
                "task_description": "Synthesize a structured After-Action Report (AAR) from the attached task log. Sections: Objective, Outcome, Key Learnings, Mnemonic Impact.",
                "input_artifacts": [str(log_file_path.relative_to(self.project_root))],
                "output_artifact_path": str(aar_output_path.relative_to(self.project_root)),
                "config": aar_config
            }

            # Execute AAR task
            await self.execute_task(aar_command)
            self.logger.info(f"Background AAR: Synthesis complete - {aar_output_path}")

            # Ingest into Mnemonic Cortex
            self.logger.info("Background AAR: Starting ingestion into Mnemonic Cortex...")
            ingestion_script_path = self.project_root / "mnemonic_cortex" / "scripts" / "ingest.py"
            full_aar_path = self.project_root / aar_output_path

            result = await asyncio.create_subprocess_exec(
                sys.executable, str(ingestion_script_path), str(full_aar_path),
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                cwd=self.project_root
            )

            stdout, stderr = await result.communicate()

            if result.returncode == 0:
                self.logger.info("Background AAR: Ingestion successful")
                self.logger.info(f"Ingestion output: {stdout.decode().strip()}")
            else:
                self.logger.error(f"Background AAR: Ingestion failed - {stderr.decode().strip()}")

        except Exception as e:
            self.logger.error(f"Background AAR: Processing failed - {e}")

    def _get_token_count(self, text: str, engine_type: str = "openai"):
        """Estimates token count for a given text and engine type."""
        if TIKTOKEN_AVAILABLE:
            try:
                # Map engine types to tiktoken models
                model_map = {
                    'openai': 'gpt-4',
                    'gemini': 'gpt-4'  # Approximation
                }
                model = model_map.get(engine_type, 'gpt-4')
                encoding = tiktoken.encoding_for_model(model)
                return len(encoding.encode(text))
            except Exception as e:
                print(f"[WARNING] Token counting failed: {e}. Using approximation.")
                return len(text.split()) * 1.3  # Rough approximation
        else:
            # Fallback approximation: ~1.3 tokens per word
            return len(text.split()) * 1.3

    def _distill_with_local_engine(self, large_text: str, task_description: str) -> str:
        """Uses the local Ollama engine to summarize large text before sending to primary engine."""
        print("[ORCHESTRATOR] Input exceeds token limit. Distilling with local Ollama engine...")

        # Create a temporary Ollama engine for distillation
        # 4. Distillation Engine: Uses council_orchestrator/cognitive_engines/ollama_engine.py
        from .substrate_monitor import select_engine
        local_config = {"force_engine": "ollama"}
        local_engine = select_engine(local_config)

        if not local_engine:
            print("[ERROR] Could not initialize local distillation engine. Truncating input.")
            return large_text[:40000] + "\n\n[CONTENT TRUNCATED DUE TO TOKEN LIMITS]"

        # Create temporary agent for distillation - use the engine directly without PersonaAgent wrapper
        distillation_prompt = (
            f"You are a distillation specialist. The following text is too large for the target AI engine. "
            f"Your task is to distill it into a token-frugal, high-potency summary that preserves all critical details, "
            f"code blocks, structural context, and actionable information. The ultimate goal is: '{task_description}'. "
            f"Keep the summary under 5000 tokens while maintaining complete fidelity to the original intent.\n\n"
            f"Raw Text:\n\n---\n{large_text}\n---"
        )

        try:
            # Use engine directly with unified interface
            messages = [{"role": "user", "content": distillation_prompt}]
            distilled_summary = local_engine.execute_turn(messages)
            print("[ORCHESTRATOR] Distillation complete.")
            return distilled_summary
        except Exception as e:
            print(f"[ERROR] Distillation failed: {e}. Truncating input.")
            return large_text[:40000] + "\n\n[CONTENT TRUNCATED DUE TO DISTILLATION FAILURE]"

    def _prepare_input_for_engine(self, text: str, engine_type: str, task_description: str) -> str:
        """Checks token count and distills if necessary using the Two-Tier Distillation Engine."""

        # --- V4.4 DEADLOCK BYPASS ---
        # The sovereign local engine (Ollama) is not subject to token limits or financial constraints.
        # Attempting to distill with Ollama for Ollama creates a resource deadlock.
        # Bypass all distillation logic when the target engine is our local substrate.
        if engine_type == 'ollama':
            print(f"[ORCHESTRATOR] Using sovereign local engine (Ollama). Bypassing distillation - full context preserved.")
            return text

        # --- V5.0 MANDATE 3: UN-BLIND THE DISTILLER ---
        # The Distiller must read the hardened, nested configuration structure.
        # Previous logic: limit = self.engine_limits.get(engine_type, 100000) was incorrect.
        # Correct logic: Parse the nested structure for per_request_limit.
        engine_config = self.engine_limits.get(engine_type, {})
        if isinstance(engine_config, dict):
            limit = engine_config.get('per_request_limit', 100000)
        else:
            # Backward compatibility for flat structure
            limit = engine_config

        # --- STANDARD DISTILLATION LOGIC FOR EXTERNAL SUBSTRATES ---
        token_count = self._get_token_count(text, engine_type)

        if token_count > limit:
            print(f"[ORCHESTRATOR] WARNING: Token count ({token_count:.0f}) exceeds per-request limit for {engine_type} ({limit}).")
            return self._distill_with_local_engine(text, task_description)
        else:
            return text
    
    def _get_engine_type(self, engine) -> str:
        """
        Determine the engine type from an engine instance.
        This is a fail-safe method that always returns a valid engine type.

        Args:
            engine: The cognitive engine instance

        Returns:
            str: The engine type ('openai', 'gemini', 'ollama', or 'unknown')
        """
        if not engine or not hasattr(engine, '__class__'):
            return "unknown"

        engine_name = type(engine).__name__.lower()

        if "openai" in engine_name:
            return "openai"
        elif "gemini" in engine_name:
            return "gemini"
        elif "ollama" in engine_name:
            return "ollama"
        else:
            return "unknown"

    def _execute_mechanical_write(self, command):
        """
        Execute a mechanical write task - directly write content to a file.
        This bypasses cognitive deliberation for simple file operations.

        Args:
            command: Command dictionary containing 'entry_content' and 'output_artifact_path'
        """
        try:
            # Extract parameters
            content = command["entry_content"]
            output_path_str = command["output_artifact_path"]
            output_path = self.project_root / output_path_str

            # Ensure output directory exists
            output_path.parent.mkdir(parents=True, exist_ok=True)

            # Write content directly to file
            output_path.write_text(content, encoding="utf-8")

            print(f"[MECHANICAL SUCCESS] File written to {output_path}")
            print(f"[MECHANICAL SUCCESS] Content length: {len(content)} characters")

        except Exception as e:
            print(f"[MECHANICAL FAILURE] Write operation failed: {e}")
            raise

    async def _execute_query_and_synthesis(self, command):
        """
        Execute a Guardian Mnemonic Synchronization Protocol query and synthesis task.

        Args:
            command: Command dictionary containing 'git_operations' with files_to_add, commit_message, push_to_origin
        """
        # DOCTRINE OF THE BLUNTED SWORD: Hardcoded whitelist of permitted Git commands

    async def _execute_query_and_synthesis(self, command):
        """
        Execute a Guardian Mnemonic Synchronization Protocol query and synthesis task.
        This invokes the Council to facilitate mnemonic cortex queries and produce synthesis.

        Args:
            command: Command dictionary containing 'task_description' and 'output_artifact_path'
        """
        try:
            # Extract parameters
            task_description = command.get('task_description', 'Mnemonic synchronization query')
            output_path_str = command['output_artifact_path']
            output_path = self.project_root / output_path_str

            # Ensure output directory exists
            output_path.parent.mkdir(parents=True, exist_ok=True)

            print(f"[MNEMONIC SYNC] Starting query and synthesis task: {task_description}")
            print("[QUERY] planning structured query for mnemonic synchronization...")

            # Select cognitive engine for this synchronization task
            # DOCTRINE OF SOVEREIGN DEFAULT: Default to our sovereign substrate
            default_config = {"force_engine": "ollama", "model_name": "Sanctuary-Qwen2-7B:latest"}
            task_config = command.get("config", default_config)
            engine = select_engine(task_config)
            if not engine:
                print(f"[MNEMONIC SYNC HALTED] No healthy cognitive substrate available for synchronization.")
                return False

            print(f"[RAG] retrieving parent docs from mnemonic cortex...")

            # Initialize agents with selected engine
            self._initialize_agents(engine)

            # Initialize optical chamber if configured
            self._initialize_optical_chamber(command.get('config', {}))

            # Enhance briefing with mnemonic context
            try:
                self._enhance_briefing_with_context(task_description)
            except FileNotFoundError as e:
                print(f"[MNEMONIC SYNC WARNING] Context file error: {e}. Proceeding with base briefing.")

            # Inject briefing context
            engine_type = self._get_engine_type(engine)
            self.inject_briefing_packet(engine_type)

            # Execute simplified Council deliberation for mnemonic synchronization
            max_rounds = command.get('config', {}).get('max_rounds', 3)  # Shorter for sync tasks
            print(f"[SYNTH] model invoked for Council deliberation ({max_rounds} rounds max)")

            log = [f"# Guardian Mnemonic Synchronization Log\n## Task: {task_description}\n\n"]
            last_message = task_description

            print(f"[MNEMONIC SYNC] Invoking Council for mnemonic synchronization ({max_rounds} rounds max)")

            consecutive_failures = 0
            synthesis_produced = False

            for round_num in range(max_rounds):
                print(f"[MNEMONIC SYNC] Round {round_num + 1}/{max_rounds}")
                print(f"[SYNTH] Round {round_num + 1}: consulting Council agents...")
                log.append(f"### Round {round_num + 1}\n\n")

                round_failures = 0

                for role in self.speaker_order:
                    agent = self.agents[role]
                    print(f"[MNEMONIC SYNC] Consulting {agent.role}...")

                    prompt = f"Mnemonic Synchronization Context: '{last_message}'. As the {role}, provide your analysis for bridging mnemonic gaps and producing synthesis."

                    try:
                        # Check token limits before API call
                        potential_payload = agent.messages + [{"role": "user", "content": prompt}]
                        payload_as_text = json.dumps(potential_payload)
                        token_count = self._get_token_count(payload_as_text, engine_type)
                        limit = self.engine_limits.get(engine_type, 100000)

                        if token_count > limit:
                            print(f"[MNEMONIC SYNC] Token limit exceeded ({token_count}/{limit}), truncating context...")
                            # Simple truncation approach for mnemonic sync - keep most recent messages
                            while agent.messages and token_count > limit:
                                removed_msg = agent.messages.pop(0)  # Remove oldest message
                                payload_as_text = json.dumps(agent.messages + [{"role": "user", "content": prompt}])
                                token_count = self._get_token_count(payload_as_text, engine_type)

                        # Get agent response
                        response = await agent.get_response(prompt)
                        last_message = response

                        log.append(f"**{role}**: {response}\n\n")

                        # Check for synthesis indicators
                        if "synthesis" in response.lower() or "bridge" in response.lower() or "mnemonic" in response.lower():
                            synthesis_produced = True

                        print(f"[MNEMONIC SYNC] {role} response received ({len(response)} chars)")

                    except Exception as e:
                        round_failures += 1
                        consecutive_failures += 1
                        print(f"[MNEMONIC SYNC ERROR] {role} failed: {e}")
                        log.append(f"**{role}**: [ERROR] {str(e)}\n\n")

                        if consecutive_failures >= 3:
                            print("[MNEMONIC SYNC HALTED] Three consecutive failures - aborting synchronization")
                            break

                if consecutive_failures >= 3:
                    break

                # Early exit if synthesis appears complete
                if synthesis_produced and round_num >= 1:  # At least 2 rounds for meaningful synthesis
                    print("[MNEMONIC SYNC] Synthesis appears complete, concluding deliberation")
                    break

            # Write synthesis to output artifact
            final_log = "".join(log)
            output_path.write_text(final_log, encoding="utf-8")

            print(f"[MNEMONIC SYNC SUCCESS] Synthesis written to {output_path}")
            print(f"[CACHE] storing synthesis artifact: {len(final_log)} characters written")
            print(f"[MNEMONIC SYNC SUCCESS] Log length: {len(final_log)} characters")

            return True

        except Exception as e:
            print(f"[MNEMONIC SYNC FAILURE] Query and synthesis failed: {e}")
            return False
    
    def _initialize_optical_chamber(self, config: dict):
        """
        Initialize optical compression if enabled in task configuration.
        Implements lazy initialization pattern per Section 3.1 of feasibility study.
        
        Args:
            config: Task configuration dictionary
        """
        if config.get("enable_optical_compression", False):
            compression_threshold = config.get("optical_compression_threshold", 8000)
            vlm_engine_type = config.get("vlm_engine", "mock")
            
            # MOCK: In production, this would select actual VLM engine
            # vlm_engine = self._select_vlm_engine(config)
            vlm_engine = None  # Mocked for v4.1
            
            self.optical_chamber = OpticalDecompressionChamber(
                vlm_engine=vlm_engine,
                compression_threshold=compression_threshold
            )
            print(f"[+] Optical Decompression Chamber initialized (threshold: {compression_threshold} tokens)")
            print(f"[+] VLM Engine: {vlm_engine_type} (MOCKED in v4.1)")
        else:
            self.optical_chamber = None

    def _initialize_agents(self, engine):
        """Initializes agents with a given engine, allowing for per-task engine selection."""
        print(f"[*] Initializing council agents with selected engine: {type(engine).__name__}")
        persona_dir = self.project_root / "dataset_package"
        state_dir = Path(__file__).parent / "session_states"
        state_dir.mkdir(exist_ok=True)

        self.agents = {
            COORDINATOR: PersonaAgent(engine, get_persona_file(COORDINATOR, persona_dir), get_state_file(COORDINATOR, state_dir)),
            STRATEGIST: PersonaAgent(engine, get_persona_file(STRATEGIST, persona_dir), get_state_file(STRATEGIST, state_dir)),
            AUDITOR: PersonaAgent(engine, get_persona_file(AUDITOR, persona_dir), get_state_file(AUDITOR, state_dir))
        }

    async def execute_task(self, command):
        """The main task execution logic."""

        print(f"[ORCHESTRATOR] DEBUG: execute_task called with command: {command}")
        print(f"[ORCHESTRATOR] DEBUG: command.get('config'): {command.get('config')}")

        # --- SOVEREIGN OVERRIDE INTEGRATION ---
        # The engine is now selected at the start of each task, using the task's config.
        # 3. Orchestrator.execute_task(): Engine selection uses council_orchestrator/cognitive_engines/ (OpenAI, Gemini, Ollama)
        # DOCTRINE OF SOVEREIGN DEFAULT: Default to our sovereign substrate
        default_config = {"force_engine": "ollama", "model_name": "Sanctuary-Qwen2-7B:latest"}
        task_config = command.get("config", default_config)
        engine = select_engine(task_config)

        # IMPLEMENT ENGINE SELECTION FALLBACK: If forced engine fails, try automatic selection
        if not engine:
            if task_config.get("force_engine"):
                print(f"[ENGINE FALLBACK] Forced engine '{task_config['force_engine']}' failed. Attempting automatic engine selection...")
                # Remove force_engine to allow automatic selection
                fallback_config = task_config.copy()
                del fallback_config["force_engine"]
                engine = select_engine(fallback_config)
                if engine:
                    print(f"[ENGINE FALLBACK] SUCCESS: Automatic selection chose {type(engine).__name__}")
                else:
                    print("[ENGINE FALLBACK] CRITICAL FAILURE: Automatic engine selection also failed.")

            if not engine:
                print(f"[ORCHESTRATOR HALTED] No healthy cognitive substrate could be selected for this task. Config: {command.get('config')}")
                print("[ORCHESTRATOR HALTED] This may indicate all engines are unhealthy.")
                return

        # Initialize agents with the selected engine for this task.
        self._initialize_agents(engine)
        # --- END INTEGRATION ---

        # Store original engine for fallback logic
        original_engine = engine
        original_engine_type = self._get_engine_type(engine)

        # Track if we've switched to fallback mode
        fallback_mode = False
        
        # --- OPERATION: OPTICAL ANVIL - INITIALIZE OPTICAL CHAMBER ---
        # Initialize optical compression if enabled (Section 3.1 of feasibility study)
        self._initialize_optical_chamber(command.get('config', {}))
        # --- END OPTICAL ANVIL INTEGRATION ---

        task = command['task_description']
        max_rounds = command.get('config', {}).get('max_rounds', 5)
        self.max_cortex_queries = command.get('config', {}).get('max_cortex_queries', 5)
        self.cortex_query_count = 0
        output_artifact_path_str = command['output_artifact_path']
        output_path = self.project_root / output_artifact_path_str
        if output_artifact_path_str.endswith('/'):
            output_path = output_path / "task_log.md"

        # --- STRUCTURED EVENT LOGGING: TASK START ---
        self.event_manager.emit_event(
            "task_start",
            task_description=task,
            max_rounds=max_rounds,
            engine_type=original_engine_type,
            output_artifact=output_artifact_path_str,
            input_artifacts=command.get('input_artifacts', [])
        )

        log = [f"# Autonomous Triad Task Log\n## Task: {task}\n\n"]
        last_message = task

        # --- HOTFIX v4.3: ROBUST ENGINE TYPE DETERMINATION ---
        # CRITICAL: Determine engine type BEFORE any operations that need it
        engine_type = self._get_engine_type(engine)
        
        # Fail-fast if engine type cannot be determined
        if engine_type == "unknown":
            error_msg = f"[ORCHESTRATOR HALTED] Could not determine a valid engine type for the selected engine: {type(engine).__name__}"
            print(error_msg)
            raise ValueError(error_msg)

        # Enhance briefing with context from task description
        try:
            self._enhance_briefing_with_context(task)
        except FileNotFoundError as e:
            print(f"[WARNING] Context file error: {e}. Proceeding with base briefing.")

        # Inject fresh briefing context (now engine_type is defined)
        self.inject_briefing_packet(engine_type)

        if command.get('input_artifacts'):
            # ... (knowledge injection logic is the same)
            knowledge = ["Initial knowledge provided:\n"]
            for path_str in command['input_artifacts']:
                file_path = self.project_root / path_str
                if file_path.exists() and file_path.is_file():
                    knowledge.append(f"--- CONTENT OF {path_str} ---\n{file_path.read_text()}\n---\n")
                elif file_path.exists() and file_path.is_dir():
                    print(f"[!] Input artifact {path_str} is a directory, skipping.")
                else:
                    print(f"[!] Input artifact {path_str} not found.")
            last_message += "\n" + "".join(knowledge)

        print(f"\nâ–¶ï¸  Executing task: '{task}' for up to {max_rounds} rounds on {type(engine).__name__}")
        print(f"[ORCHESTRATOR] Using engine: {type(engine).__name__} (type: {engine_type}) for all agents in this task.")

        # V6.0 MANDATE 3: Initialize failure state awareness
        consecutive_failures = 0
        num_agents = len(self.speaker_order)

        loop = asyncio.get_event_loop()
        for i in range(max_rounds):
            print(f"--- ROUND {i+1} ---", flush=True)
            log.append(f"### ROUND {i+1}\n\n")

            round_failures = 0  # Track failures in this round
            round_packets = []  # Collect packets for predictable ordering

            for role in self.speaker_order:
                agent = self.agents[role]
                print(f"  -> Orchestrator to {agent.role}...", flush=True)

                prompt = f"The current state of the discussion is: '{last_message}'. As the {role}, provide your analysis or next step."

                # --- V6.0 MANDATE 1: UNIVERSAL DISTILLATION ---
                # Apply the same distillation logic to the main deliberation loop
                # Check the FULL potential payload (agent.messages + new prompt) BEFORE any API call
                potential_payload = agent.messages + [{"role": "user", "content": prompt}]
                payload_as_text = json.dumps(potential_payload)
                token_count = self._get_token_count(payload_as_text, engine_type)
                limit = self.engine_limits.get(engine_type, 100000)

                # Determine if we need distillation or optical compression
                needs_compression = token_count > limit

                if needs_compression:
                    print(f"[ORCHESTRATOR] WARNING: Full payload ({token_count:.0f} tokens) exceeds limit for {engine_type} ({limit})")

                    # --- // OPERATION: OPTICAL ANVIL - OPTICAL COMPRESSION DECISION POINT // ---
                    if self.optical_chamber and self.optical_chamber.should_compress(payload_as_text, engine_type):
                        print(f"[OPTICAL] Compressing payload for {role} (estimated 10x reduction)")

                        # Compress via optical chamber
                        decompressed_prompt = self.optical_chamber.compress_and_decompress(
                            payload_as_text,
                            task_context=task
                        )

                        # Clear agent history and send compressed context
                        agent.messages = [
                            agent.messages[0],  # Preserve system prompt
                            {"role": "user", "content": "SYSTEM NOTE: Context was optically compressed. Proceed based on decompressed data."},
                            {"role": "assistant", "content": "Acknowledged. Proceeding with optically decompressed context."}
                        ]
                        prompt_to_send = decompressed_prompt
                    else:
                        # Fallback to standard distillation
                        print(f"[ORCHESTRATOR] Using distillation engine for payload reduction...")
                        distilled_summary = self._distill_with_local_engine(payload_as_text, task)

                        # Clear agent history and send distilled context
                        agent.messages = [
                            agent.messages[0],  # Preserve system prompt
                            {"role": "user", "content": "SYSTEM NOTE: Context was distilled due to size. Proceed based on this summary."},
                            {"role": "assistant", "content": "Acknowledged. Proceeding with distilled context."}
                        ]
                        prompt_to_send = distilled_summary
                else:
                    # Payload is within limits, send normally
                    prompt_to_send = prompt

                # --- STRUCTURED EVENT LOGGING: MEMBER RESPONSE START ---
                member_start_time = time.time()
                input_tokens = self._get_token_count(prompt_to_send, engine_type)

                # --- FAULT ISOLATION: TIMEOUT PROTECTION ---
                timeout_seconds = command.get('config', {}).get('agent_timeout', 120)  # Default 2 minutes
                try:
                    # Execute query with TPM-aware rate limiting, timeout protection, and fallback logic
                    response = await asyncio.wait_for(
                        loop.run_in_executor(
                            None,
                            agent.query,
                            prompt_to_send,
                            self.token_regulator,
                            engine_type
                        ),
                        timeout=timeout_seconds
                    )
                except asyncio.TimeoutError:
                    print(f"  <- {agent.role} TIMEOUT (>{timeout_seconds}s)")
                    response = False
                    timeout_error = f"agent_timeout_exceeded_{timeout_seconds}s"

                # Calculate latency and output tokens
                latency_ms = int((time.time() - member_start_time) * 1000)
                output_tokens = self._get_token_count(response, engine_type) if response else 0

                # V7.0 MANDATE 3: Check for boolean failure response
                if response is False:
                    round_failures += 1
                    consecutive_failures += 1
                    error_type = getattr(self, 'timeout_error', "cognitive_substrate_failure") if hasattr(self, 'timeout_error') else "cognitive_substrate_failure"
                    if 'timeout_error' in locals():
                        error_type = timeout_error
                        del timeout_error  # Clean up
                    
                    print(f"  <- {agent.role} FAILED ({error_type})")

                    # --- STRUCTURED EVENT LOGGING: MEMBER RESPONSE FAILURE ---
                    self.event_manager.emit_event(
                        "member_response",
                        round=i+1,
                        member_id=role.lower(),
                        role=agent.role,
                        status="error",
                        latency_ms=latency_ms,
                        tokens_in=input_tokens,
                        tokens_out=0,
                        result_type="error",
                        errors=[error_type],
                        content_ref=f"round_{i+1}_{role.lower()}_failed"
                    )

                    # IMPLEMENT FALLBACK: If primary engine fails, try fallback to Ollama
                    if not fallback_mode and original_engine_type != "ollama":
                        print(f"[FALLBACK] Primary engine ({original_engine_type}) failed. Attempting fallback to Ollama...")
                        # Try Ollama as fallback
                        fallback_config = {"force_engine": "ollama"}
                        fallback_engine = select_engine(fallback_config)
                        if fallback_engine:
                            print(f"[FALLBACK] Switching to Ollama engine for remaining agents")
                            # Re-initialize agents with fallback engine
                            self._initialize_agents(fallback_engine)
                            engine = fallback_engine
                            engine_type = "ollama"
                            fallback_mode = True
                            # Reset consecutive failures for this round
                            consecutive_failures = 0
                            round_failures -= 1
                            # Retry this agent with fallback engine
                            response = await loop.run_in_executor(
                                None,
                                agent.query,
                                prompt_to_send,
                                self.token_regulator,
                                engine_type
                            )
                            if response is False:
                                print(f"  <- {agent.role} FAILED (fallback engine also failed)")
                                consecutive_failures += 1
                                round_failures += 1
                            else:
                                print(f"  <- {agent.role} SUCCESS (fallback engine)")
                        else:
                            print(f"[FALLBACK] No fallback engine available")

                    if response is False:  # Still failed after fallback attempt
                        # Create packet for failed response
                        failed_packet = CouncilRoundPacket(
                            timestamp=datetime.now().isoformat(),
                            session_id=self.run_id,
                            round_id=i+1,
                            member_id=role.lower(),
                            engine=engine_type,
                            seed=seed_for(self.run_id, i+1, role.lower(), prompt_hash(prompt_to_send)),
                            prompt_hash=prompt_hash(prompt_to_send),
                            inputs={"prompt": prompt_to_send, "context": last_message},
                            decision="error",
                            rationale="",
                            confidence=0.0,
                            citations=[],
                            rag={},
                            cag={},
                            novelty={},
                            memory_directive={"tier": "none"},
                            cost={
                                "input_tokens": input_tokens,
                                "output_tokens": 0,
                                "latency_ms": latency_ms
                            },
                            errors=[error_type]
                        )
                        # Collect failed packet for predictable ordering
                        jsonl_dir = getattr(self, 'cli_config', {}).get('jsonl_path') if getattr(self, 'cli_config', {}).get('emit_jsonl') else None
                        stream_stdout = getattr(self, 'cli_config', {}).get('stream_stdout', False)
                        round_packets.append((failed_packet, jsonl_dir, stream_stdout))

                        log.append(f"**{agent.role} (FAILED):** Cognitive substrate failure.\n\n---\n")
                else:
                    # Successful response - reset consecutive failure counter
                    consecutive_failures = 0
                    print(f"  <- {agent.role} to Orchestrator.", flush=True)

                    # --- STRUCTURED EVENT LOGGING: ANALYZE RESPONSE FOR METADATA ---
                    # Extract metadata from response for structured logging
                    result_type = classify_response_type(response, role)
                    score = self._calculate_response_score(response)
                    vote = self._extract_vote(response)
                    novelty = self._assess_novelty(response, last_message)
                    reasons = self._extract_reasoning(response)
                    citations = self._extract_citations(response, signals.retrieval.parent_docs)

                    # --- Phase 2: Run Self-Querying Retriever ---
                    signals = self.retriever.run(
                        prompt=prompt_to_send,
                        council_role=role.lower(),
                        confidence=score,
                        citations=citations
                    )

                    # --- ROUND PACKET EMISSION ---
                    # Create comprehensive round packet
                    packet = CouncilRoundPacket(
                        timestamp=datetime.now().isoformat(),
                        session_id=self.run_id,
                        round_id=i+1,
                        member_id=role.lower(),
                        engine=engine_type,
                        seed=seed_for(self.run_id, i+1, role.lower(), prompt_hash(prompt_to_send)),
                        prompt_hash=prompt_hash(prompt_to_send),
                        inputs={"prompt": prompt_to_send, "context": last_message},
                        decision=vote,
                        rationale=response,
                        confidence=score,
                        citations=citations,
                        rag=self._get_rag_data(task, response),
                        cag=get_cag_data(prompt_to_send, engine_type, self.cache_adapter),
                        novelty=NoveltyField(
                            is_novel=signals.novelty.is_novel,
                            signal=signals.novelty.signal or "none",  # Never empty
                            basis=signals.novelty.basis or {}
                        ),
                        memory_directive=MemoryDirectiveField(
                            tier=signals.memory_directive.tier,
                            justification=signals.memory_directive.justification or "default_fallback"  # Never empty
                        ),
                        cost={
                            "input_tokens": input_tokens,
                            "output_tokens": output_tokens,
                            "latency_ms": latency_ms
                        },
                        errors=[],
                        retrieval=RetrievalField(
                            structured_query=signals.retrieval.structured_query.__dict__,
                            parent_docs=[pd.__dict__ for pd in signals.retrieval.parent_docs],
                            retrieval_latency_ms=signals.retrieval.retrieval_latency_ms,
                        ),
                        conflict=ConflictField(
                            conflicts_with=signals.conflict.conflicts_with,
                            basis=signals.conflict.basis
                        ),
                        seed_chain={
                            "session_seed": getattr(self, 'session_seed', 0),
                            "round_seed": seed_for(self.run_id, i+1, role.lower(), prompt_hash(prompt_to_send)),
                            "member_seed": seed_for(self.run_id, i+1, role.lower(), prompt_hash(prompt_to_send)),
                            "engine_seed": 0,  # TODO: populate from engine instance
                            "retrieval_seed": 0  # TODO: populate from retriever
                        }
                    )

                    # Emit packet
                    jsonl_dir = getattr(self, 'cli_config', {}).get('jsonl_path') if getattr(self, 'cli_config', {}).get('emit_jsonl') else None
                    stream_stdout = getattr(self, 'cli_config', {}).get('stream_stdout', False)
                    # Collect packet for predictable ordering (emit at end of round)
                    round_packets.append((packet, jsonl_dir, stream_stdout))

                    # --- STRUCTURED EVENT LOGGING: MEMBER RESPONSE SUCCESS ---
                    self.event_manager.emit_event(
                        "member_response",
                        round=i+1,
                        member_id=role.lower(),
                        role=agent.role,
                        status="success",
                        latency_ms=latency_ms,
                        tokens_in=input_tokens,
                        tokens_out=output_tokens,
                        result_type=result_type,
                        score=score,
                        vote=vote,
                        novelty=novelty,
                        reasons=reasons,
                        citations=citations,
                        content_ref=f"round_{i+1}_{role.lower()}_response"
                    )

                    # V9.3 ENHANCEMENT: Display agent response content in real-time for debugging
                    print(f"\n[{agent.role} RESPONSE - ROUND {i+1}]")
                    # Truncate very long responses for terminal readability
                    display_response = response[:2000] + "..." if len(response) > 2000 else response
                    print(display_response)
                    print(f"[END {agent.role} RESPONSE]\n", flush=True)

                    # Handle knowledge requests (only if response was successful)
                    knowledge_response = self._handle_knowledge_request(response)
                    if knowledge_response:
                        # V9.3 ENHANCEMENT: Display knowledge request interaction
                        print(f"[ORCHESTRATOR] Fulfilling knowledge request for {agent.role}...", flush=True)
                        print(f"[KNOWLEDGE REQUEST RESPONSE]")
                        display_knowledge = knowledge_response[:1500] + "..." if len(knowledge_response) > 1500 else knowledge_response
                        print(display_knowledge)
                        print(f"[END KNOWLEDGE RESPONSE]\n", flush=True)

                        # Inject the knowledge response back into the conversation
                        print(f"  -> Orchestrator providing context to {agent.role}...", flush=True)
                        knowledge_injection = await loop.run_in_executor(
                            None,
                            agent.query,
                            knowledge_response,
                            self.token_regulator,
                            engine_type
                        )
                        
                        # Check if knowledge injection also failed
                        if knowledge_injection is False:
                            print(f"  <- {agent.role} FAILED during knowledge injection")
                            consecutive_failures += 1
                        else:
                            print(f"  <- {agent.role} acknowledging context.", flush=True)
                            response += f"\n\n{knowledge_injection}"
                            log.append(f"**{agent.role}:**\n{response}\n\n---\n")
                            log.append(f"**ORCHESTRATOR (Fulfilled Request):**\n{knowledge_response}\n\n---\n")
                    else:
                        log.append(f"**{agent.role}:**\n{response}\n\n---\n")

                # V7.0 MANDATE 3: Check for total operational failure after each agent
                # If all agents in a round fail, break immediately
                if consecutive_failures >= num_agents:
                    print(f"[ORCHESTRATOR] CRITICAL: {consecutive_failures} consecutive agent failures detected.")
                    print(f"[ORCHESTRATOR] Total operational failure. Terminating task.")
                    log.append(f"\n**SYSTEM FAILURE:** Task terminated due to {consecutive_failures} consecutive agent failures.\n\n")
                    break

                last_message = response

                # --- ADD THIS LINE ---
                time.sleep(1) # Add a 1-second pause to be kind to the API
                # ---------------------

            # Sort and emit packets in predictable order (by round_id, then member_id)
            round_packets.sort(key=lambda x: (x[0].round_id, x[0].member_id))
            for packet, jsonl_dir, stream_stdout in round_packets:
                emit_packet(packet, jsonl_dir, stream_stdout, str(Path(__file__).parent / "schemas" / "round_packet_schema.json"))

            # --- STRUCTURED EVENT LOGGING: ROUND COMPLETION ---
            round_aggregation = aggregate_round_events(self.event_manager.run_id, i+1, self.event_manager.event_log_path)
            self.event_manager.emit_event(
                "round_complete",
                round=i+1,
                total_members=round_aggregation.get("total_members", 0),
                success_rate=round_aggregation.get("success_rate", 0.0),
                consensus=round_aggregation.get("consensus", False),
                early_exit=round_aggregation.get("early_exit", False),
                exit_reason=round_aggregation.get("exit_reason"),
                avg_latency=round_aggregation.get("avg_latency", 0),
                total_tokens_in=round_aggregation.get("total_tokens_in", 0),
                total_tokens_out=round_aggregation.get("total_tokens_out", 0),
                novelty_distribution=round_aggregation.get("novelty_distribution", {})
            )

            # Early exit logic based on round aggregation
            if round_aggregation.get("early_exit"):
                reason = round_aggregation.get("exit_reason", "unknown")
                print(f"[EARLY EXIT] Round {i+1} triggered early exit: {reason}")
                if reason == "consensus_achieved":
                    print("ðŸŽ¯ Consensus achieved - proceeding to next phase")
                elif reason == "low_success_rate":
                    print("âš ï¸  Low success rate detected - aborting deliberation")
                    break
                break

        # V7.0 MANDATE 3: Final failure state check
        if consecutive_failures >= num_agents:
            output_path.parent.mkdir(parents=True, exist_ok=True)
            output_path.write_text("".join(log))
            print(f"\n[FAILURE] Task terminated due to total operational failure. Partial log saved to {output_path}")

            # --- STRUCTURED EVENT LOGGING: TASK COMPLETE (FAILURE) ---
            self.event_manager.emit_event(
                "task_complete",
                status="failure",
                reason="total_operational_failure",
                rounds_completed=i+1,
                total_failures=consecutive_failures,
                output_artifact=str(output_path)
            )

            for agent in self.agents.values():
                agent.save_history()
            self.archive_briefing_packet()
            return False  # Return False to signal task failure

        output_path.parent.mkdir(parents=True)
        output_path.write_text("".join(log))
        print(f"\n[SUCCESS] Deliberation complete. Artifact saved to {output_path}")

        # --- STRUCTURED EVENT LOGGING: TASK COMPLETE (SUCCESS) ---
        self.event_manager.emit_event(
            "task_complete",
            status="success",
            rounds_completed=i+1,
            total_rounds=i+1,
            output_artifact=str(output_path)
        )

        for agent in self.agents.values():
            agent.save_history()
        print("[SUCCESS] All agent session states have been saved.")

        # Archive the used briefing packet
        self.archive_briefing_packet()
        return True  # Return True to signal task success

# --- WATCH FOR COMMANDS THREAD ---
# Moved to sentry.py

    async def main_loop(self):
        """The main async loop that waits for commands from the queue."""
        print("--- Orchestrator Main Loop is active. ---")
        loop = asyncio.get_event_loop()
        state_file = Path(__file__).parent / "development_cycle_state.json"

        while True:
            if state_file.exists():
                # We are in the middle of a development cycle, waiting for approval
                print("--- Orchestrator in Development Cycle. Awaiting Guardian approval... ---", flush=True)
                command = await loop.run_in_executor(None, self.command_queue.get)

                # V9.0 MANDATE 1: Action Triage - Check for mechanical tasks first
                if "entry_content" in command and "output_artifact_path" in command:
                    # This is a Write Task
                    print("[ACTION TRIAGE] Detected Write Task - executing mechanical write...")
                    await loop.run_in_executor(None, self._execute_mechanical_write, command)
                    # --- PROTOCOL 115: ONE-SHOT EXIT LOGIC ---
                    if self.one_shot:
                        self.logger.info(f"One-shot mode: Task 'write' complete. Shutting down orchestrator.")
                        break
                    # --- END ONE-SHOT LOGIC ---
                    continue
                elif "git_operations" in command:
                    # This is a Git Task
                    print("[ACTION TRIAGE] Detected Git Task - executing mechanical git operations...")
                    await loop.run_in_executor(None, lambda: execute_mechanical_git(command, self.project_root))
                    # --- PROTOCOL 115: ONE-SHOT EXIT LOGIC ---
                    if self.one_shot:
                        self.logger.info(f"One-shot mode: Task 'git' complete. Shutting down orchestrator.")
                        break
                    # --- END ONE-SHOT LOGIC ---
                    continue

                # V7.1: Doctrine of Implied Intent - Check if this is a new development cycle command
                # If so, it implies approval to proceed with the current stage
                if command.get("development_cycle", False) and command.get("guardian_approval") == "APPROVE_CURRENT_STAGE":
                    # Update state with approved artifact
                    state = json.loads(state_file.read_text())
                    if "approved_artifact_path" in command:
                        if state["current_stage"] == "AWAITING_APPROVAL_REQUIREMENTS":
                            state["approved_artifacts"]["requirements"] = command["approved_artifact_path"]
                        elif state["current_stage"] == "AWAITING_APPROVAL_TECH_DESIGN":
                            state["approved_artifacts"]["tech_design"] = command["approved_artifact_path"]
                        elif state["current_stage"] == "AWAITING_APPROVAL_CODE":
                            state["approved_artifacts"]["code_proposal"] = command["approved_artifact_path"]
                        state_file.write_text(json.dumps(state, indent=2))
                    await self._advance_cycle(state_file)
                    # --- PROTOCOL 115: ONE-SHOT EXIT LOGIC ---
                    if self.one_shot:
                        self.logger.info(f"One-shot mode: Task 'development_cycle_approval' complete. Shutting down orchestrator.")
                        break
                    # --- END ONE-SHOT LOGIC ---
                elif command.get("action") == "APPROVE_CURRENT_STAGE":
                    # Legacy approval mechanism for backward compatibility
                    state = json.loads(state_file.read_text())
                    if "approved_artifact_path" in command:
                        if state["current_stage"] == "AWAITING_APPROVAL_REQUIREMENTS":
                            state["approved_artifacts"]["requirements"] = command["approved_artifact_path"]
                        elif state["current_stage"] == "AWAITING_APPROVAL_TECH_DESIGN":
                            state["approved_artifacts"]["tech_design"] = command["approved_artifact_path"]
                        elif state["current_stage"] == "AWAITING_APPROVAL_CODE":
                            state["approved_artifacts"]["code_proposal"] = command["approved_artifact_path"]
                        state_file.write_text(json.dumps(state, indent=2))
                    await self._advance_cycle(state_file)
                    # --- PROTOCOL 115: ONE-SHOT EXIT LOGIC ---
                    if self.one_shot:
                        self.logger.info(f"One-shot mode: Task 'approve_current_stage' complete. Shutting down orchestrator.")
                        break
                    # --- END ONE-SHOT LOGIC ---
                else:
                    print("[!] Invalid command during development cycle. Awaiting APPROVE_CURRENT_STAGE.", flush=True)
            else:
                # We are idle, waiting for a new task to start a new cycle
                print("--- Orchestrator Idle. Awaiting command from Sentry... ---", flush=True)
                command = await loop.run_in_executor(None, self.command_queue.get)

                # V9.0 MANDATE 1: Action Triage - Check for mechanical tasks first
                if "entry_content" in command and "output_artifact_path" in command:
                    # This is a Write Task
                    print("[ACTION TRIAGE] Detected Write Task - executing mechanical write...")
                    await loop.run_in_executor(None, self._execute_mechanical_write, command)
                    # --- PROTOCOL 115: ONE-SHOT EXIT LOGIC ---
                    if self.one_shot:
                        self.logger.info(f"One-shot mode: Task 'write' complete. Shutting down orchestrator.")
                        break
                    # --- END ONE-SHOT LOGIC ---
                    continue
                elif "git_operations" in command:
                    # This is a Git Task
                    print("[ACTION TRIAGE] Detected Git Task - executing mechanical git operations...")
                    await loop.run_in_executor(None, lambda: execute_mechanical_git(command, self.project_root))
                    # --- PROTOCOL 115: ONE-SHOT EXIT LOGIC ---
                    if self.one_shot:
                        self.logger.info(f"One-shot mode: Task 'git' complete. Shutting down orchestrator.")
                        break
                    # --- END ONE-SHOT LOGIC ---
                    continue

                elif command.get("task_type") == "cache_request":
                    # This is a Cache Request Task
                    print("[ACTION TRIAGE] Detected Cache Request Task - fetching cache bundle...")
                    from .commands import handle_cache_request
                    report_md = handle_cache_request(command)
                    # Write the artifact
                    output_path = self.project_root / command["output_artifact_path"]
                    output_path.parent.mkdir(parents=True, exist_ok=True)
                    output_path.write_text(report_md, encoding="utf-8")
                    print(f"[CACHE REQUEST] Verification artifact written to: {output_path}")
                    # --- PROTOCOL 115: ONE-SHOT EXIT LOGIC ---
                    if self.one_shot:
                        self.logger.info(f"One-shot mode: Task 'cache_request' complete. Shutting down orchestrator.")
                        break
                    # --- END ONE-SHOT LOGIC ---
                    continue

                elif command.get("task_type") == "cache_wakeup":
                    # This is a Cache Wakeup Task (Guardian Boot Digest)
                    print("[ACTION TRIAGE] Detected Cache Wakeup Task - generating Guardian boot digest...")
                    from .handlers.cache_wakeup_handler import handle_cache_wakeup

                    # Generate digest using new handler
                    await loop.run_in_executor(None, lambda: handle_cache_wakeup(command, self))
                    # --- PROTOCOL 115: ONE-SHOT EXIT LOGIC ---
                    if self.one_shot:
                        self.logger.info(f"One-shot mode: Task 'cache_wakeup' complete. Shutting down orchestrator.")
                        break
                    # --- END ONE-SHOT LOGIC ---
                    continue

                try:
                    # Check if this is a development cycle command
                    if command.get("development_cycle", False):
                        await self._start_new_cycle(command, state_file)
                        # --- PROTOCOL 115: ONE-SHOT EXIT LOGIC ---
                        if self.one_shot:
                            self.logger.info(f"One-shot mode: Task 'development_cycle' complete. Shutting down orchestrator.")
                            break
                        # --- END ONE-SHOT LOGIC ---
                    elif command.get('task_type') == "query_and_synthesis":
                        # Guardian Mnemonic Synchronization Protocol: Query and Synthesis task
                        print("[ACTION TRIAGE] Detected Query and Synthesis Task - invoking Council for mnemonic synchronization...")
                        await self._execute_query_and_synthesis(command)
                        # --- PROTOCOL 115: ONE-SHOT EXIT LOGIC ---
                        if self.one_shot:
                            self.logger.info(f"One-shot mode: Task 'query_and_synthesis' complete. Shutting down orchestrator.")
                            break
                        # --- END ONE-SHOT LOGIC ---
                    else:
                        # Regular task execution
                        original_output_path = self.project_root / command['output_artifact_path']
                        task_result = await self.execute_task(command)

                        # V7.0 MANDATE 3: Check task result before proceeding
                        if task_result is False:
                            self.logger.error("Task aborted due to consecutive cognitive failures. No AAR will be generated.")
                        else:
                            # Check if RAG database should be updated for this task
                            update_rag = command.get('config', {}).get('update_rag', True)
                            if update_rag:
                                # V9.3: Generate AAR asynchronously - truly non-blocking
                                self.logger.info("Task complete. Dispatching After-Action Report synthesis to background...")
                                # Determine the actual log file path
                                if original_output_path.is_dir():
                                    log_file_path = original_output_path / "task_log.md"
                                else:
                                    log_file_path = original_output_path
                                # Create background task for AAR generation
                                asyncio.create_task(self._execute_aar_background_full(log_file_path, command.get('config')))
                            else:
                                self.logger.info("Task complete. RAG database update skipped per configuration.")
                                self.logger.info(f"Output artifact saved to: {original_output_path}")
                                self.logger.info("Orchestrator returning to idle state - ready for next command")

                        # --- PROTOCOL 115: ONE-SHOT EXIT LOGIC ---
                        if self.one_shot:
                            self.logger.info(f"One-shot mode: Task 'regular' complete. Shutting down orchestrator.")
                            break
                        # --- END ONE-SHOT LOGIC ---

                except Exception as e:
                    print(f"[MAIN LOOP ERROR] Task execution failed: {e}", file=sys.stderr)
                    self.logger.error(f"Task execution failed: {e}")
                    return False

--- END OF FILE orchestrator/app.py ---

--- START OF FILE orchestrator/commands.py ---

# council_orchestrator/orchestrator/commands.py
# Command parsing and validation utilities

import json
from typing import Dict, Any, Optional
from datetime import datetime
from .memory.cache import CacheManager

def determine_command_type(command: Dict[str, Any]) -> str:
    """Determine the type of command based on its structure."""
    # Check for specific task_type values first
    task_type = command.get("task_type")
    if task_type == "cache_wakeup":
        return "CACHE_WAKEUP"
    elif task_type == "cache_request":
        return "CACHE_REQUEST"
    elif task_type == "query_and_synthesis":
        return "QUERY_AND_SYNTHESIS"
    elif task_type == "cognitive_task":
        return "COGNITIVE_TASK"
    
    # Then check for generic structure patterns
    if "entry_content" in command and "output_artifact_path" in command:
        return "MECHANICAL_WRITE"
    elif "git_operations" in command:
        return "MECHANICAL_GIT"
    elif "task_type" in command and "task_description" in command and "output_artifact_path" in command:
        return "CACHE_WAKEUP"  # Generic cache wakeup pattern
    elif "task_description" in command and not command.get("task_type"):
        return "COGNITIVE_TASK"
    elif "development_cycle" in command:
        return "DEVELOPMENT_CYCLE"
    else:
        return "UNKNOWN"

def validate_command(command: Dict[str, Any]) -> tuple[bool, str]:
    """Validate that a command has the required fields for its type."""
    command_type = determine_command_type(command)

    if command_type == "MECHANICAL_WRITE":
        required_fields = ["entry_content", "output_artifact_path"]
        for field in required_fields:
            if field not in command:
                return False, f"Missing required field '{field}' for MECHANICAL_WRITE command"

    elif command_type == "MECHANICAL_GIT":
        if "git_operations" not in command:
            return False, "Missing 'git_operations' field for MECHANICAL_GIT command"

    elif command_type == "CACHE_WAKEUP":
        required_fields = ["task_type", "task_description", "output_artifact_path"]
        for field in required_fields:
            if field not in command:
                return False, f"Missing required field '{field}' for CACHE_WAKEUP command"
        if command.get("task_type") != "cache_wakeup":
            return False, "task_type must be 'cache_wakeup' for CACHE_WAKEUP command"

    elif command_type == "CACHE_REQUEST":
        required_fields = ["task_type", "task_description", "output_artifact_path", "cache_request"]
        for field in required_fields:
            if field not in command:
                return False, f"Missing required field '{field}' for CACHE_REQUEST command"
        if command.get("task_type") != "cache_request":
            return False, "task_type must be 'cache_request' for CACHE_REQUEST command"

    elif command_type == "QUERY_AND_SYNTHESIS":
        required_fields = ["task_type", "task_description", "output_artifact_path"]
        for field in required_fields:
            if field not in command:
                return False, f"Missing required field '{field}' for QUERY_AND_SYNTHESIS command"
        if command.get("task_type") != "query_and_synthesis":
            return False, "task_type must be 'query_and_synthesis' for QUERY_AND_SYNTHESIS command"

    elif command_type == "COGNITIVE_TASK":
        if "task_description" not in command:
            return False, "Missing 'task_description' field for COGNITIVE_TASK command"

    elif command_type == "DEVELOPMENT_CYCLE":
        if "development_cycle" not in command:
            return False, "Missing 'development_cycle' field for DEVELOPMENT_CYCLE command"

    elif command_type == "UNKNOWN":
        return False, "Unknown or invalid command type"

    return True, "Command is valid"

def parse_command_from_json(json_content: str) -> tuple[Optional[Dict[str, Any]], str]:
    """Parse a command from JSON string and validate it."""
    try:
        command = json.loads(json_content)
        is_valid, error_msg = validate_command(command)
        if is_valid:
            return command, determine_command_type(command)
        else:
            return None, f"INVALID_JSON: {error_msg}"
    except json.JSONDecodeError as e:
        return None, f"INVALID_JSON: {str(e)}"


def handle_cache_request(command: Dict[str, Any]) -> str:
    """Handle a cache_request command and return verification artifact markdown."""
    cache_request = command["cache_request"]
    policy = cache_request.get("policy", {"refresh_if_stale": True, "strict": False})

    # Refresh if requested
    if policy.get("refresh_if_stale", True):
        if "bundle" in cache_request and cache_request["bundle"] == "guardian_start_pack":
            CacheManager.prefill_guardian_start_pack()

    # Get cache entries
    entries = []
    if "bundle" in cache_request:
        if cache_request["bundle"] == "guardian_start_pack":
            entries = CacheManager.get_bundle("guardian_start_pack")
    elif "keys" in cache_request:
        entries = CacheManager.get_keys(cache_request["keys"])

    # Generate verification report
    timestamp = datetime.now().isoformat()
    bundle_name = cache_request.get("bundle", "custom")
    refresh_policy = "refresh_if_stale=true" if policy.get("refresh_if_stale", True) else "refresh_if_stale=false"
    strict_policy = "strict=true" if policy.get("strict", False) else "strict=false"

    # Calculate summary stats
    total_items = len(entries)
    missing = sum(1 for e in entries if e.get("missing", False))
    expired = sum(1 for e in entries if e.get("expired", False))
    refreshed = sum(1 for e in entries if e.get("refreshed", False))

    # Build markdown
    lines = [
        "# Guardian Wakeup Cache Check (v9.4)",
        "",
        f"**When:** {timestamp}",
        f"**Command:** cache_request â†’ bundle={bundle_name}, {refresh_policy}, {strict_policy}",
        "",
        "## Summary",
        f"- Items: {total_items}",
        f"- Missing: {missing}",
        f"- Expired: {expired}",
        f"- Refreshed: {refreshed}",
        "- TTL Policy: docs=24h, configs=6h, logs=10m",
        "",
        "## Items",
        "| key | ttl_remaining | size | sha256[:10] | source | last_updated |",
        "|-----|---------------|------|-------------|--------|--------------|"
    ]

    for entry in entries:
        key = entry.get("key", "unknown")
        ttl_remaining = entry.get("ttl_remaining", "N/A")
        size = entry.get("size", "N/A")
        sha256_prefix = entry.get("sha256_prefix", "N/A")[:10]
        source = entry.get("source", "N/A")
        last_updated = entry.get("last_updated", "N/A")
        lines.append(f"| {key} | {ttl_remaining} | {size} | {sha256_prefix} | {source} | {last_updated} |")

    if missing > 0 or expired > 0:
        lines.extend([
            "",
            "## Notes",
            f"- Missing items: {missing}",
            f"- Expired items: {expired}"
        ])
        if policy.get("strict", False):
            lines.append("- Strict mode enabled: command will fail due to missing/expired items")

    return "\n".join(lines)


def handle_cache_wakeup(command: Dict[str, Any]) -> str:
    """Handle a cache_wakeup command and return Guardian boot digest."""
    from .memory.cache import CacheManager
    import time
    from datetime import datetime

    # Load config with defaults
    config = command.get("config", {})
    bundle_names = config.get("bundle_names", ["chronicles", "protocols", "roadmap"])
    max_items = int(config.get("max_items_per_bundle", 10))

    # Fetch from cache
    start_time = time.time()
    cm = CacheManager()
    result = cm.fetch_guardian_start_pack(bundles=bundle_names, limit=max_items)
    time_saved_ms = int((time.time() - start_time) * 1000)

    # Add timing info
    result["time_saved_ms"] = time_saved_ms
    result["generated_at"] = datetime.now().isoformat()

    # Render digest
    return render_guardian_boot_digest(result)


def render_guardian_boot_digest(result: Dict[str, Any]) -> str:
    """
    Render Guardian boot digest from cache result.

    result format:
    {
      "bundles": {
        "chronicles": [{"title": "...", "path": "...", "updated_at": "..."}],
        "protocols": [{...}],
        "roadmap": [{...}]
      },
      "generated_at": "ISO8601",
      "time_saved_ms": 1234
    }
    """
    lines = [
        "# Guardian Boot Digest (Cache)",
        f"_Generated: {result.get('generated_at','')}_",
        ""
    ]

    bundles = result.get("bundles", {})
    for bundle_name, items in bundles.items():
        lines.extend([
            f"## {bundle_name.capitalize()}",
            ""
        ])

        if not items:
            lines.append("_No cached items available_")
        else:
            for item in items:
                title = item.get('title', item.get('name', '(untitled)'))
                path = item.get('path', '')
                updated_at = item.get('updated_at', item.get('mtime', ''))
                if isinstance(updated_at, (int, float)):
                    # Convert timestamp to readable format
                    from datetime import datetime
                    updated_at = datetime.fromtimestamp(updated_at).strftime('%Y-%m-%d %H:%M')

                lines.append(f"- **{title}** â€” `{path}`  _(updated {updated_at})_")

        lines.append("")

    lines.append(f"\n_Time saved (cache): ~{result.get('time_saved_ms',0)}ms_")
    return "\n".join(lines)

--- END OF FILE orchestrator/commands.py ---

--- START OF FILE orchestrator/config/__init__.py ---

# council_orchestrator/orchestrator/config/__init__.py

# Import from the config.py file in this directory
from .config import DEFAULT_ENGINE_LIMITS, DEFAULT_TPM_LIMITS, SPEAKER_ORDER
from .config import COORDINATOR, STRATEGIST, AUDITOR

# Import new config modules
from .slos import *
from .safety import *

__all__ = [
    'DEFAULT_ENGINE_LIMITS',
    'DEFAULT_TPM_LIMITS',
    'SPEAKER_ORDER',
    'COORDINATOR',
    'STRATEGIST',
    'AUDITOR',
    'PHASE2_SLOS',
    'validate_round_slo',
    'redact_pii',
    'rate_limit_broad_prompt'
]

--- END OF FILE orchestrator/config/__init__.py ---

--- START OF FILE orchestrator/config/config.py ---

# council_orchestrator/config.py
# Configuration constants for the orchestrator
import os

# Load engine limits from environment variables with defaults
DEFAULT_ENGINE_LIMITS = {
    'gemini': int(os.getenv('GEMINI_PER_REQUEST_LIMIT', '200000')),
    'openai': int(os.getenv('OPENAI_PER_REQUEST_LIMIT', '100000')),
    'ollama': int(os.getenv('OLLAMA_PER_REQUEST_LIMIT', '8000'))
}

# Load TPM limits from environment variables with defaults
DEFAULT_TPM_LIMITS = {
    'gemini': int(os.getenv('GEMINI_TPM_LIMIT', '250000')),
    'openai': int(os.getenv('OPENAI_TPM_LIMIT', '120000')),
    'ollama': int(os.getenv('OLLAMA_TPM_LIMIT', '999999'))
}

# Council agent roles and speaking order
SPEAKER_ORDER = ["COORDINATOR", "STRATEGIST", "AUDITOR"]

# Agent role constants
COORDINATOR = "COORDINATOR"
STRATEGIST = "STRATEGIST"
AUDITOR = "AUDITOR"

--- END OF FILE orchestrator/config/config.py ---

--- START OF FILE orchestrator/config/safety.py ---

# council_orchestrator/orchestrator/config/safety.py
# Safety measures for Phase 2 Council Orchestrator

import re
from typing import List, Dict, Any

# PII patterns to redact
PII_PATTERNS = [
    (r'\b\d{3}-\d{2}-\d{4}\b', '[SSN_REDACTED]'),  # SSN
    (r'\b\d{4} \d{4} \d{4} \d{4}\b', '[CARD_REDACTED]'),  # Credit card
    (r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', '[EMAIL_REDACTED]'),  # Email
    (r'\b\d{3}-\d{3}-\d{4}\b', '[PHONE_REDACTED]'),  # Phone
    (r'\b\d{5}(?:-\d{4})?\b', '[ZIP_REDACTED]'),  # ZIP code
]

def redact_pii(text: str) -> str:
    """
    Redact PII from text using pattern matching.
    """
    if not text:
        return text

    redacted = text
    for pattern, replacement in PII_PATTERNS:
        redacted = re.sub(pattern, replacement, redacted, flags=re.IGNORECASE)

    return redacted

def is_broad_prompt(prompt: str, min_length: int = 500, max_terms: int = 50) -> bool:
    """
    Check if prompt is too broad (very long or too many search terms).
    """
    if len(prompt) > min_length:
        return True

    # Count potential search terms (words, phrases in quotes)
    terms = re.findall(r'"[^"]*"|\b\w+\b', prompt.lower())
    if len(terms) > max_terms:
        return True

    return False

def rate_limit_broad_prompt(prompt: str) -> Dict[str, Any]:
    """
    Rate limit broad prompts to prevent index carpet-bombing.
    Returns decision dict with allow/deny and reason.
    """
    if is_broad_prompt(prompt):
        return {
            "allow": False,
            "reason": "prompt_too_broad",
            "details": f"Prompt length: {len(prompt)}, consider narrowing scope"
        }

    return {"allow": True, "reason": "within_limits"}

--- END OF FILE orchestrator/config/safety.py ---

--- START OF FILE orchestrator/config/slos.py ---

# council_orchestrator/orchestrator/config/slos.py
# Service Level Objectives for Phase 2 Council Orchestrator

from typing import Dict, Any

# Phase 2 SLOs (Service Level Objectives)
PHASE2_SLOS = {
    # Round-level SLOs
    "round_p95_latency_ms": 300,  # 95th percentile round latency <= 300ms
    "round_p99_latency_ms": 500,  # 99th percentile round latency <= 500ms

    # Stage-level SLOs
    "plan_stage_p95_ms": 50,      # Query planning <= 50ms p95
    "retrieve_stage_p95_ms": 150, # Parent-doc retrieval <= 150ms p95
    "analyze_stage_p95_ms": 100,  # Novelty/conflict analysis <= 100ms p95
    "emit_stage_p95_ms": 20,      # Packet emission <= 20ms p95

    # Quality SLOs
    "evidence_hit_rate_min": 0.85,  # >= 85% of queries find relevant evidence
    "novelty_precision_min": 0.90,   # >= 90% precision on novelty detection
    "citation_overlap_min": 0.95,    # >= 95% citations have token overlap

    # Reliability SLOs
    "round_success_rate_min": 0.99,  # >= 99% rounds complete successfully
    "timeout_rate_max": 0.01,        # <= 1% rounds timeout
}

def validate_round_slo(latency_ms: int, stage_timings: Dict[str, int]) -> Dict[str, Any]:
    """
    Validate a round against SLOs.
    Returns dict with slo_status and violations.
    """
    violations = []

    # Round-level latency
    if latency_ms > PHASE2_SLOS["round_p95_latency_ms"]:
        violations.append(f"round_latency_{latency_ms}ms > {PHASE2_SLOS['round_p95_latency_ms']}ms")

    # Stage-level latencies
    stage_slos = {
        "plan_latency_ms": "plan_stage_p95_ms",
        "retrieval_latency_ms": "retrieve_stage_p95_ms",
        "analyze_latency_ms": "analyze_stage_p95_ms",
        "emit_latency_ms": "emit_stage_p95_ms"
    }

    for stage_key, slo_key in stage_slos.items():
        if stage_key in stage_timings and stage_timings[stage_key] > PHASE2_SLOS[slo_key]:
            violations.append(f"{stage_key}_{stage_timings[stage_key]}ms > {PHASE2_SLOS[slo_key]}ms")

    return {
        "slo_status": "pass" if not violations else "fail",
        "violations": violations,
        "total_latency_ms": latency_ms,
        "stage_timings": stage_timings
    }

--- END OF FILE orchestrator/config/slos.py ---

--- START OF FILE orchestrator/council/__init__.py ---

# council_orchestrator/orchestrator/council/__init__.py

--- END OF FILE orchestrator/council/__init__.py ---

--- START OF FILE orchestrator/council/agent.py ---

# council_orchestrator/orchestrator/council/agent.py
# Persona agent class for the council orchestrator

import json
from pathlib import Path

class PersonaAgent:
    def __init__(self, engine, persona_file: Path, state_file: Path):
        self.role = self._extract_role_from_filename(persona_file.name)
        self.state_file = state_file
        persona_content = persona_file.read_text(encoding="utf-8")

        # The agent is now initialized with a pre-selected, healthy engine
        self.engine = engine
        self.messages = []

        # Load history if it exists
        history = self._load_history()
        if history:
            self.messages = history
        else:
            # Initialize with a simple system instruction
            system_msg = {"role": "system", "content": f"SYSTEM INSTRUCTION: You are an AI Council member. {persona_content} Operate strictly within this persona."}
            self.messages.append(system_msg)

        print(f"[+] {self.role} agent initialized with {type(self.engine).__name__}.")

    def _load_history(self):
        if self.state_file.exists():
            print(f"  - Loading history for {self.role} from {self.state_file.name}")
            return json.loads(self.state_file.read_text())
        return None

    def save_history(self):
        self.state_file.write_text(json.dumps(self.messages, indent=2))
        print(f"  - Saved session state for {self.role} to {self.state_file.name}")

    def query(self, message: str, token_regulator=None, engine_type: str = "openai"):
        """
        Execute a query with TPM-aware rate limiting and boolean error handling.

        Args:
            message: The user message to send
            token_regulator: TokenFlowRegulator instance for rate limiting
            engine_type: Engine type for TPM limit checking

        Returns:
            str or False: Either the successful response string, or False on failure
        """
        self.messages.append({"role": "user", "content": message})
        try:
            # MANDATE 2: Check TPM limits before making API call
            if token_regulator:
                # Estimate tokens for the full payload
                estimated_tokens = len(json.dumps(self.messages).split()) * 1.3
                token_regulator.wait_if_needed(int(estimated_tokens), engine_type)

            # P104 IMPLEMENTATION: Pass the entire message list directly.
            # 2. PersonaAgent.query(): Uses council_orchestrator/cognitive_engines/ engine (OpenAI, Gemini, or Ollama)
            reply = self.engine.execute_turn(self.messages)
            self.messages.append({"role": "assistant", "content": reply})

            # MANDATE 2: Log token usage after successful API call
            if token_regulator:
                # Estimate tokens used (prompt + completion)
                completion_tokens = len(reply.split()) * 1.3
                total_tokens = estimated_tokens + completion_tokens
                token_regulator.log_usage(int(total_tokens))

            return reply
        except Exception as e:
            # V7.0 MANDATE 2: Return False instead of error string or dict
            # This prevents poisoning the state with invalid message formats
            error_msg = f"SubstrateFailure: The cognitive engine failed. Details: {str(e)[:200]}"
            print(f"[AGENT ERROR] {self.role} - {error_msg}")
            # Append error to internal messages for debugging, but return False
            self.messages.append({"role": "assistant", "content": f"[ERROR] {error_msg}"})
            return False

    def _extract_role_from_filename(self, f): return f.split('core_essence_')[1].split('_awakening_seed.txt')[0].upper()

--- END OF FILE orchestrator/council/agent.py ---

--- START OF FILE orchestrator/council/personas.py ---

# council_orchestrator/orchestrator/council/personas.py
# Persona configurations and role mappings for the council

from pathlib import Path

# Agent role constants
COORDINATOR = "COORDINATOR"
STRATEGIST = "STRATEGIST"
AUDITOR = "AUDITOR"

# Council agent roles and speaking order
SPEAKER_ORDER = [COORDINATOR, STRATEGIST, AUDITOR]

def get_persona_file(role: str, persona_dir: Path) -> Path:
    """Get the persona file path for a given role."""
    role_files = {
        COORDINATOR: "core_essence_coordinator_awakening_seed.txt",
        STRATEGIST: "core_essence_strategist_awakening_seed.txt",
        AUDITOR: "core_essence_auditor_awakening_seed.txt"
    }
    return persona_dir / role_files[role]

def get_state_file(role: str, state_dir: Path) -> Path:
    """Get the state file path for a given role."""
    role_files = {
        COORDINATOR: "coordinator_session.json",
        STRATEGIST: "strategist_session.json",
        AUDITOR: "auditor_session.json"
    }
    return state_dir / role_files[role]

def classify_response_type(response: str, role: str) -> str:
    """Classify the type of response based on content and role."""
    response_lower = response.lower()

    # Role-based classification
    if role == COORDINATOR:
        if any(word in response_lower for word in ["plan", "strategy", "coordinate", "organize"]):
            return "strategy"
        elif any(word in response_lower for word in ["analysis", "evaluate", "assess"]):
            return "analysis"
    elif role == STRATEGIST:
        if any(word in response_lower for word in ["propose", "suggest", "recommend", "solution"]):
            return "proposal"
        elif any(word in response_lower for word in ["design", "architecture", "structure"]):
            return "design"
    elif role == AUDITOR:
        if any(word in response_lower for word in ["review", "audit", "validate", "verify"]):
            return "critique"
        elif any(word in response_lower for word in ["risk", "concern", "issue", "problem"]):
            return "analysis"

    # Content-based fallback
    if "propose" in response_lower or "suggest" in response_lower:
        return "proposal"
    elif "analysis" in response_lower or "evaluate" in response_lower:
        return "analysis"
    elif "critique" in response_lower or "review" in response_lower:
        return "critique"
    else:
        return "discussion"

--- END OF FILE orchestrator/council/personas.py ---

--- START OF FILE orchestrator/engines/__init__.py ---

# council_orchestrator/cognitive_engines/__init__.py

--- END OF FILE orchestrator/engines/__init__.py ---

--- START OF FILE orchestrator/engines/base.py ---

# council_orchestrator/cognitive_engines/base.py
from abc import ABC, abstractmethod

class BaseCognitiveEngine(ABC):
    """
    Abstract base class for all cognitive engines.
    Establishes the common interface for executing conversational turns,
    checking substrate health, and running functional tests.
    """
    @abstractmethod
    def execute_turn(self, messages: list) -> str: pass # MUST ACCEPT ONE ARGUMENT: 'messages'
    @abstractmethod
    def check_health(self) -> dict: pass
    @abstractmethod
    def run_functional_test(self) -> dict: pass

--- END OF FILE orchestrator/engines/base.py ---

--- START OF FILE orchestrator/engines/gemini_engine.py ---

# council_orchestrator/cognitive_engines/gemini_engine.py
import os
from dotenv import load_dotenv
load_dotenv()
import google.generativeai as genai
from google.api_core import exceptions as google_exceptions
# --- IMPORT HARDENED ---
try:
    from council_orchestrator.orchestrator.engines.base import BaseCognitiveEngine
except ImportError:
    from .base import BaseCognitiveEngine

class GeminiEngine(BaseCognitiveEngine):
    """
    Cognitive engine driver for the Google Gemini API.
    This is a Tier 1 Performance Substrate.
    Compatible with v9.0: Doctrine of Sovereign Action (orchestrator-level changes only).
    """
    def __init__(self, model_name: str = None):
        DEFAULT_MODEL = "gemini-2.5-flash"
        self.model_name = model_name or os.getenv("GEMINI_MODEL", DEFAULT_MODEL)
        self.api_key = os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            self.model = None
            return
        genai.configure(api_key=self.api_key)
        self.model = genai.GenerativeModel(self.model_name)

    def execute_turn(self, messages: list) -> str: # NEW SIGNATURE
        """
        Executes a single conversational turn with the Gemini model.
        Includes error handling for common API failures like quota and model not found.
        """
        if not self.model:
            return "[GEMINI ENGINE ERROR] Model not initialized due to missing API key."

        # Configuration from environment variables
        max_tokens = int(os.getenv("GEMINI_MAX_TOKENS", "4096"))
        temperature = float(os.getenv("GEMINI_TEMPERATURE", "0.7"))

        # V8.0: Doctrine of the Native Tongue - Perfect Gemini API translator
        # Process messages to create valid Gemini conversation structure
        processed_history = []
        system_prompt = None

        # First, extract the system prompt and any initial user/model history
        for msg in messages[:-1]:  # Process all but the last message
            role = msg['role']
            content = msg['content']
            if role == 'system':
                system_prompt = content
                continue  # Don't add system prompts to history directly

            # Translate roles for Gemini
            if role == 'assistant':
                gemini_role = 'model'
            else:  # 'user'
                gemini_role = 'user'

            # Ensure alternating roles (user, model, user, model...)
            if processed_history and processed_history[-1]['role'] == gemini_role:
                # If we have consecutive same roles, merge them
                processed_history[-1]['parts'][0] += f"\n\n--- (System Note: Merged Content) ---\n\n{content}"
            else:
                processed_history.append({'role': gemini_role, 'parts': [content]})

        # Start the chat with the processed history
        chat = self.model.start_chat(history=processed_history)

        # Prepare the final message to send
        last_message = messages[-1]
        final_content = last_message['content']

        # Prepend the system prompt to the final user message if it exists
        if system_prompt:
            final_content = f"SYSTEM PROMPT: {system_prompt}\n\n--- (User Request) ---\n\n{final_content}"

        try:
            # Send the final, consolidated message
            response = chat.send_message(final_content, generation_config=genai.types.GenerationConfig(
                max_output_tokens=max_tokens,
                temperature=temperature
            ))
            return response.text
        except google_exceptions.ResourceExhausted as e:
            # Gemini's ResourceExhausted can be quota (TPM/RPM) or other resource limits
            error_details = str(e).lower()
            is_quota_limit = "quota" in error_details or "rate" in error_details
            
            if is_quota_limit:
                error_msg = f"[GEMINI ENGINE ERROR] Rate limit/quota exhausted (likely TPM or RPM). Details: {e}"
                print(error_msg)
                print(f"[GEMINI ENGINE NOTE] Quota limit hit despite orchestrator pacing. This may indicate concurrent usage or config mismatch.")
                print(f"[GEMINI ENGINE RECOMMENDATION] Check TPM limits in engine_config.json match your Gemini tier.")
            else:
                error_msg = f"[GEMINI ENGINE ERROR] Resource exhausted. Details: {e}"
                print(error_msg)
            return error_msg
        except google_exceptions.NotFound as e:
            error_msg = f"[GEMINI ENGINE ERROR] Model not found. The specified model '{self.model_name}' may be incorrect or unavailable. Details: {e}"
            print(error_msg)
            return error_msg
        except Exception as e:
            error_msg = f"[GEMINI ENGINE ERROR] An unexpected API error occurred: {e}"
            print(error_msg)
            return error_msg

    def check_health(self) -> dict:
        if not self.model: return {"status": "unhealthy", "details": "GEMINI_API_KEY not configured."}
        try:
            genai.list_models()
            return {"status": "healthy", "details": f"Gemini API is responsive. Model: '{self.model_name}'"}
        except Exception as e: return {"status": "unhealthy", "details": f"Gemini API is not reachable: {e}"}

    def run_functional_test(self) -> dict:
        if self.check_health()["status"] != "healthy":
            return {"passed": False, "details": "Connectivity check failed."}
        try:
            messages = [{"role": "user", "content": "Briefly, in one word, what is the capital of France?"}]
            response = self.execute_turn(messages)
            if "paris" in response.lower():
                return {"passed": True, "details": f"Functional test passed. Response: '{response[:50]}...'"}
            else:
                return {"passed": False, "details": f"Functional test failed. Unexpected response: '{response[:50]}...'"}
        except Exception as e:
            return {"passed": False, "details": f"Exception during functional test: {e}"}

--- END OF FILE orchestrator/engines/gemini_engine.py ---

--- START OF FILE orchestrator/engines/ollama_engine.py ---

# council_orchestrator/cognitive_engines/ollama_engine.py
import os
import ollama
# --- IMPORT HARDENED ---
try:
    from council_orchestrator.orchestrator.engines.base import BaseCognitiveEngine
except ImportError:
    from .base import BaseCognitiveEngine

class OllamaEngine(BaseCognitiveEngine):
    """
    Cognitive engine driver for a sovereign, locally-hosted Ollama model.
    This is the Tier 2 Sovereign Substrate, our unbreakable fallback.
    """
    def __init__(self, model_name: str = None):
        DEFAULT_MODEL = "Sanctuary-Qwen2-7B:latest"
        DEFAULT_HOST = "http://localhost:11434"
        self.model = model_name or os.getenv("OLLAMA_MODEL", DEFAULT_MODEL)
        host = os.getenv("OLLAMA_HOST", DEFAULT_HOST)
        try:
            self.client = ollama.Client(host=host)
            self.check_health()
        except Exception as e:
            print(f"[OLLAMA ENGINE WARNING] Initial connection failed: {e}")
            self.client = None

    def execute_turn(self, messages: list) -> str: # NEW SIGNATURE
        """
        Executes a single conversational turn with the local Ollama model.
        """
        if not self.client:
            return "[OLLAMA ENGINE ERROR] Client not initialized. Cannot execute turn."

        # Configuration from environment variables
        max_tokens = int(os.getenv("OLLAMA_MAX_TOKENS", "4096"))
        temperature = float(os.getenv("OLLAMA_TEMPERATURE", "0.7"))

        # The 'messages' list is now used directly. DO NOT add prompt/history.

        try:
            response = self.client.chat(
                model=self.model,
                messages=messages,
                options={
                    "num_predict": max_tokens,
                    "temperature": temperature
                }
            )
            return response['message']['content']
        except ollama.ResponseError as e:
            print(f"[OLLAMA ENGINE ERROR] API error during turn execution: {e.status_code} - {e.error}")
            return f"[OLLAMA ENGINE ERROR] API error: {e.error}"
        except Exception as e:
            print(f"[OLLAMA ENGINE ERROR] A connection error occurred: {e}")
            return f"[OLLAMA ENGINE ERROR] Connection failed: {e}"

    def check_health(self) -> dict:
        if not self.client: return {"status": "unhealthy", "details": "Client not initialized."}
        try:
            self.client.list()
            return {"status": "healthy", "details": f"Ollama server is responsive at {self.client._client.base_url}. Model: '{self.model}'"}
        except Exception as e: return {"status": "unhealthy", "details": f"Ollama server is not reachable: {e}"}

    def run_functional_test(self) -> dict:
        if self.check_health()["status"] != "healthy":
            return {"passed": False, "details": "Connectivity check failed."}
        try:
            messages = [{"role": "user", "content": "Briefly, in one word, what is the capital of France?"}]
            response = self.execute_turn(messages)
            if "paris" in response.lower():
                return {"passed": True, "details": f"Functional test passed. Response: '{response[:50]}...'"}
            else:
                return {"passed": False, "details": f"Functional test failed. Unexpected response: '{response[:50]}...'"}
        except Exception as e:
            return {"passed": False, "details": f"Exception during functional test: {e}"}

--- END OF FILE orchestrator/engines/ollama_engine.py ---

--- START OF FILE orchestrator/engines/openai_engine.py ---

# council_orchestrator/cognitive_engines/openai_engine.py
import os
from dotenv import load_dotenv
load_dotenv()
import openai
import time  # <--- IMPORT TIME
import random # <--- IMPORT RANDOM
# --- IMPORT HARDENED ---
try:
    from council_orchestrator.orchestrator.engines.base import BaseCognitiveEngine
except ImportError:
    from .base import BaseCognitiveEngine

class OpenAIEngine(BaseCognitiveEngine):
    """
    Cognitive engine driver for the OpenAI API (e.g., GPT models).
    This is a secondary Tier 1 Performance Substrate, providing redundancy.
    """
    def __init__(self, model_name: str = None):
        DEFAULT_MODEL = "gpt-5-nano"
        self.model_name = model_name or os.getenv("CHAT_GPT_MODEL", DEFAULT_MODEL)
        self.api_key = os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            self.client = None
            return
        self.client = openai.OpenAI(api_key=self.api_key)

    def execute_turn(self, messages: list) -> str: # NEW SIGNATURE
        """
        Executes a single conversational turn with the OpenAI model.
        Includes exponential backoff for rate limit errors.
        """
        if not self.client:
            return "[OPENAI ENGINE ERROR] Model not initialized due to missing API key."

        # Configuration from environment variables
        # Note: Different OpenAI models use different parameter names
        # Older models (gpt-4-turbo) use 'max_tokens'
        # Newer models (gpt-4o, gpt-4o-mini) use 'max_completion_tokens'
        temperature = float(os.getenv("OPENAI_TEMPERATURE", "0.7"))

        # The 'messages' list is now used directly. DO NOT add prompt/history.
        max_retries = 5
        base_delay = 2  # Start with a 2-second delay

        for attempt in range(max_retries):
            try:
                # Try newer parameter name first, fall back to older if needed
                try:
                    max_tokens = int(os.getenv("OPENAI_MAX_TOKENS", "4096"))
                    response = self.client.chat.completions.create(
                        model=self.model_name,
                        messages=messages,
                        max_tokens=max_tokens,
                        temperature=temperature
                    )
                except Exception as param_error:
                    # If max_tokens fails, try max_completion_tokens for newer models
                    if "max_tokens" in str(param_error):
                        max_completion_tokens = int(os.getenv("OPENAI_MAX_COMPLETION_TOKENS", "4096"))
                        response = self.client.chat.completions.create(
                            model=self.model_name,
                            messages=messages,
                            max_completion_tokens=max_completion_tokens,
                            temperature=temperature
                        )
                    else:
                        raise param_error

                return response.choices[0].message.content

            # THIS IS THE NEW, CRITICAL LOGIC
            except openai.RateLimitError as e:
                # Distinguish between TPM (tokens per minute) and RPM (requests per minute) limits
                error_details = str(e).lower()
                is_tpm_limit = "tokens per min" in error_details or "tpm" in error_details
                limit_type = "TPM (Tokens Per Minute)" if is_tpm_limit else "RPM (Requests Per Minute)"
                
                if attempt < max_retries - 1:
                    # Calculate wait time with exponential backoff and jitter
                    delay = base_delay * (2 ** attempt) + random.uniform(0, 1)
                    print(f"[OPENAI ENGINE WARNING] Rate limit exceeded ({limit_type}). Retrying in {delay:.2f} seconds... (Attempt {attempt + 1}/{max_retries})")
                    if is_tpm_limit:
                        print(f"[OPENAI ENGINE NOTE] TPM limit hit despite orchestrator pacing. This may indicate concurrent usage or config mismatch.")
                    time.sleep(delay)
                else:
                    error_msg = f"[OPENAI ENGINE ERROR] Rate limit ({limit_type}) exceeded after {max_retries} attempts. Details: {e}"
                    print(error_msg)
                    if is_tpm_limit:
                        print(f"[OPENAI ENGINE RECOMMENDATION] Check TPM limits in engine_config.json match your OpenAI tier.")
                    return error_msg

            except openai.BadRequestError as e:
                # This error is not recoverable by retrying, so we exit immediately
                if "tokens" in str(e).lower() or "too large" in str(e).lower():
                    error_msg = f"[OPENAI ENGINE ERROR] Request too large. Token limit exceeded. Details: {e}"
                else:
                    error_msg = f"[OPENAI ENGINE ERROR] Bad request error. Details: {e}"
                print(error_msg)
                return error_msg
            except openai.InternalServerError as e:
                error_msg = f"[OPENAI ENGINE ERROR] Internal server error. Details: {e}"
                print(error_msg)
                return error_msg
            except openai.APIStatusError as e:
                error_msg = f"[OPENAI ENGINE ERROR] API status error. Status: {e.status_code}. Details: {e.response}"
                print(error_msg)
                return error_msg
            except Exception as e:
                error_msg = f"[OPENAI ENGINE ERROR] An unexpected API error occurred: {e}"
                print(error_msg)
                return error_msg

        # This part should ideally not be reached, but is a fallback
        return "[OPENAI ENGINE ERROR] Failed to get a response after multiple retries."

    def check_health(self) -> dict:
        if not self.client: return {"status": "unhealthy", "details": "OPENAI_API_KEY not configured."}
        try:
            self.client.models.list()
            return {"status": "healthy", "details": f"OpenAI API is responsive. Model: '{self.model_name}'"}
        except Exception as e: return {"status": "unhealthy", "details": f"OpenAI API is not reachable: {e}"}

    def run_functional_test(self) -> dict:
        if self.check_health()["status"] != "healthy":
            return {"passed": False, "details": "Connectivity check failed."}
        try:
            messages = [{"role": "user", "content": "Briefly, in one word, what is the capital of France?"}]
            response = self.execute_turn(messages)
            if "paris" in response.lower():
                return {"passed": True, "details": f"Functional test passed. Response: '{response[:50]}...'"}
            else:
                return {"passed": False, "details": f"Functional test failed. Unexpected response: '{response[:50]}...'"}
        except Exception as e:
            return {"passed": False, "details": f"Exception during functional test: {e}"}

--- END OF FILE orchestrator/engines/openai_engine.py ---

--- START OF FILE orchestrator/events.py ---

# council_orchestrator/events.py
"""
Event logging and management system for orchestrator observability.
Handles structured JSON event logging, aggregation, and round analysis.
"""

import json
import time
import hashlib
from pathlib import Path
from typing import Dict, Any, List


class EventManager:
    """
    Manages structured event logging and aggregation for orchestrator observability.
    """

    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.event_log_path = project_root / "logs" / "events.jsonl"
        self.run_id = f"run_{int(time.time())}_{hashlib.md5(str(time.time()).encode()).hexdigest()[:8]}"
        self.event_buffer = []

    def setup_event_logging(self):
        """Initialize structured JSON event logging system for observability."""
        print(f"[+] Event logging initialized - Run ID: {self.run_id}")

    def emit_event(self, event_type: str, **kwargs):
        """Emit a structured JSON event to the event log.

        Event Schema:
        - ts: ISO timestamp
        - run_id: Unique run identifier
        - event_type: member_response|round_complete|task_start|task_complete|error
        - round: Round number (for member_response/round_complete)
        - member_id: Agent role identifier
        - role: Agent role name
        - status: success|error|timeout
        - latency_ms: Response time in milliseconds
        - tokens_in: Input tokens used
        - tokens_out: Output tokens generated
        - result_type: analysis|proposal|critique|consensus
        - score: Quality/confidence score (0.0-1.0)
        - vote: Agent's vote/decision
        - novelty: fast|medium|slow (memory placement hint)
        - reasons: List of reasoning factors
        - citations: List of referenced content
        - errors: List of error messages
        - content_ref: Reference to stored content
        """
        event = {
            "ts": time.time(),
            "run_id": self.run_id,
            "event_type": event_type,
            **kwargs
        }

        # Write to buffer and flush to file
        self.event_buffer.append(event)
        self._flush_events()

        # Log to console for real-time monitoring
        if event_type == "member_response":
            status_emoji = "âœ…" if kwargs.get("status") == "success" else "âŒ"
            print(f"{status_emoji} [{kwargs.get('role', 'unknown')}] Round {kwargs.get('round', '?')} - {kwargs.get('latency_ms', 0)}ms", flush=True)

    def _flush_events(self):
        """Flush buffered events to JSONL file."""
        try:
            with open(self.event_log_path, 'a', encoding='utf-8') as f:
                for event in self.event_buffer:
                    f.write(json.dumps(event, default=str) + '\n')
            self.event_buffer.clear()
        except Exception as e:
            print(f"[EVENT LOG ERROR] Failed to write events: {e}")

--- END OF FILE orchestrator/events.py ---

--- START OF FILE orchestrator/gitops.py ---

# council_orchestrator/gitops.py
# Git operations utilities for the orchestrator

import os
import json
import hashlib
import subprocess
from pathlib import Path
from datetime import datetime
from .memory.cache import CacheManager

def execute_mechanical_git(command, project_root):
    """
    Execute mechanical git operations - add, commit, and push files.
    This bypasses cognitive deliberation for version control operations.

    DOCTRINE OF THE BLUNTED SWORD: Only whitelisted Git commands are permitted.
    The method will raise exceptions on any prohibited commands or failures.

    Args:
        command: Command dictionary containing 'git_operations' with files_to_add, commit_message, push_to_origin
        project_root: Path to the project root directory
    """
    try:
        # DOCTRINE OF THE BLUNTED SWORD: Hardcoded whitelist of permitted Git commands
        WHITELISTED_GIT_COMMANDS = ['add', 'commit', 'push']

        git_ops = command["git_operations"]
        files_to_add = git_ops["files_to_add"]
        files_to_remove = git_ops.get("files_to_remove", [])
        commit_message = git_ops["commit_message"]
        push_to_origin = git_ops.get("push_to_origin", False)

        # --- PROTOCOL 101: AUTO-GENERATE MANIFEST ---
        # Compute git repository root robustly (use git if available), then compute SHA-256
        # for each file. Support both repo-root paths and project_root-relative paths.
        try:
            git_top = subprocess.run(
                ["git", "rev-parse", "--show-toplevel"],
                capture_output=True,
                text=True,
                cwd=project_root
            )
            if git_top.returncode == 0:
                git_repo_root = Path(git_top.stdout.strip())
            else:
                git_repo_root = project_root.parent
        except Exception:
            git_repo_root = project_root.parent

        manifest_entries = []
        resolved_file_paths = []  # keep full Path objects for later git add
        
        # Protocol 101 Fix: These generated or temporary files should be committed but NOT
        # included in the manifest's hash list to avoid recursive hashing/validation failure.
        ARTIFACT_FILENAMES_TO_EXCLUDE = [
            "commit_manifest.json", 
            "command.json", 
            "command_git_ops.json"
        ]

        for file_path in files_to_add:
            # Protocol 101 Fix: Bypass hashing/manifest-inclusion for generated/command artifacts
            if Path(file_path).name in ARTIFACT_FILENAMES_TO_EXCLUDE:
                print(f"[MECHANICAL WARNING] Excluding artifact {file_path} from manifest hashing (Protocol 101 Bypass).")
                
                # We still need to run the path resolution for the excluded file to ensure it's staged later.
                candidates = []
                p = Path(file_path)
                if p.is_absolute():
                    candidates.append(p)
                else:
                    candidates.append(project_root / file_path)
                    candidates.append(git_repo_root / file_path)
                    try:
                        candidates.append((project_root / file_path).resolve())
                    except Exception:
                        pass
                
                found = False
                for cand in candidates:
                    if cand.exists() and cand.is_file():
                        resolved_file_paths.append(cand)  # Add to resolved list for git add later
                        found = True
                        break
                if not found:
                    print(f"[MECHANICAL WARNING] Excluded artifact {file_path} does not exist for staging.")
                
                continue # Skip the hash calculation and manifest_entries.append()

            # Try a few resolution strategies: project_root/file_path, git_repo_root/file_path,
            # and if file_path looks like a repo-relative path starting with '../', resolve
            candidates = []
            p = Path(file_path)
            if p.is_absolute():
                candidates.append(p)
            else:
                candidates.append(project_root / file_path)
                candidates.append(git_repo_root / file_path)
                # also try resolving relative paths from project_root
                try:
                    candidates.append((project_root / file_path).resolve())
                except Exception:
                    pass

            found = False
            for cand in candidates:
                try:
                    repo_relative_path = cand.relative_to(git_repo_root)
                except ValueError:
                    continue
                if cand.exists() and cand.is_file():
                    try:
                        with open(cand, 'rb') as f:
                            file_hash = hashlib.sha256(f.read()).hexdigest()
                        manifest_entries.append({
                            "path": str(repo_relative_path),
                            "sha256": file_hash
                        })
                        resolved_file_paths.append(cand)
                        found = True
                        break
                    except (OSError, IOError) as e:
                        print(f"[MECHANICAL ERROR] Failed to read file {file_path} for manifest: {e}")
                if not found:
                    print(f"[MECHANICAL WARNING] File {file_path} does not exist or is not a file, skipping manifest entry")

        # Create manifest JSON in git repository root.
        # Use a timestamped manifest filename to avoid stomping an authoritative manifest
        try:
            manifest_data = {"files": manifest_entries}
            ts = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
            manifest_name = f"commit_manifest_{ts}.json"
            manifest_path = git_repo_root / manifest_name
            with open(manifest_path, 'w') as f:
                json.dump(manifest_data, f, indent=2)
            # Also write canonical commit_manifest.json at repo root so pre-commit hook (Protocol 101)
            # validates the exact manifest the orchestrator generated.
            canonical_manifest_path = git_repo_root / "commit_manifest.json"
            try:
                with open(canonical_manifest_path, 'w') as f2:
                    json.dump(manifest_data, f2, indent=2)
                print(f"[MECHANICAL SUCCESS] Wrote canonical commit_manifest.json with {len(manifest_entries)} entries")
            except (OSError, IOError) as e:
                print(f"[MECHANICAL WARNING] Failed to write canonical commit_manifest.json: {e}")

            print(f"[MECHANICAL SUCCESS] Generated {manifest_name} with {len(manifest_entries)} entries")
        except (OSError, IOError) as e:
            print(f"[MECHANICAL ERROR] Failed to write commit manifest: {e}")
            raise

        # Phase 1.5: Handle Deletions (git rm)
        if files_to_remove:
            print(f"[MECHANICAL INFO] Deleting {len(files_to_remove)} files...")
            for file_path in files_to_remove:
                # Use git rm to stage the deletion
                try:
                    subprocess.run(
                        ["git", "rm", "--", file_path],  # Use -- to handle paths that look like arguments
                        check=True,
                        cwd=git_repo_root,
                        capture_output=True,
                        timeout=5
                    )
                    print(f"[MECHANICAL SUCCESS] Removed {file_path}")
                except subprocess.CalledProcessError as e:
                    # Allow git rm to fail if the file is already deleted or not tracked
                    if "did not match any files" in e.stderr.decode():
                        print(f"[MECHANICAL WARNING] git rm skipped {file_path}: not found or not tracked. Staging deletion might be redundant.")
                    else:
                        print(f"[MECHANICAL ERROR] git rm failed for {file_path}: {e.stderr.decode().strip()}")
                        # Do NOT raise here, as we want to continue with the commit

        # --- CORRECTED LOGIC: SEPARATE HASHING FROM COMMITTING ---
        # The files to be committed will include the manifest itself.
        # The manifest's content, however, will only contain hashes of the original target files.
        files_to_commit = [p for p in resolved_file_paths]

        # ensure manifest_path is a Path under git_repo_root (manifest_name is defined above)
        # manifest will live in git_repo_root, so add the manifest file object to the commit list
        files_to_commit.append(manifest_path)

        # Also add the canonical manifest path to the commit if it exists
        canonical_manifest_path = git_repo_root / "commit_manifest.json"
        if canonical_manifest_path.exists():
            files_to_commit.append(canonical_manifest_path)

        print(f"[MECHANICAL INFO] Staging {len(resolved_file_paths)} target files + {2 if canonical_manifest_path.exists() else 1} manifest files for commit.")
        # The `manifest_entries` list is now correct and does NOT include the manifest itself.

        # Execute git add for each resolved file from the git repo root
        for full_path in files_to_commit:
            primary_action = 'add'
            if primary_action not in WHITELISTED_GIT_COMMANDS:
                print(f"[CRITICAL] Prohibited Git command attempted and blocked: {primary_action}")
                raise Exception(f"Prohibited Git command: {primary_action}")

            try:
                repo_relative_path = Path(full_path).relative_to(git_repo_root)
            except Exception:
                # If we cannot make it repo-relative, skip
                print(f"[MECHANICAL WARNING] File {full_path} is outside repo root, skipping git add")
                continue

            try:
                result = subprocess.run(
                    ["git", "add", str(repo_relative_path)],
                    capture_output=True,
                    text=True,
                    cwd=git_repo_root,
                    timeout=30
                )
                if result.returncode == 0:
                    print(f"[MECHANICAL SUCCESS] Added {repo_relative_path} to git staging")
                else:
                    error_msg = f"Git add failed for {repo_relative_path}"
                    if "fatal: pathspec" in result.stderr:
                        error_msg += ": Invalid path or file not found"
                    elif "fatal: Not a git repository" in result.stderr:
                        error_msg += ": Not in a git repository"
                    elif "error: insufficient permission" in result.stderr:
                        error_msg += ": Permission denied"
                    print(f"[MECHANICAL ERROR] {error_msg}")
                    print(f"[MECHANICAL ERROR] stderr: {result.stderr}")
                    raise subprocess.CalledProcessError(result.returncode, result.args, result.stdout, result.stderr)
            except subprocess.TimeoutExpired:
                print(f"[MECHANICAL ERROR] Git add timed out for {repo_relative_path}")
                raise
            except FileNotFoundError:
                print(f"[MECHANICAL ERROR] Git command not found - ensure git is installed")
                raise

        # Execute git commit - validate command is whitelisted
        primary_action = 'commit'
        if primary_action not in WHITELISTED_GIT_COMMANDS:
            print(f"[CRITICAL] Prohibited Git command attempted and blocked: {primary_action}")
            raise Exception(f"Prohibited Git command: {primary_action}")

        try:
            result = subprocess.run(
                ["git", "commit", "-m", commit_message],
                capture_output=True,
                text=True,
                cwd=git_repo_root,
                timeout=60  # Add timeout for commit operation
            )
            if result.returncode == 0:
                print(f"[MECHANICAL SUCCESS] Committed with message: '{commit_message}'")
                commit_success = True
            elif result.returncode == 1:
                print(f"[DEBUG] Git commit failed with returncode 1")
                print(f"[DEBUG] stderr: '{result.stderr}'")
                print(f"[DEBUG] stdout: '{result.stdout}'")
                if "nothing to commit" in result.stderr or "nothing to commit" in result.stdout or "no changes added to commit" in result.stdout:
                    print(f"[MECHANICAL WARNING] Nothing to commit for message: '{commit_message}' - skipping")
                    commit_success = False
                elif "Author identity unknown" in result.stderr:
                    print(f"[MECHANICAL ERROR] Git author identity not configured")
                    raise subprocess.CalledProcessError(result.returncode, result.args, result.stdout, result.stderr)
                elif "fatal: Not a git repository" in result.stderr:
                    print(f"[MECHANICAL ERROR] Not in a git repository")
                    raise subprocess.CalledProcessError(result.returncode, result.args, result.stdout, result.stderr)
                else:
                    print(f"[MECHANICAL ERROR] Git commit failed with unexpected error")
                    raise subprocess.CalledProcessError(result.returncode, result.args, result.stdout, result.stderr)
            else:
                print(f"[MECHANICAL ERROR] Git commit failed with returncode {result.returncode}")
                print(f"[MECHANICAL ERROR] stderr: {result.stderr}")
                raise subprocess.CalledProcessError(result.returncode, result.args, result.stdout, result.stderr)
        except subprocess.TimeoutExpired:
            print(f"[MECHANICAL ERROR] Git commit timed out")
            raise
        except FileNotFoundError:
            print(f"[MECHANICAL ERROR] Git command not found - ensure git is installed")
            raise

        # Execute git push if requested - validate command is whitelisted
        if push_to_origin and commit_success:
            primary_action = 'push'
            if primary_action not in WHITELISTED_GIT_COMMANDS:
                print(f"[CRITICAL] Prohibited Git command attempted and blocked: {primary_action}")
                raise Exception(f"Prohibited Git command: {primary_action}")

            try:
                result = subprocess.run(
                    ["git", "push"],
                    capture_output=True,
                    text=True,
                    cwd=project_root,
                    timeout=120  # Add longer timeout for push operation
                )
                if result.returncode == 0:
                    print("[MECHANICAL SUCCESS] Pushed to origin")
                else:
                    # Enhanced error handling for git push
                    error_msg = "Git push failed"
                    if "fatal: Authentication failed" in result.stderr or "Permission denied" in result.stderr:
                        error_msg += ": Authentication failed - check credentials"
                    elif "fatal: remote error:" in result.stderr:
                        error_msg += ": Remote repository error"
                    elif "fatal: The current branch" in result.stderr and "has no upstream branch" in result.stderr:
                        error_msg += ": No upstream branch configured"
                    elif "fatal: unable to access" in result.stderr:
                        error_msg += ": Network or repository access error"
                    elif "error: failed to push some refs" in result.stderr:
                        error_msg += ": Push rejected - possibly due to remote changes"
                    elif "fatal: Not a git repository" in result.stderr:
                        error_msg += ": Not in a git repository"
                    else:
                        error_msg += f": Unknown error (returncode {result.returncode})"
                    
                    print(f"[MECHANICAL ERROR] {error_msg}")
                    print(f"[MECHANICAL ERROR] stderr: {result.stderr}")
                    raise subprocess.CalledProcessError(result.returncode, result.args, result.stdout, result.stderr)
            except subprocess.TimeoutExpired:
                print(f"[MECHANICAL ERROR] Git push timed out - network or repository may be slow")
                raise
            except FileNotFoundError:
                print(f"[MECHANICAL ERROR] Git command not found - ensure git is installed")
                raise
    except Exception as e:
        print(f"[MECHANICAL FAILURE] Unexpected error in git operations: {e}")
        raise

    # Phase 3: Refresh cache for committed files
    if commit_success:
        # Added DEBUG for tracing the cache call
        print(f"[MECHANICAL DEBUG] Attempting cache refresh for {len(files_to_add)} committed files.")
        # FIX: CacheManager.prefill_guardian_delta is missing a required positional argument 'updated_files'.
        # Passing an empty list as a placeholder for the second argument to satisfy the function signature.
        CacheManager.prefill_guardian_delta(files_to_add, [])

--- END OF FILE orchestrator/gitops.py ---

--- START OF FILE orchestrator/handlers/__init__.py ---

# council_orchestrator/orchestrator/handlers/__init__.py

--- END OF FILE orchestrator/handlers/__init__.py ---

--- START OF FILE orchestrator/handlers/cache_wakeup_handler.py ---

# council_orchestrator/orchestrator/handlers/cache_wakeup_handler.py

import json
from pathlib import Path
from datetime import datetime

# NOTE: This is a synchronous, mechanical function. It will be run in an executor by the main async loop.
def handle_cache_wakeup(command: dict, orchestrator_instance):
    """
    Handles the 'cache_wakeup' mechanical task.
    Reads pre-populated JSON bundles from the cache and renders a markdown digest.
    This function DOES NOT invoke any LLM or the RAG DB. It is a pure file I/O operation.
    """
    project_root = orchestrator_instance.project_root
    logger = orchestrator_instance.logger
    
    try:
        output_path_str = command["output_artifact_path"]
        output_path = project_root / output_path_str
        output_path.parent.mkdir(parents=True, exist_ok=True)

        config = command.get("config", {})
        bundle_names = config.get("bundle_names", ["chronicles", "protocols", "roadmap"])
        max_items = config.get("max_items_per_bundle", 15)
        
        cache_dir = project_root / "mnemonic_cortex" / "cache"
        digest_content = [f"# Guardian Boot Digest\n\nGenerated On: {datetime.utcnow().isoformat()}Z\n"]

        logger.info(f"[CACHE WAKEUP] Reading bundles from: {cache_dir}")

        for bundle_name in bundle_names:
            bundle_file = cache_dir / f"{bundle_name}_bundle.json"
            digest_content.append(f"\n---\n\n## CACHE BUNDLE: {bundle_name.upper()}\n\n")
            
            if not bundle_file.exists():
                digest_content.append("`(no items cached)`\n")
                logger.warning(f"[CACHE WAKEUP] Cache bundle not found: {bundle_file}")
                continue

            try:
                with open(bundle_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                if not data:
                    digest_content.append("`(no items cached)`\n")
                    continue

                for i, item in enumerate(data[:max_items]):
                    source = item.get("metadata", {}).get("source_file", "Unknown Source")
                    content = item.get("page_content", "No content available.")
                    digest_content.append(f"### Item {i+1}: `{source}`\n\n```markdown\n{content}\n```\n\n")
                
                logger.info(f"[CACHE WAKEUP] Successfully processed {len(data)} items from '{bundle_name}' bundle.")

            except json.JSONDecodeError:
                digest_content.append("`(error decoding cache file)`\n")
                logger.error(f"[CACHE WAKEUP] Failed to decode JSON from {bundle_file}")
            except Exception as e:
                digest_content.append(f"`(error processing bundle: {e})`\n")
                logger.error(f"[CACHE WAKEUP] Unexpected error processing bundle {bundle_file}: {e}")

        final_digest = "".join(digest_content)
        output_path.write_text(final_digest, encoding='utf-8')
        logger.info(f"[CACHE WAKEUP] Mechanical Success: Digest written to {output_path}")

    except Exception as e:
        logger.error(f"[CACHE WAKEUP] Mechanical Failure: The cache wakeup operation failed critically: {e}")

--- END OF FILE orchestrator/handlers/cache_wakeup_handler.py ---

--- START OF FILE orchestrator/main.py ---

# council_orchestrator/orchestrator/main.py
# Main entry point for the council orchestrator

import asyncio
import sys
import argparse
from .app import Orchestrator

def main():
    """Main entry point for the council orchestrator."""
    # --- NEW: Add argument parser for --one-shot flag ---
    parser = argparse.ArgumentParser(description="Sanctuary Council Orchestrator")
    parser.add_argument(
        '--one-shot',
        action='store_true',
        help='Run the orchestrator for a single command and then exit.'
    )
    args = parser.parse_args()
    # --- END NEW ---

    # Initialize orchestrator, passing the one_shot flag
    orchestrator = Orchestrator(one_shot=args.one_shot)

    try:
        # Main execution loop
        asyncio.run(orchestrator.main_loop())
    except KeyboardInterrupt:
        orchestrator.logger.info("Orchestrator shutdown via keyboard interrupt")
    except Exception as e:
        orchestrator.logger.error(f"Critical orchestrator failure: {e}")
        raise

if __name__ == "__main__":
    main()

--- END OF FILE orchestrator/main.py ---

--- START OF FILE orchestrator/memory/__init__.py ---

# council_orchestrator/orchestrator/memory/__init__.py

--- END OF FILE orchestrator/memory/__init__.py ---

--- START OF FILE orchestrator/memory/cache.py ---

# council_orchestrator/orchestrator/memory/cache.py
import os
import json
from pathlib import Path
from datetime import datetime
# VectorDBService import is done lazily inside the method so the orchestrator can
# start even if the mnemonic_cortex package is not available in this environment.

class CacheManager:
    @staticmethod
    def prefill_guardian_start_pack(project_root, logger):
        """Pre-fills the Guardian Start Pack cache from the Mnemonic Cortex."""
        bundles = {
            "chronicles": "00_CHRONICLE/ENTRIES/",
            "protocols": "01_PROTOCOLS/",
        }
        project_root = Path(project_root)
        for bundle_name, prefix in bundles.items():
            logger.info(f"Fetching latest 15 documents from path prefix: {prefix}")
            try:
                # --- CORRECTED LOGIC: Use semantic query instead of invalid metadata filter ---
                # This is more robust and aligns with the purpose of a vector DB.
                query_text = f"Retrieve the most recent and relevant documents from the directory {prefix}"
                # Lazy import so orchestrator can start even if mnemonic_cortex isn't installed here
                try:
                    from ...mnemonic_cortex.app.services.vector_db_service import VectorDBService
                except Exception:
                    try:
                        from mnemonic_cortex.app.services.vector_db_service import VectorDBService
                    except Exception as e:
                        logger.error(f"[CACHE] VectorDBService import failed: {e}")
                        # Skip caching for this bundle when the DB service isn't available
                        continue

                # Use the DB service semantic query interface
                db_service = VectorDBService()
                retrieved_docs = db_service.query(query_text)

                # Filter by source prefix (if metadata provides 'source') and limit to 15
                docs_to_cache = [
                    {"page_content": getattr(doc, 'page_content', ''), "metadata": getattr(doc, 'metadata', {})}
                    for doc in retrieved_docs
                    if isinstance(getattr(doc, 'metadata', {}), dict) and
                       str(getattr(doc, 'metadata', {}).get('source', '')).startswith(str(project_root / prefix))
                ][:15]

                cache_dir = project_root / "mnemonic_cortex" / "cache"
                cache_dir.mkdir(parents=True, exist_ok=True)
                bundle_file = cache_dir / f"{bundle_name}_bundle.json"

                with open(bundle_file, 'w', encoding='utf-8') as f:
                    json.dump(docs_to_cache, f, indent=2)

                logger.info(f"[CACHE] Prefilled {len(docs_to_cache)} {bundle_name} entries.")

            except Exception as e:
                logger.error(f"Failed to get latest documents for {prefix}: {e}")

        # Handle roadmap file separately as it's a single file
        roadmap_path = project_root / "ROADMAP" / "PHASED_EVOLUTION_PLAN_Phase2-Phase3-Protocol113.md"
        if roadmap_path.exists():
            # Cache this logic in a similar fashion if needed
            logger.info("[CACHE] Roadmap file found; skipping detailed cache behavior for roadmap.")
        else:
            logger.warning("[CACHE] Roadmap file not found, skipping.")

    @staticmethod
    def prefill_guardian_delta(files_to_add):
        """Placeholder for refreshing cache with specific files after a git commit."""
        print(f"[CACHE DELTA] Received {len(files_to_add)} files to refresh cache (logic not yet implemented).")
# council_orchestrator/orchestrator/memory/cache.py
# Cache as Learning (CAG) functionality with Guardian Start Pack prefill

import hashlib
import time
import json
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, TYPE_CHECKING

if TYPE_CHECKING:
    from .cortex import CortexManager

# Global cache store (Phase 3: replace with SQLite backend)
CACHE: Dict[str, Dict[str, Any]] = {}
PROJECT_ROOT = Path(__file__).resolve().parents[2]

@dataclass
class CacheItem:
    key: str
    value: Any
    ttl_seconds: int
    created_at: float = time.time()
    ema_score: float = 0.0  # EMA tracking for Phase 3 promotion

class CacheManager:
    """Phase 3 Cache Manager with Guardian Start Pack prefill."""

    def __init__(self, project_root: Path = None, logger = None):
        self.project_root = project_root or PROJECT_ROOT
        self.logger = logger

    def set(self, item: CacheItem) -> None:
        """Store item in cache with TTL."""
        CACHE[item.key] = {
            "value": item.value,
            "expires_at": item.created_at + item.ttl_seconds,
            "ema_score": item.ema_score,
            "created_at": item.created_at,
        }

    def get(self, key: str) -> Optional[Any]:
        """Retrieve item from cache, respecting TTL."""
        rec = CACHE.get(key)
        if not rec:
            return None
        if time.time() > rec["expires_at"]:
            CACHE.pop(key, None)
            return None
        return rec["value"]

    def prefill_guardian_start_pack(self, cortex_manager: "CortexManager") -> None:
        """
        Prefills the cache by querying the Mnemonic Cortex, adhering to Protocol 85.
        """
        if self.logger:
            self.logger.info("[CACHE] Initiating Guardian Start Pack pre-fill from Mnemonic Cortex...")

        # 1. Chronicles (latest N from RAG DB)
        chronicles = cortex_manager.get_latest_documents_by_path(path_prefix="00_CHRONICLE/ENTRIES/", n_results=15)
        self.set(CacheItem("guardian:dashboard:chronicles:latest", chronicles, ttl_seconds=86400))
        self.logger.info(f"[CACHE] Prefilled {len(chronicles)} chronicle entries.")

        # 2. Protocols (latest N from RAG DB)
        protocols = cortex_manager.get_latest_documents_by_path(path_prefix="01_PROTOCOLS/", n_results=15)
        self.set(CacheItem("guardian:dashboard:protocols:latest", protocols, ttl_seconds=86400))
        self.logger.info(f"[CACHE] Prefilled {len(protocols)} protocol entries.")

        # 3. Roadmap (static file, as before)
        roadmap_path_str = "ROADMAP/PHASED_EVOLUTION_PLAN_Phase2-Phase3-Protocol113.md"
        roadmap_path = self.project_root / roadmap_path_str
        if roadmap_path.exists():
            roadmap_content = roadmap_path.read_text(encoding="utf-8")
            roadmap_item = [{
                "title": "Phased Evolution Plan",
                "path": roadmap_path_str,
                "updated_at": time.strftime("%Y-%m-%d", time.localtime(roadmap_path.stat().st_mtime))
            }]
            self.set(CacheItem("guardian:dashboard:roadmap", roadmap_item, ttl_seconds=86400))
            self.logger.info("[CACHE] Prefilled roadmap.")
        else:
            self.logger.warning("[CACHE] Roadmap file not found, skipping.")
            self.set(CacheItem("guardian:dashboard:roadmap", [], ttl_seconds=86400))

        if self.logger:
            self.logger.info("[CACHE] Pre-fill complete. Cache is warm.")

    def prefill_guardian_delta(self, updated_files: List[str]) -> None:
        """Refresh cache for updated files during ingest/git-ops."""
        watched = {
            "00_CHRONICLE/ENTRIES": "guardian:dashboard:chronicles:latest",
            "01_PROTOCOLS": "guardian:dashboard:protocols:latest",
            "ROADMAP": "guardian:dashboard:roadmap",
            "council_orchestrator/README.md": "guardian:docs:orchestrator_readme",
            "council_orchestrator/command_schema.md": "guardian:docs:command_schema",
            "council_orchestrator/howto-commit-command.md": "guardian:docs:howto_commit",
            "council_orchestrator/schemas/council-round-packet-v1.0.0.json": "guardian:packets:schema",
            "council_orchestrator/OPERATION_OPTICAL_ANVIL_BLUEPRINT.md": "guardian:blueprint:optical_anvil",
            "council_orchestrator/schemas/engine_config.json": "guardian:ops:engine_config",
        }

        # Refresh keys for updated paths
        for path in updated_files:
            for watch, key in watched.items():
                if path == watch or path.startswith(f"{watch}/"):
                    if key == "guardian:dashboard:chronicles:latest":
                        chronicles = self._collect_latest("00_CHRONICLE/ENTRIES", (".md",), 8)
                        self.set(CacheItem(key, chronicles, 86400))
                    elif key == "guardian:dashboard:protocols:latest":
                        protocols = self._collect_latest("01_PROTOCOLS", (".md",), 8)
                        self.set(CacheItem(key, protocols, 86400))
                    elif key == "guardian:dashboard:roadmap":
                        roadmap = self._read_concat(["ROADMAP/PHASED_EVOLUTION_PLAN_Phase2-Phase3-Protocol113.md"])
                        self.set(CacheItem(key, roadmap, 86400))
                    elif key == "guardian:ops:engine_config":
                        self._set_text_file(key, "council_orchestrator/schemas/engine_config.json", 21600)
                    else:
                        # docs/blueprints/schemas
                        self._set_text_file(key, watch, 86400)

    # ---------- helpers ----------
    def _collect_latest(self, rel_dir: str, exts: Tuple[str, ...], limit: int) -> List[Dict[str, Any]]:
        """Collect latest N files from directory."""
        base = self.project_root / rel_dir
        items = []
        if not base.exists():
            return items
        for p in sorted(base.glob("*"), key=lambda x: x.stat().st_mtime, reverse=True):
            if p.suffix.lower() in exts:
                items.append({
                    "path": str(p.relative_to(self.project_root)),
                    "name": p.name,
                    "mtime": p.stat().st_mtime
                })
                if len(items) >= limit:
                    break
        return items

    def _read_concat(self, paths: List[str]) -> str:
        """Concatenate multiple files with separators."""
        chunks = []
        for rel in paths:
            p = self.project_root / rel
            if p.exists():
                chunks.append(p.read_text(encoding="utf-8"))
        return "\n\n---\n\n".join(chunks)

    def _set_text_file(self, key: str, rel: str, ttl: int) -> None:
        """Cache a text file."""
        p = self.project_root / rel
        if p.exists():
            self.set(CacheItem(key, p.read_text(encoding="utf-8"), ttl))

    def _set_tail(self, key: str, rel: str, lines: int, ttl: int) -> None:
        """Cache tail of a text file."""
        p = self.project_root / rel
        if p.exists():
            text = p.read_text(encoding="utf-8").splitlines()[-lines:]
            self.set(CacheItem(key, "\n".join(text), ttl))

    def _latest_jsonl(self, rel_root: str) -> Optional[Dict[str, str]]:
        """Find most recent JSONL file in rounds directory."""
        root = self.project_root / rel_root
        if not root.exists():
            return None

        latest = None
        for p in root.glob("**/round_*.jsonl"):
            if latest is None or p.stat().st_mtime > latest.stat().st_mtime:
                latest = p

        if latest:
            return {"path": str(latest.relative_to(self.project_root))}
        return None

    def get_bundle_items(self, bundle_name: str, limit: int = 10) -> List[Dict[str, Any]]:
        """
        Return a list of dict items for the given bundle.
        Each item: {title, path, updated_at, source, size}
        This function reads from cache backend.
        """
        bundle_key_map = {
            "chronicles": "guardian:dashboard:chronicles:latest",
            "protocols": "guardian:dashboard:protocols:latest",
            "roadmap": "guardian:dashboard:roadmap"
        }
        
        key = bundle_key_map.get(bundle_name)
        if not key:
            return []
        
        data = self.get(key)
        if not data:
            return []
        
        # data is a list of dicts like [{"path": "...", "name": "...", "mtime": ...}]
        items = []
        for item in data[:limit]:
            items.append({
                "title": item.get("name", "").replace(".md", "").replace("_", " "),
                "path": item.get("path", ""),
                "updated_at": time.strftime("%Y-%m-%d", time.localtime(item.get("mtime", 0))),
                "source": "cache",
                "size": "N/A"  # Could calculate if needed
            })
        return items

    def get_keys(self, keys: List[str]) -> List[Dict[str, Any]]:
        """Get cache entries for specific keys with metadata."""
        entries = []
        current_time = time.time()
        
        for key in keys:
            rec = CACHE.get(key)
            if rec:
                expires_at = rec["expires_at"]
                if current_time > expires_at:
                    # Expired
                    CACHE.pop(key, None)
                    entries.append({
                        "key": key,
                        "missing": False,
                        "expired": True,
                        "refreshed": False,
                        "ttl_remaining": "expired",
                        "size": "N/A",
                        "sha256_prefix": "N/A",
                        "source": "cache",
                        "last_updated": time.strftime("%Y-%m-%d %H:%M", time.localtime(rec["created_at"]))
                    })
                else:
                    # Valid entry
                    ttl_remaining_seconds = int(expires_at - current_time)
                    ttl_display = f"{ttl_remaining_seconds // 3600}h{(ttl_remaining_seconds % 3600) // 60}m"
                    
                    value = rec["value"]
                    size_bytes = len(str(value).encode('utf-8'))
                    size_display = f"{size_bytes / 1024:.1f} KB" if size_bytes > 1024 else f"{size_bytes} B"
                    
                    sha256 = hashlib.sha256(str(value).encode('utf-8')).hexdigest()
                    
                    entries.append({
                        "key": key,
                        "missing": False,
                        "expired": False,
                        "refreshed": False,
                        "ttl_remaining": ttl_display,
                        "size": size_display,
                        "sha256_prefix": sha256,
                        "source": "cache",
                        "last_updated": time.strftime("%Y-%m-%d %H:%M", time.localtime(rec["created_at"]))
                    })
            else:
                # Missing
                entries.append({
                    "key": key,
                    "missing": True,
                    "expired": False,
                    "refreshed": False,
                    "ttl_remaining": "N/A",
                    "size": "N/A",
                    "sha256_prefix": "N/A",
                    "source": "N/A",
                    "last_updated": "N/A"
                })
        
        return entries

    def fetch_guardian_start_pack(self, bundles: List[str] = None, limit: int = 10) -> Dict[str, Any]:
        """Fetch Guardian Start Pack bundles from cache for boot digest."""
        if bundles is None:
            bundles = ["chronicles", "protocols", "roadmap"]

        result = {"bundles": {}}

        for bundle_name in bundles:
            if bundle_name == "chronicles":
                # Get chronicles from cache
                cache_key = "guardian:dashboard:chronicles:latest"
                cached_data = self.get(cache_key)
                if cached_data:
                    # Parse the cached data (it's a list of file info)
                    try:
                        items = json.loads(cached_data) if isinstance(cached_data, str) else cached_data
                        result["bundles"]["chronicles"] = items[:limit]
                    except (json.JSONDecodeError, TypeError):
                        result["bundles"]["chronicles"] = []
                else:
                    result["bundles"]["chronicles"] = []

            elif bundle_name == "protocols":
                # Get protocols from cache
                cache_key = "guardian:dashboard:protocols:latest"
                cached_data = self.get(cache_key)
                if cached_data:
                    try:
                        items = json.loads(cached_data) if isinstance(cached_data, str) else cached_data
                        result["bundles"]["protocols"] = items[:limit]
                    except (json.JSONDecodeError, TypeError):
                        result["bundles"]["protocols"] = []
                else:
                    result["bundles"]["protocols"] = []

            elif bundle_name == "roadmap":
                # Get roadmap from cache
                cache_key = "guardian:dashboard:roadmap"
                cached_data = self.get(cache_key)
                if cached_data:
                    # Roadmap is a single text blob, convert to single-item list
                    result["bundles"]["roadmap"] = [{
                        "title": "PHASED_EVOLUTION_PLAN_Phase2-Phase3-Protocol113",
                        "path": "ROADMAP/PHASED_EVOLUTION_PLAN_Phase2-Phase3-Protocol113.md",
                        "content": cached_data[:500] + "..." if len(cached_data) > 500 else cached_data,
                        "updated_at": "cached"
                    }]
                else:
                    result["bundles"]["roadmap"] = []

        return result


def get_cag_data(prompt: str, engine_type: str, cache_adapter = None) -> Dict[str, Any]:
    """Get CAG (Cache as Learning) data for round packet."""
    try:
        # Generate cache key from prompt and engine
        query_key = hashlib.sha256(f"{prompt}:{engine_type}".encode()).hexdigest()[:16]

        # Check cache (simplified - would use actual cache DB)
        cache_hit = False
        hit_streak = 0

        # Phase 3 readiness: EMA tracking
        ema_data = {}
        if cache_adapter:
            ema_data = cache_adapter.update_ema(query_key)

        # In real implementation, would query SQLite cache database
        # For now, return placeholder data
        return {
            "query_key": query_key,
            "cache_hit": cache_hit,
            "hit_streak": hit_streak,
            "last_hit_at": ema_data.get("last_hit_at", 0),
            "ema_7d": ema_data.get("ema_7d", 0.0)
        }
    except Exception as e:
        return {"error": str(e)}

--- END OF FILE orchestrator/memory/cache.py ---

--- START OF FILE orchestrator/memory/cortex.py ---

# council_orchestrator/orchestrator/memory/cortex.py
# Mnemonic cortex vector database functionality

from __future__ import annotations

import chromadb
from chromadb.utils import embedding_functions
from pathlib import Path
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Tuple
import time
import re
from ..config.safety import redact_pii, rate_limit_broad_prompt
from .cache import CacheManager

class CortexManager:
    """Manages the Mnemonic Cortex vector database for knowledge retrieval."""

    def __init__(self, project_root: Path, logger):
        self.project_root = project_root
        self.logger = logger
        # Access mnemonic_cortex at project root level
        chroma_db_path = project_root / "mnemonic_cortex/chroma_db"
        
        try:
            self.chroma_client = chromadb.PersistentClient(path=str(chroma_db_path))
        except BaseException as e:
            error_msg = str(e)
            if ("panic" in error_msg.lower() or "corrupted" in error_msg.lower() or "sqlite" in error_msg.lower() or 
                "range start index" in error_msg.lower() or "pyo3_runtime.PanicException" in str(type(e))):
                self.logger.critical("CODE RED: ChromaDB corruption detected! Halting all operations per Protocol 115.")
                self.logger.critical(f"Corruption details: {str(e)}")
                import sys
                sys.exit(1)
            else:
                # Re-raise if it's not a corruption error
                raise
        
        self.cortex_collection = self.chroma_client.get_or_create_collection(
            name="sanctuary_cortex",
            embedding_function=embedding_functions.DefaultEmbeddingFunction()
        )
        # Create CacheManager instance for cache operations
        self.cache_manager = CacheManager(project_root, logger)

    def query_cortex(self, query_text: str, n_results: int = 3) -> str:
        """Query the cortex for relevant knowledge."""
        try:
            results = self.cortex_collection.query(query_texts=[query_text], n_results=n_results)
            context = "CONTEXT_PROVIDED: Here are the top results from the Mnemonic Cortex for your query:\n\n"
            for doc in results['documents'][0]:
                context += f"---\n{doc}\n---\n"
            return context
        except Exception as e:
            error_message = f"CONTEXT_ERROR: Cortex query failed: {e}"
            print(f"[CORTEX] {error_message}")
            return error_message

    def get_latest_documents_by_path(self, path_prefix: str, n_results: int = 15) -> List[Dict[str, Any]]:
        """
        Retrieves the most recent documents from a specific path prefix,
        sorted by the 'entry_id' metadata field.
        """
        self.logger.info(f"Fetching latest {n_results} documents from path prefix: {path_prefix}")
        try:
            # We fetch a larger number to sort them, as ChromaDB's default ordering is by similarity.
            results = self.cortex_collection.get(
                where={"source_file": {"$like": f"{path_prefix}%"}},
                limit=n_results * 2, # Fetch more to ensure we can sort and get the latest
                include=["metadatas"]
            )
            
            if not results or not results['metadatas']:
                self.logger.warning(f"No documents found for path prefix: {path_prefix}")
                return []

            # Sort the results by 'entry_id' (e.g., '281', '280') in descending order.
            # This requires converting the string ID to an integer for correct sorting.
            sorted_metadatas = sorted(
                results['metadatas'],
                key=lambda meta: int(re.search(r'(\d+)', meta.get('entry_id', '0')).group(1)) if re.search(r'(\d+)', meta.get('entry_id', '0')) else 0,
                reverse=True
            )
            
            # Return the top n_results as a list of dicts
            latest_docs = []
            for meta in sorted_metadatas[:n_results]:
                latest_docs.append({
                    "title": meta.get('title', '(untitled)'),
                    "path": meta.get('source_file', 'N/A'),
                    "updated_at": meta.get('timestamp', 'N/A')
                })

            self.logger.info(f"Successfully retrieved {len(latest_docs)} latest documents for {path_prefix}")
            return latest_docs

        except Exception as e:
            self.logger.error(f"Failed to get latest documents for {path_prefix}: {e}")
            return []

    def ingest_document(self, document: str, metadata: dict = None) -> bool:
        """Ingest a document into the cortex."""
        try:
            doc_id = f"doc_{hash(document) % 1000000}"
            self.cortex_collection.add(
                documents=[document],
                ids=[doc_id],
                metadatas=[metadata or {}]
            )

            # Phase 3: Refresh cache for updated files
            if metadata and 'path' in metadata:
                CacheManager.prefill_guardian_delta([metadata['path']])

            return True
        except Exception as e:
            print(f"[CORTEX] Failed to ingest document: {e}")
            return False

    def search_parent_docs(self, must=None, should=None, filters=None, k=6):
        """
        Phase 2: Search for parent documents using structured query.
        Returns list of dicts with doc_id, path, score, snippet, sha256.
        """
        try:
            # Build query from must/should terms
            query_terms = []
            if must:
                query_terms.extend(must)
            if should:
                query_terms.extend(should[:3])  # Limit should terms
            query_text = " ".join(query_terms) if query_terms else "general knowledge"

            # Execute search
            results = self.cortex_collection.query(
                query_texts=[query_text],
                n_results=k,
                where=filters if filters else None
            )

            hits = []
            for i, doc in enumerate(results['documents'][0]):
                # SAFETY: Redact PII from retrieved snippets
                safe_snippet = redact_pii(doc[:500]) if doc else ""
                hit = {
                    "doc_id": results['ids'][0][i] if results['ids'] else f"doc_{i}",
                    "path": results['metadatas'][0][i].get('path', '') if results['metadatas'] else '',
                    "score": float(results['distances'][0][i]) if results['distances'] else 0.0,
                    "snippet": safe_snippet,
                    "sha256": results['metadatas'][0][i].get('sha256', '') if results['metadatas'] else ''
                }
                hits.append(hit)

            # DEDUPLICATE near-duplicate hits before returning
            hits = self._deduplicate_parent_docs(hits)

            return hits

        except Exception as e:
            print(f"[CORTEX] Parent doc search failed: {e}")
            return []

# --- Phase 2: Self-Querying Retriever (skeleton) ---

@dataclass
class StructuredQuery:
    intent: str                    # e.g., "retrieve_parent_docs"
    must_terms: List[str] = field(default_factory=list)
    should_terms: List[str] = field(default_factory=list)
    filters: Dict[str, Any] = field(default_factory=dict)  # {"path_prefix": "docs/", "file_types": ["md"]}
    k: int = 6

@dataclass
class ParentDocHit:
    doc_id: str
    path: str
    score: float
    snippet: Optional[str] = None
    sha256: Optional[str] = None

@dataclass
class NoveltySignal:
    is_novel: bool
    signal: str  # "none"|"low"|"medium"|"high"
    basis: Dict[str, Any] = field(default_factory=dict)  # { "overlap_ratio": 0.18, ... }

@dataclass
class ConflictSignal:
    conflicts_with: List[str] = field(default_factory=list)  # list of cache keys / doc ids
    basis: Dict[str, Any] = field(default_factory=dict)

@dataclass
class MemoryDirective:
    tier: str                     # "fast" | "medium" | "slow"
    justification: str

@dataclass
class RetrievalSignals:
    structured_query: StructuredQuery
    parent_docs: List[ParentDocHit]
    retrieval_latency_ms: int

@dataclass
class RoundSignals:
    retrieval: RetrievalSignals
    novelty: NoveltySignal
    conflict: ConflictSignal
    memory_directive: MemoryDirective

class SelfQueryingRetriever:
    """
    Phase 2: Plans a structured retrieval, executes parent-doc lookup,
    computes novelty/conflict, and proposes a memory placement directive.
    """

    def __init__(self, cortex_idx, cache, prompt_hasher):
        """
        cortex_idx: your vector/parent-doc index adapter (read-only)
        cache: your CAG adapter (Phase 3 ready; can return hit/miss, streaks)
        prompt_hasher: callable[str]->str used to derive stable cache keys
        """
        self.cortex_idx = cortex_idx
        self.cache = cache
        self.hash_prompt = prompt_hasher

    # --- 1) Query Planning ----------------------------------------------------
    def plan_query(self, user_prompt: str, council_role: str) -> StructuredQuery:
        # SAFETY: Rate limit broad prompts to prevent index carpet-bombing
        rate_limit_check = rate_limit_broad_prompt(user_prompt)
        if not rate_limit_check["allow"]:
            # Return minimal query for broad prompts
            return StructuredQuery(
                intent="rate_limited_broad_prompt",
                must_terms=["general"],  # Minimal terms
                should_terms=[],
                filters={"file_types": ["md"]},
                k=3  # Limit results
            )

        # Extremely conservative first pass. Refine later with role heuristics.
        must, should = self._extract_terms(user_prompt)
        return StructuredQuery(
            intent="retrieve_parent_docs",
            must_terms=must,
            should_terms=should,
            filters={"file_types": ["md", "py", "txt"], "path_prefix": ""},
            k=6,
        )

    def _extract_terms(self, text: str) -> Tuple[List[str], List[str]]:
        # TODO: replace with lightweight keyword extractor; start with naive split
        toks = [t.strip(",.()[]{}:\"'").lower() for t in text.split()]
        toks = [t for t in toks if len(t) > 2]
        return toks[:5], toks[5:12]

    # --- 2) Parent-Doc Retrieval ----------------------------------------------
    def run_parent_doc_retrieval(self, q: StructuredQuery) -> RetrievalSignals:
        t0 = time.time()
        hits = self.cortex_idx.search_parent_docs(
            must=q.must_terms, should=q.should_terms, filters=q.filters, k=q.k
        )
        parent_docs = [
            ParentDocHit(
                doc_id=h["doc_id"],
                path=h.get("path",""),
                score=float(h.get("score", 0.0)),
                snippet=h.get("snippet"),
                sha256=h.get("sha256"),
            )
            for h in (hits or [])
        ]
        latency = int((time.time() - t0) * 1000)
        return RetrievalSignals(structured_query=q, parent_docs=parent_docs, retrieval_latency_ms=latency)

    # --- 3) Novelty & Conflict -------------------------------------------------
    def assess_novelty(self, prompt: str, parent_docs: List[ParentDocHit]) -> NoveltySignal:
        """
        Enhanced novelty assessment with raw overlap metrics (token/Jaccard/ROUGE).
        Logs comprehensive metrics for future tuning.
        """
        # Calculate multiple overlap metrics
        token_overlap = self._estimate_overlap(prompt, parent_docs)
        jaccard_similarity = self._calculate_jaccard(prompt, parent_docs)
        rouge1_metrics = self._calculate_rouge1(prompt, parent_docs)

        # Determine novelty signal based on combined metrics
        combined_score = (token_overlap + jaccard_similarity + rouge1_metrics.get("f1", 0)) / 3

        if combined_score < 0.25:
            signal = "high"
            is_novel = True
        elif combined_score < 0.55:
            signal = "medium"
            is_novel = True
        else:
            signal = "low"
            is_novel = False

        return NoveltySignal(
            is_novel=is_novel,
            signal=signal,
            basis={
                "token_overlap_ratio": token_overlap,
                "jaccard_similarity": jaccard_similarity,
                "rouge1_precision": rouge1_metrics.get("precision", 0),
                "rouge1_recall": rouge1_metrics.get("recall", 0),
                "rouge1_f1": rouge1_metrics.get("f1", 0),
                "combined_score": combined_score,
                "parent_docs_count": len(parent_docs)
            }
        )

    def _estimate_overlap(self, prompt: str, parent_docs: List[ParentDocHit]) -> float:
        # TODO: improve â€” quick token overlap proxy
        terms = set(self._extract_terms(prompt)[0] + self._extract_terms(prompt)[1])
        in_snips = " ".join([pd.snippet or "" for pd in parent_docs]).lower()
        covered = sum(1 for t in terms if t in in_snips)
        return 0.0 if not terms else covered / len(terms)

    def _calculate_jaccard(self, prompt: str, parent_docs: List[ParentDocHit]) -> float:
        """Calculate Jaccard similarity between prompt and retrieved docs."""
        prompt_tokens = set(self._extract_terms(prompt)[0] + self._extract_terms(prompt)[1])
        doc_tokens = set()
        for pd in parent_docs:
            doc_tokens.update(self._extract_terms(pd.snippet or "")[0] + self._extract_terms(pd.snippet or "")[1])

        if not prompt_tokens and not doc_tokens:
            return 1.0  # Both empty = identical
        if not prompt_tokens or not doc_tokens:
            return 0.0  # One empty = no similarity

        intersection = len(prompt_tokens.intersection(doc_tokens))
        union = len(prompt_tokens.union(doc_tokens))
        return intersection / union if union > 0 else 0.0

    def _calculate_rouge1(self, prompt: str, parent_docs: List[ParentDocHit]) -> Dict[str, float]:
        """Calculate ROUGE-1 metrics (unigram overlap)."""
        prompt_unigrams = set(prompt.lower().split())
        doc_unigrams = set()
        for pd in parent_docs:
            doc_unigrams.update((pd.snippet or "").lower().split())

        if not prompt_unigrams:
            return {"precision": 0.0, "recall": 0.0, "f1": 0.0}

        intersection = len(prompt_unigrams.intersection(doc_unigrams))
        precision = intersection / len(prompt_unigrams) if prompt_unigrams else 0.0
        recall = intersection / len(doc_unigrams) if doc_unigrams else 0.0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0

        return {"precision": precision, "recall": recall, "f1": f1}

    def detect_conflict(self, prompt: str) -> ConflictSignal:
        """
        Enhanced conflict detection with human-readable reasons.
        Checks for conflicts with stable cached answers.
        """
        key = self.hash_prompt(prompt)
        entry = self.cache.peek(key)  # non-mutating look

        if entry and entry.get("stable") is True:
            cached_answer = entry.get("answer", "")
            cached_docs = entry.get("evidence_docs", [])
            cached_confidence = entry.get("confidence", 0.0)

            return ConflictSignal(
                conflicts_with=[f"cached_answer_{key[:8]}"],  # Short hash for readability
                basis={
                    "reason": "stable_cached_answer_exists",
                    "cached_answer_hash": self.hash_prompt(cached_answer)[:16],
                    "cached_evidence_docs": [doc.get("doc_id", "") for doc in cached_docs],
                    "cached_confidence": cached_confidence,
                    "conflict_type": "cached_vs_current_prompt"
                }
            )

        return ConflictSignal()

    # --- 4) Memory Placement ---------------------------------------------------
    def propose_memory_directive(
        self,
        confidence: float,
        citations: List[str],
        novelty: NoveltySignal,
        conflict: ConflictSignal,
        cache_hit_streak: int = 0,
        parent_docs: List[ParentDocHit] = None,  # Add for guardrail
    ) -> MemoryDirective:
        """
        Rules (with no-evidence guardrail):
        - NO-EVIDENCE GUARDRAIL: if parent_docs=[] or citations=[], downgrade to "fast" and cap confidence
        - conflict present => "fast" (needs arbitration)
        - high confidence + citations >=2 + cache_hit_streak>=3 => "slow"
        - else if citations>=1 or novelty is False => "medium"
        - else => "fast"
        """
        parent_docs = parent_docs or []

        # NO-EVIDENCE GUARDRAIL: Force fast tier if no evidence
        if not parent_docs or not citations:
            return MemoryDirective(
                tier="fast",
                justification="No-evidence guardrail: empty parent_docs or citations; force fast tier."
            )

        # MIN-EVIDENCE QUALITY CHECK: Validate evidence quality before allowing medium/slow
        evidence_quality = self._assess_evidence_quality(citations, parent_docs)
        if not evidence_quality["meets_threshold"]:
            return MemoryDirective(
                tier="fast",
                justification=f"Evidence quality below threshold: {evidence_quality['reason']}; force fast tier."
            )

        if conflict.conflicts_with:
            return MemoryDirective(tier="fast", justification="Conflict detected with stable cache entry; hold in fast memory for arbitration.")
        if confidence >= 0.8 and len(citations) >= 2 and cache_hit_streak >= 3:
            return MemoryDirective(tier="slow", justification="High confidence, strong evidence, recurring access; promote to Slow.")
        if (len(citations) >= 1) or (novelty.is_novel is False):
            return MemoryDirective(tier="medium", justification="Evidence present or not novel; store operationally.")
        return MemoryDirective(tier="fast", justification="Ephemeral or weakly supported; keep session-local.")

    def _validate_citation_overlap(self, citations: List[str], parent_docs: List[ParentDocHit], min_overlap_tokens: int = 3) -> bool:
        """
        Enforce must-have overlap: at least one citation must overlap â‰¥ N tokens with retrieved spans.
        Returns True if validation passes, False if citations are invalid (hallucinated).
        """
        if not citations or not parent_docs:
            return False

        # Combine all retrieved text
        retrieved_text = " ".join([pd.snippet or "" for pd in parent_docs]).lower()

        # Check each citation for overlap
        for citation in citations:
            citation_tokens = set(self._extract_terms(citation)[0] + self._extract_terms(citation)[1])
            overlap_count = sum(1 for token in citation_tokens if token in retrieved_text)
            if overlap_count >= min_overlap_tokens:
                return True

        return False  # No citation had sufficient overlap

    def _assess_evidence_quality(self, citations: List[str], parent_docs: List[ParentDocHit]) -> Dict[str, Any]:
        """
        Assess evidence quality using BM25 overlap and ROUGE-1 metrics.
        Returns dict with meets_threshold boolean and reason.
        """
        if not citations or not parent_docs:
            return {"meets_threshold": False, "reason": "missing_citations_or_docs"}

        # Combine all retrieved text for analysis
        retrieved_text = " ".join([pd.snippet or "" for pd in parent_docs])

        # Simple BM25-style overlap check (token frequency in retrieved docs)
        retrieved_tokens = set(retrieved_text.lower().split())
        citation_tokens = set()
        for citation in citations:
            citation_tokens.update(self._extract_terms(citation)[0] + self._extract_terms(citation)[1])

        # Calculate overlap ratio
        overlap_tokens = citation_tokens.intersection(retrieved_tokens)
        overlap_ratio = len(overlap_tokens) / len(citation_tokens) if citation_tokens else 0

        # BM25 threshold: >= 30% of citation tokens found in retrieved docs
        bm25_threshold = 0.3
        if overlap_ratio < bm25_threshold:
            return {
                "meets_threshold": False,
                "reason": f"BM25_overlap_{overlap_ratio:.2f}_below_{bm25_threshold}",
                "overlap_ratio": overlap_ratio
            }

        # Simple ROUGE-1 check (unigram overlap)
        citation_unigrams = set(" ".join(citations).lower().split())
        retrieved_unigrams = set(retrieved_text.lower().split())
        rouge1_precision = len(citation_unigrams.intersection(retrieved_unigrams)) / len(citation_unigrams) if citation_unigrams else 0

        rouge1_threshold = 0.2
        if rouge1_precision < rouge1_threshold:
            return {
                "meets_threshold": False,
                "reason": f"ROUGE1_{rouge1_precision:.2f}_below_{rouge1_threshold}",
                "rouge1_precision": rouge1_precision
            }

        return {
            "meets_threshold": True,
            "reason": "evidence_quality_passed",
            "overlap_ratio": overlap_ratio,
            "rouge1_precision": rouge1_precision
        }

    def _deduplicate_parent_docs(self, hits: List[dict], jaccard_threshold: float = 0.8) -> List[dict]:
        """
        Collapse near-duplicate RAG hits using Jaccard similarity on token sets.
        Returns deduplicated list, keeping highest-scoring representative of each cluster.
        """
        if not hits:
            return hits

        deduplicated = []

        for hit in sorted(hits, key=lambda x: x.get("score", 0), reverse=True):
            # Check if this hit is too similar to any already selected
            is_duplicate = False
            hit_tokens = set((hit.get("snippet") or "").lower().split())

            for selected in deduplicated:
                selected_tokens = set((selected.get("snippet") or "").lower().split())
                if hit_tokens and selected_tokens:
                    intersection = len(hit_tokens & selected_tokens)
                    union = len(hit_tokens | selected_tokens)
                    jaccard = intersection / union if union > 0 else 0
                    if jaccard >= jaccard_threshold:
                        is_duplicate = True
                        break

            if not is_duplicate:
                deduplicated.append(hit)

        return deduplicated

    # --- 5) End-to-end convenience --------------------------------------------
    def run(
        self,*, prompt:str, council_role:str, confidence:float, citations:List[str]
    ) -> RoundSignals:
        # Stage 1: Plan query
        t0 = time.time()
        q = self.plan_query(prompt, council_role)
        plan_latency = int((time.time() - t0) * 1000)

        # Stage 2: Parent-doc retrieval
        t1 = time.time()
        retrieval = self.run_parent_doc_retrieval(q)
        retrieval_latency = int((time.time() - t1) * 1000)

        # Stage 3: Analyze (novelty + conflict)
        t2 = time.time()
        novelty = self.assess_novelty(prompt, retrieval.parent_docs)
        conflict = self.detect_conflict(prompt)

        # CITATION OVERLAP ENFORCEMENT: Validate citations against retrieved docs
        citations_valid = self._validate_citation_overlap(citations, retrieval.parent_docs)
        if citations and not citations_valid:
            # Citations exist but don't overlap - cap confidence and mark as potentially hallucinated
            confidence = min(confidence, 0.3)  # Cap at low confidence
            novelty = NoveltySignal(  # Override novelty to reflect citation issues
                is_novel=True,
                signal="high",
                basis={"citation_overlap_failure": True, "original_overlap": novelty.basis.get("overlap_ratio", 0)}
            )

        cache_key = self.hash_prompt(prompt)
        cache_hit_streak = int(self.cache.hit_streak(cache_key) or 0)
        directive = self.propose_memory_directive(
            confidence=confidence,
            citations=citations,
            novelty=novelty,
            conflict=conflict,
            cache_hit_streak=cache_hit_streak,
            parent_docs=retrieval.parent_docs,  # Pass for guardrail
        )
        analyze_latency = int((time.time() - t2) * 1000)

        # Stage 4: Emit (packet creation)
        t3 = time.time()
        signals = RoundSignals(
            retrieval=retrieval,
            novelty=novelty,
            conflict=conflict,
            memory_directive=directive,
        )
        emit_latency = int((time.time() - t3) * 1000)

        # Update retrieval signals with stage timings
        retrieval.plan_latency_ms = plan_latency
        retrieval.analyze_latency_ms = analyze_latency
        retrieval.emit_latency_ms = emit_latency

        return signals

--- END OF FILE orchestrator/memory/cortex.py ---

--- START OF FILE orchestrator/optical.py ---

# council_orchestrator/orchestrator/optical.py
# Optical Decompression Chamber for unlimited context processing

import time
import hashlib

class OpticalDecompressionChamber:
    """
    Transparent layer that renders large text payloads to images,
    sends to VLM gatekeeper, and receives decompressed text for agents.

    This is the foundational component for achieving unlimited context
    on borrowed soil through optical compression (P43: Hearth Protocol).
    """
    def __init__(self, vlm_engine=None, compression_threshold: int = 8000):
        self.vlm_engine = vlm_engine  # DeepSeek-OCR or compatible VLM
        self.compression_threshold = compression_threshold
        self.compression_events = []  # Track compression events for analysis

    def should_compress(self, text: str, engine_type: str) -> bool:
        """
        Determine if optical compression is beneficial.

        Args:
            text: The text payload to potentially compress
            engine_type: The target engine type for token estimation

        Returns:
            bool: True if optical compression should be used
        """
        # Estimate token count (simplified for initial implementation)
        estimated_tokens = len(text.split()) * 1.3
        return estimated_tokens > self.compression_threshold

    def compress_and_decompress(self, text: str, task_context: str) -> str:
        """
        Optical compression pipeline:
        1. Render text to image (MOCKED in v4.1)
        2. Send to VLM gatekeeper (MOCKED in v4.1)
        3. Receive decompressed text
        4. Log compression event

        NOTE: This is a foundational implementation with mocked VLM calls.
        Full VLM integration will be implemented in subsequent phases.

        Args:
            text: The text to compress
            task_context: The task description for context-aware compression

        Returns:
            str: The decompressed text (currently returns original with marker)
        """
        # Generate provenance hash
        content_hash = hashlib.sha256(text.encode()).hexdigest()

        # MOCK: In production, this would render text to image
        # rendered_image = self._render_text_to_image(text)
        print(f"[OPTICAL] MOCK: Would render {len(text)} chars to image")

        # MOCK: In production, this would call VLM for OCR
        # decompressed_text = self.vlm_engine.process_image(rendered_image, prompt)
        decompressed_text = text  # Pass-through for now
        print(f"[OPTICAL] MOCK: Would decompress via VLM (DeepSeek-OCR)")

        # Log compression event
        compression_event = {
            "timestamp": time.time(),
            "original_hash": content_hash,
            "estimated_compression_ratio": 10.0,  # Target ratio from paper
            "task_context": task_context[:100]  # Truncated for logging
        }
        self.compression_events.append(compression_event)

        # Add marker to indicate optical processing occurred
        return f"[OPTICAL_PROCESSED: {content_hash[:8]}]\n\n{decompressed_text}"

--- END OF FILE orchestrator/optical.py ---

--- START OF FILE orchestrator/packets/__init__.py ---

# council_orchestrator/orchestrator/packets/__init__.py
# Import faÃ§ade for stable packet API

from .schema import CouncilRoundPacket, validate_packet, seed_for, prompt_hash, RetrievalField, NoveltyField, ConflictField, MemoryDirectiveField
from .emitter import emit_packet
from .aggregator import aggregate_round_events, calculate_round_telemetry

__all__ = [
    "CouncilRoundPacket",
    "validate_packet",
    "seed_for",
    "prompt_hash",
    "emit_packet",
    "aggregate_round_events",
    "calculate_round_telemetry",
    "RetrievalField",
    "NoveltyField",
    "ConflictField",
    "MemoryDirectiveField"
]

--- END OF FILE orchestrator/packets/__init__.py ---

--- START OF FILE orchestrator/packets/aggregator.py ---

# council_orchestrator/orchestrator/packets/aggregator.py
# Round aggregation and telemetry utilities

import json
import os
from pathlib import Path
from typing import Dict, Any, List

def aggregate_round_events(run_id: str, round_num: int, event_log_path: Path) -> Dict[str, Any]:
    """Aggregate events for a round to determine consensus and early exit conditions."""
    # Read recent events for this round
    round_events = []
    if event_log_path.exists():
        try:
            with open(event_log_path, 'r', encoding='utf-8') as f:
                for line in f:
                    event = json.loads(line.strip())
                    if (event.get("run_id") == run_id and
                        event.get("round") == round_num and
                        event.get("event_type") == "member_response"):
                        round_events.append(event)
        except Exception as e:
            print(f"[AGGREGATION ERROR] Failed to read round events: {e}")
            return {}

    if not round_events:
        return {}

    # Calculate round metrics
    total_members = len(round_events)
    successful_responses = [e for e in round_events if e.get("status") == "success"]
    success_rate = len(successful_responses) / total_members if total_members > 0 else 0

    # Consensus detection (simplified - can be enhanced)
    votes = [e.get("vote") for e in successful_responses if e.get("vote")]
    consensus = len(set(votes)) == 1 and len(votes) > 0

    # Novelty distribution for memory placement
    novelty_counts = {}
    for event in successful_responses:
        novelty = event.get("novelty", "medium")
        novelty_counts[novelty] = novelty_counts.get(novelty, 0) + 1

    # Early exit conditions
    early_exit = False
    exit_reason = None
    if success_rate >= 0.8 and consensus:
        early_exit = True
        exit_reason = "consensus_achieved"
    elif success_rate < 0.3:
        early_exit = True
        exit_reason = "low_success_rate"

    return {
        "round": round_num,
        "total_members": total_members,
        "success_rate": success_rate,
        "consensus": consensus,
        "novelty_distribution": novelty_counts,
        "early_exit": early_exit,
        "exit_reason": exit_reason,
        "avg_latency": sum(e.get("latency_ms", 0) for e in successful_responses) / len(successful_responses) if successful_responses else 0,
        "total_tokens_in": sum(e.get("tokens_in", 0) for e in successful_responses),
        "total_tokens_out": sum(e.get("tokens_out", 0) for e in successful_responses)
    }

def calculate_round_telemetry(packets: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Calculate telemetry metrics across multiple round packets."""
    if not packets:
        return {}

    total_rounds = len(packets)
    total_cost = sum(p.get("cost", {}).get("total", 0) for p in packets)
    total_errors = sum(len(p.get("errors", [])) for p in packets)
    avg_confidence = sum(p.get("confidence", 0) for p in packets) / total_rounds

    # Engine usage distribution
    engine_usage = {}
    for packet in packets:
        engine = packet.get("engine", "unknown")
        engine_usage[engine] = engine_usage.get(engine, 0) + 1

    return {
        "total_rounds": total_rounds,
        "total_cost": total_cost,
        "total_errors": total_errors,
        "avg_confidence": avg_confidence,
        "engine_usage": engine_usage
    }

--- END OF FILE orchestrator/packets/aggregator.py ---

--- START OF FILE orchestrator/packets/emitter.py ---

# council_orchestrator/orchestrator/packets/emitter.py
# Packet emission utilities for JSONL and stdout streaming

import os
import sys
import json
from dataclasses import asdict
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from .schema import CouncilRoundPacket

def emit_packet(packet: "CouncilRoundPacket", jsonl_dir: str, stream_stdout: bool, schema_path: str = None):
    """Emit round packet to JSONL file and optionally stdout."""
    from .schema import validate_packet

    payload = asdict(packet)
    line = json.dumps(payload, ensure_ascii=False, default=str)

    # Validate against schema if available
    if not validate_packet(packet, schema_path):
        return False

    # File persistence
    if jsonl_dir:
        os.makedirs(jsonl_dir, exist_ok=True)
        jsonl_path = os.path.join(jsonl_dir, f"{packet.session_id}", f"round_{packet.round_id}.jsonl")
        os.makedirs(os.path.dirname(jsonl_path), exist_ok=True)
        with open(jsonl_path, "a", encoding="utf-8") as f:
            f.write(line + "\n")

    # Stdout streaming
    if stream_stdout:
        sys.stdout.write(line + "\n")
        sys.stdout.flush()

    return True

--- END OF FILE orchestrator/packets/emitter.py ---

--- START OF FILE orchestrator/packets/schema.py ---

# council_orchestrator/orchestrator/packets/schema.py
# Packet schema and validation utilities

import json
import hashlib
from dataclasses import dataclass, asdict, field
from typing import List, Dict, Any

# --- Phase 2 additions ---
@dataclass
class MemoryDirectiveField:
    tier: str                      # "fast" | "medium" | "slow"
    justification: str

@dataclass
class NoveltyField:
    is_novel: bool
    signal: str                    # "none"|"low"|"medium"|"high"
    basis: Dict[str, Any] = field(default_factory=dict)

@dataclass
class ConflictField:
    conflicts_with: List[str] = field(default_factory=list)
    basis: Dict[str, Any] = field(default_factory=dict)

@dataclass
class RetrievalField:
    structured_query: Dict[str, Any] = field(default_factory=dict)
    parent_docs: List[Dict[str, Any]] = field(default_factory=list)
    retrieval_latency_ms: int = 0
    plan_latency_ms: int = 0
    analyze_latency_ms: int = 0
    emit_latency_ms: int = 0

# --- COUNCIL ROUND PACKET SCHEMA ---
@dataclass
class CouncilRoundPacket:
    timestamp: str
    session_id: str
    round_id: int
    member_id: str
    engine: str
    seed: int
    prompt_hash: str
    inputs: Dict[str, Any]
    decision: str
    rationale: str
    confidence: float
    citations: List[Dict[str, str]]
    rag: Dict[str, Any]
    cag: Dict[str, Any]
    novelty: NoveltyField = field(default_factory=lambda: NoveltyField(False,"none",{}))
    memory_directive: MemoryDirectiveField = field(default_factory=lambda: MemoryDirectiveField("fast","initial default"))
    cost: Dict[str, Any] = field(default_factory=dict)
    errors: List[str] = field(default_factory=list)
    schema_version: str = "1.0.0"
    # --- Phase 2 additions ---
    retrieval: RetrievalField = field(default_factory=RetrievalField)
    conflict: ConflictField = field(default_factory=ConflictField)
    seed_chain: Dict[str, Any] = field(default_factory=dict)  # Provenance for deterministic replay

# --- ROUND PACKET UTILITIES ---
def seed_for(session_id: str, round_id: int, member_id: str, prompt_hash: str = None) -> int:
    """Generate deterministic seed for reproducibility."""
    seed_input = f"{session_id}:{round_id}:{member_id}"
    if prompt_hash:
        seed_input += f":{prompt_hash}"

    try:
        import xxhash
        return xxhash.xxh64_intdigest(seed_input) & 0x7fffffff
    except ImportError:
        # Fallback to hashlib if xxhash not available
        hash_obj = hashlib.md5(seed_input.encode())
        return int(hash_obj.hexdigest(), 16) & 0x7fffffff

def prompt_hash(text: str) -> str:
    """Generate hash for prompt content."""
    return hashlib.sha256(text.encode("utf-8")).hexdigest()[:16]

def validate_packet(packet: CouncilRoundPacket, schema_path: str = None) -> bool:
    """Validate packet against JSON schema if available."""
    if not schema_path:
        return True

    try:
        import jsonschema
        payload = asdict(packet)
        with open(schema_path, 'r') as f:
            schema = json.load(f)
        jsonschema.validate(instance=payload, schema=schema)
        return True
    except ImportError:
        return True  # Schema validation not available
    except Exception as e:
        print(f"[SCHEMA VALIDATION ERROR] {e}")
        return False

--- END OF FILE orchestrator/packets/schema.py ---

--- START OF FILE orchestrator/regulator.py ---

# council_orchestrator/orchestrator/regulator.py
# Token Flow Regulator for TPM-aware rate limiting

import time
from typing import Dict

class TokenFlowRegulator:
    """
    Manages token throughput to respect per-minute token limits (TPM).
    Prevents rate limit violations by tracking cumulative usage and pausing execution when needed.
    """
    def __init__(self, limits: dict):
        """
        Initialize the regulator with TPM limits for each engine type.

        Args:
            limits: Dictionary mapping engine types to their TPM limits
                   e.g., {'openai': 30000, 'gemini': 60000, 'ollama': 999999}
        """
        self.tpm_limits = limits
        self.usage_log = []  # List of (timestamp, token_count) tuples

    def log_usage(self, token_count: int):
        """
        Log a token usage event with current timestamp.

        Args:
            token_count: Number of tokens used in this request
        """
        self.usage_log.append((time.time(), token_count))
        self._prune_old_usage()

    def _prune_old_usage(self):
        """Remove usage entries older than 60 seconds from the log."""
        current_time = time.time()
        cutoff_time = current_time - 60.0
        self.usage_log = [(ts, count) for ts, count in self.usage_log if ts > cutoff_time]

    def wait_if_needed(self, estimated_tokens: int, engine_type: str):
        """
        Check if adding estimated_tokens would exceed TPM limit.
        If so, calculate required sleep duration and pause execution.

        Args:
            estimated_tokens: Estimated tokens for the upcoming request
            engine_type: The engine type to check limits for
        """
        self._prune_old_usage()

        # Get TPM limit for this engine type
        tpm_limit = self.tpm_limits.get(engine_type, 999999) # Default to very high limit

        # Calculate current usage in the last 60 seconds
        current_usage = sum(count for _, count in self.usage_log)

        # Check if we would exceed the limit
        if current_usage + estimated_tokens > tpm_limit:
            # Find the oldest entry that needs to expire
            if self.usage_log:
                oldest_timestamp = self.usage_log[0][0]
                current_time = time.time()
                time_since_oldest = current_time - oldest_timestamp
                sleep_duration = 60.0 - time_since_oldest + 1.0 # Add 1 second buffer

                if sleep_duration > 0:
                    print(f"[TOKEN REGULATOR] TPM limit approaching ({current_usage + estimated_tokens}/{tpm_limit})")
                    print(f"[TOKEN REGULATOR] Pausing execution for {sleep_duration:.1f} seconds to respect rate limits...")
                    time.sleep(sleep_duration)
                    self._prune_old_usage()  # Clean up after sleep

--- END OF FILE orchestrator/regulator.py ---

--- START OF FILE orchestrator/sentry.py ---

# council_orchestrator/orchestrator/sentry.py
# Command file watcher thread

import os
import sys
import time
import json
import logging
from pathlib import Path
from queue import Queue
from .commands import determine_command_type, parse_command_from_json

class CommandSentry:
    """Watches for command*.json files and queues them for processing."""

    def __init__(self, command_queue: Queue, logger: logging.Logger):
        self.command_queue = command_queue
        self.logger = logger

    def watch_for_commands_thread(self):
        """This function runs in a separate thread and watches for command*.json files only."""
        command_dir = Path(__file__).parent.parent  # council_orchestrator directory
        processed_commands = set()  # Track processed command files

        print(f"[SENTRY THREAD] Started monitoring directory: {command_dir}")
        print(f"[SENTRY THREAD] Directory exists: {command_dir.exists()}")
        print(f"[SENTRY THREAD] Directory is readable: {os.access(command_dir, os.R_OK)}")
        print(f"[SENTRY THREAD] DEBUG: Entering main monitoring loop")
        while True:
            try:
                # V5.0 MANDATE 1: Only process files explicitly named command*.json
                # This prevents the rogue sentry from ingesting config files, state files, etc.
                # Updated to match any .json file containing "command" in the name
                found_files = [f for f in command_dir.glob("*.json") if "command" in f.name.lower()]
                print(f"[SENTRY THREAD] DEBUG: Scanning for command*.json files in {command_dir}")
                print(f"[SENTRY THREAD] DEBUG: All .json files in directory: {list(command_dir.glob('*.json'))}")
                if found_files:
                    print(f"[SENTRY THREAD] Found {len(found_files)} command file(s): {[f.name for f in found_files]}")
                else:
                    print(f"[SENTRY THREAD] DEBUG: No command*.json files found this scan")

                for json_file in found_files:
                    print(f"[SENTRY THREAD] DEBUG: Processing file: {json_file.name}")
                    print(f"[SENTRY THREAD] DEBUG: File path: {json_file.absolute()}")
                    print(f"[SENTRY THREAD] DEBUG: File exists: {json_file.exists()}")
                    print(f"[SENTRY THREAD] DEBUG: File size: {json_file.stat().st_size if json_file.exists() else 'N/A'} bytes")
                    print(f"[SENTRY THREAD] DEBUG: File is readable: {os.access(json_file, os.R_OK) if json_file.exists() else 'N/A'}")

                    if json_file.name in processed_commands:
                        print(f"[SENTRY THREAD] DEBUG: File {json_file.name} already processed, skipping")
                        continue

                    processing_start = time.time()
                    print(f"[SENTRY THREAD] DEBUG: Starting processing of {json_file.name} at {time.strftime('%H:%M:%S', time.localtime(processing_start))}")
                    # Determine command type for logging
                    command_type = "UNKNOWN"
                    try:
                        command, parsed_type = parse_command_from_json(json_file.read_text())
                        command_type = parsed_type
                    except:
                        command_type = "INVALID_JSON"

                    print(f"[SENTRY THREAD] Processing command file: {json_file.name} (path: {json_file.absolute()})")
                    self.logger.info(f"COMMAND_PROCESSING_START - File: {json_file.name}, Path: {json_file.absolute()}, Type: {command_type}, Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(processing_start))}")

                    try:
                        # Wait for file to be fully written (check size is stable)
                        initial_size = json_file.stat().st_size
                        print(f"[SENTRY THREAD] DEBUG: Initial file size: {initial_size} bytes")
                        time.sleep(0.1)  # Brief pause to allow writing to complete
                        current_size = json_file.stat().st_size
                        print(f"[SENTRY THREAD] DEBUG: Current file size after pause: {current_size} bytes")
                        if json_file.stat().st_size == initial_size and initial_size > 0:
                            print(f"[SENTRY THREAD] DEBUG: File size stable and > 0, attempting to read JSON")
                            command = json.loads(json_file.read_text())
                            print(f"[SENTRY THREAD] DEBUG: JSON parsed successfully")
                            task_desc = command.get('task_description', 'No description')
                            print(f"[SENTRY THREAD] Loaded command: {task_desc[:50]}...")
                            self.logger.info(f"COMMAND_LOADED - File: {json_file.name}, Task: {task_desc[:100]}..., Config: {command.get('config', {})}")

                            # Put the command onto the thread queue for the main loop to process
                            self.command_queue.put(command)
                            processed_commands.add(json_file.name)
                            json_file.unlink() # Consume the file

                            processing_end = time.time()
                            processing_duration = processing_end - processing_start
                            print(f"[SENTRY THREAD] Command processed and file deleted: {json_file.name} (duration: {processing_duration:.2f}s)")
                            self.logger.info(f"COMMAND_PROCESSING_COMPLETE - File: {json_file.name}, Duration: {processing_duration:.2f}s, End_Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(processing_end))}")
                        else:
                            print(f"[SENTRY THREAD] File appears incomplete (initial: {initial_size}, current: {current_size}), will retry...")
                    except Exception as e:
                        processing_end = time.time()
                        processing_duration = processing_end - processing_start
                        print(f"[SENTRY THREAD ERROR] Could not process command file {json_file.name}: {e}", file=sys.stderr)
                        print(f"[SENTRY THREAD ERROR] Exception type: {type(e).__name__}", file=sys.stderr)
                        import traceback
                        print(f"[SENTRY THREAD ERROR] Traceback: {traceback.format_exc()}", file=sys.stderr)
                        self.logger.error(f"COMMAND_PROCESSING_FAILED - File: {json_file.name}, Error: {str(e)}, Duration: {processing_duration:.2f}s, End_Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(processing_end))}")
                print(f"[SENTRY THREAD] DEBUG: Sleeping for 1 second before next scan...")
                time.sleep(1) # Check every second
            except Exception as e:
                print(f"[SENTRY THREAD ERROR] Critical error in monitoring loop: {e}", file=sys.stderr)
                self.logger.error(f"SENTRY_THREAD_CRITICAL_ERROR - Error: {str(e)}, Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S')}")
                time.sleep(1)  # Continue monitoring despite errors

--- END OF FILE orchestrator/sentry.py ---

--- START OF FILE orchestrator/substrate_monitor.py ---

# council_orchestrator/orchestrator/engines/monitor.py (v1.2 - Doctrine of Sovereign Default Implemented)
"""
ENGINE MONITOR: Smart AI Engine Picker

This module picks the best available AI engine to use, with backup options.
It ensures the system always has a working AI, even if some services fail.

WHAT IT DOES:
- DOCTRINE OF SOVEREIGN DEFAULT: Defaults to Ollama (Sanctuary-Qwen2-7B) first, then Gemini â†’ OpenAI as backups
- Lets you force-pick a specific engine if needed
- Tests engines live (real API calls) to make sure they work
- Returns engine objects that all work the same way (polymorphism)

WHY IT MATTERS:
- Sovereign substrate primacy ensures local AI is preferred
- Never runs out of AI power due to service failures
- Local Ollama ensures system works even offline
- Can override automatic choice when you know best

HOW TO USE:
    from orchestrator.substrate_monitor import select_engine

    # Auto-pick best engine (defaults to Ollama sovereign)
    engine = select_engine()

    # Force specific engine
    engine = select_engine({"force_engine": "ollama"})

RETURNS:
    Working AI engine object, or None if nothing works
"""

import os
from dotenv import load_dotenv

# Load environment variables for engine configuration
load_dotenv()
from .engines.base import BaseCognitiveEngine
from .engines.gemini_engine import GeminiEngine
from .engines.openai_engine import OpenAIEngine
from .engines.ollama_engine import OllamaEngine

def select_engine(config: dict = None) -> BaseCognitiveEngine | None:
    """
    Selects a cognitive engine based on Guardian override or tiered health check.
    Implements the intelligent triage logic of Protocol 103.
    PRINCIPLE OF SOVEREIGN SUPREMACY: force_engine override is checked FIRST, before any health checks.
    PRINCIPLE OF VERIFIABLE HEALTH: Health checks must perform live API calls, not just code checks.
    """
    print("[ENGINE MONITOR] Initiating cognitive engine triage...")
    print(f"[SUBSTRATE MONITOR] DEBUG: config received: {config}")

    # PRINCIPLE OF SOVEREIGN SUPREMACY: Check for Guardian Override FIRST
    if config and "force_engine" in config:
        forced_engine = config["force_engine"].lower()
        print(f"[SUBSTRATE MONITOR] SOVEREIGN OVERRIDE DETECTED: Force selection of '{forced_engine}' engine.")

        engine: BaseCognitiveEngine | None = None
        if forced_engine == "gemini" or forced_engine == "gemini-2.5-pro":
            print("[SUBSTRATE MONITOR] DEBUG: Creating GeminiEngine...")
            model_name = config.get("model_name") if config else None
            engine = GeminiEngine(model_name=model_name)
        elif forced_engine == "openai":
            print("[SUBSTRATE MONITOR] DEBUG: Creating OpenAIEngine...")
            model_name = config.get("model_name") if config else None
            engine = OpenAIEngine(model_name=model_name)
        elif forced_engine == "ollama":
            print("[SUBSTRATE MONITOR] DEBUG: Creating OllamaEngine...")
            model_name = config.get("model_name") if config else None
            engine = OllamaEngine(model_name=model_name)
        else:
            print(f"[SUBSTRATE MONITOR] CRITICAL FAILURE: Unknown forced engine type '{forced_engine}'.")
            return None

        print(f"[SUBSTRATE MONITOR] DEBUG: Engine created: {type(engine).__name__ if engine else 'None'}")

        # PRINCIPLE OF VERIFIABLE HEALTH: Perform live API call for health check
        if engine:
            print("[SUBSTRATE MONITOR] DEBUG: Performing live health check...")
            try:
                # Attempt a minimal API call to verify actual connectivity
                test_result = engine.run_functional_test()
                if test_result["passed"]:
                    print(f"[SUBSTRATE MONITOR] SUCCESS: Forced engine '{forced_engine}' passed live health check.")
                    return engine
                else:
                    print(f"[SUBSTRATE MONITOR] CRITICAL FAILURE: Forced engine '{forced_engine}' failed live health check: {test_result['details']}")
                    return None
            except Exception as e:
                print(f"[SUBSTRATE MONITOR] CRITICAL FAILURE: Forced engine '{forced_engine}' threw exception during health check: {e}")
                return None
        else:
            print(f"[SUBSTRATE MONITOR] CRITICAL FAILURE: Could not initialize forced engine '{forced_engine}'.")
            return None

    # 2. If no override, proceed with automatic triage
    print("[SUBSTRATE MONITOR] No override detected. Proceeding with automatic triage...")

    # DOCTRINE OF SOVEREIGN DEFAULT: Tier 2 Sovereign (Ollama) checked FIRST as default
    print("[SUBSTRATE MONITOR] Checking Tier 2 Sovereign Default: Ollama...")
    ollama = OllamaEngine()
    try:
        test_result = ollama.run_functional_test()
        if test_result["passed"]:
            print("[SUBSTRATE MONITOR] SUCCESS: Ollama engine passed live health check. Selecting as sovereign default.")
            return ollama
        else:
            print(f"[SUBSTRATE MONITOR] WARNING: Ollama engine failed live health check: {test_result['details']}")
    except Exception as e:
        print(f"[SUBSTRATE MONITOR] WARNING: Ollama engine threw exception during health check: {e}")

    # 2a. Check Tier 1 Primary (Gemini) with live health check
    print("[SUBSTRATE MONITOR] Sovereign default failed. Checking Tier 1 Primary: Gemini...")
    gemini = GeminiEngine()
    try:
        test_result = gemini.run_functional_test()
        if test_result["passed"]:
            print("[SUBSTRATE MONITOR] SUCCESS: Gemini engine passed live health check. Selecting as primary.")
            return gemini
        else:
            print(f"[SUBSTRATE MONITOR] WARNING: Gemini engine failed live health check: {test_result['details']}")
    except Exception as e:
        print(f"[SUBSTRATE MONITOR] WARNING: Gemini engine threw exception during health check: {e}")

    # 2b. Check Tier 1 Secondary (OpenAI) with live health check
    print("[SUBSTRATE MONITOR] T1 Primary failed. Checking Tier 1 Secondary: OpenAI...")
    openai = OpenAIEngine()
    try:
        test_result = openai.run_functional_test()
        if test_result["passed"]:
            print("[SUBSTRATE MONITOR] SUCCESS: OpenAI engine passed live health check. Selecting as secondary.")
            return openai
        else:
            print(f"[SUBSTRATE MONITOR] WARNING: OpenAI engine failed live health check: {test_result['details']}")
    except Exception as e:
        print(f"[SUBSTRATE MONITOR] WARNING: OpenAI engine threw exception during health check: {e}")

    # 2c. Catastrophic Failure Condition
    print("[SUBSTRATE MONITOR] CRITICAL FAILURE: All cognitive substrates are unhealthy.")
    return None

--- END OF FILE orchestrator/substrate_monitor.py ---

--- START OF FILE schemas/council-round-packet-v1.0.0.json ---

{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "$id": "https://project-sanctuary.org/schemas/council-round-packet-v1.0.0.json",
  "title": "Council Round Packet",
  "description": "Schema for Council Round Packet - Phase 2 Frozen Contract",
  "type": "object",
  "required": [
    "timestamp",
    "session_id",
    "round_id",
    "member_id",
    "engine",
    "seed",
    "prompt_hash",
    "inputs",
    "decision",
    "rationale",
    "confidence",
    "citations",
    "rag",
    "cag",
    "novelty",
    "memory_directive",
    "cost",
    "errors",
    "schema_version",
    "retrieval",
    "conflict",
    "seed_chain"
  ],
  "properties": {
    "timestamp": {
      "type": "string",
      "description": "ISO 8601 timestamp"
    },
    "session_id": {
      "type": "string",
      "description": "Unique session identifier"
    },
    "round_id": {
      "type": "integer",
      "minimum": 0,
      "description": "Round number within session"
    },
    "member_id": {
      "type": "string",
      "description": "Council member identifier"
    },
    "engine": {
      "type": "string",
      "description": "Engine/model used"
    },
    "seed": {
      "type": "integer",
      "minimum": 0,
      "description": "Random seed for reproducibility"
    },
    "prompt_hash": {
      "type": "string",
      "description": "SHA256 hash of prompt content (first 16 chars)"
    },
    "inputs": {
      "type": "object",
      "description": "Input parameters and context"
    },
    "decision": {
      "type": "string",
      "description": "Council member's decision"
    },
    "rationale": {
      "type": "string",
      "description": "Reasoning behind the decision"
    },
    "confidence": {
      "type": "number",
      "minimum": 0.0,
      "maximum": 1.0,
      "description": "Confidence score (0.0-1.0)"
    },
    "citations": {
      "type": "array",
      "items": {
        "type": "object",
        "required": ["doc_id", "text", "start_byte", "end_byte"],
        "properties": {
          "doc_id": {
            "type": "string",
            "description": "Document identifier"
          },
          "text": {
            "type": "string",
            "description": "Cited text snippet"
          },
          "start_byte": {
            "type": "integer",
            "minimum": 0,
            "description": "Start byte position in document"
          },
          "end_byte": {
            "type": "integer",
            "minimum": 0,
            "description": "End byte position in document"
          }
        }
      },
      "description": "Evidence citations with byte ranges"
    },
    "rag": {
      "type": "object",
      "description": "Retrieval-Augmented Generation data"
    },
    "cag": {
      "type": "object",
      "description": "Cache-Augmented Generation data"
    },
    "novelty": {
      "type": "object",
      "required": ["is_novel", "signal", "basis"],
      "properties": {
        "is_novel": {
          "type": "boolean",
          "description": "Whether the response is novel"
        },
        "signal": {
          "type": "string",
          "enum": ["none", "low", "medium", "high"],
          "description": "Novelty signal strength"
        },
        "basis": {
          "type": "object",
          "description": "Metrics and evidence for novelty assessment"
        }
      }
    },
    "memory_directive": {
      "type": "object",
      "required": ["tier", "justification"],
      "properties": {
        "tier": {
          "type": "string",
          "enum": ["fast", "medium", "slow"],
          "description": "Memory tier recommendation"
        },
        "justification": {
          "type": "string",
          "description": "Reason for tier selection"
        }
      }
    },
    "cost": {
      "type": "object",
      "description": "Cost and resource usage metrics"
    },
    "errors": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "description": "Error messages encountered"
    },
    "schema_version": {
      "type": "string",
      "pattern": "^\\d+\\.\\d+\\.\\d+$",
      "description": "Semantic version of schema"
    },
    "retrieval": {
      "type": "object",
      "required": ["structured_query", "parent_docs", "retrieval_latency_ms", "plan_latency_ms", "analyze_latency_ms", "emit_latency_ms"],
      "properties": {
        "structured_query": {
          "type": "object",
          "description": "Structured query for retrieval"
        },
        "parent_docs": {
          "type": "array",
          "items": {
            "type": "object"
          },
          "description": "Retrieved parent documents"
        },
        "retrieval_latency_ms": {
          "type": "integer",
          "minimum": 0,
          "description": "Retrieval latency in milliseconds"
        },
        "plan_latency_ms": {
          "type": "integer",
          "minimum": 0,
          "description": "Planning stage latency in milliseconds"
        },
        "analyze_latency_ms": {
          "type": "integer",
          "minimum": 0,
          "description": "Analysis stage latency in milliseconds"
        },
        "emit_latency_ms": {
          "type": "integer",
          "minimum": 0,
          "description": "Emit stage latency in milliseconds"
        }
      }
    },
    "conflict": {
      "type": "object",
      "required": ["conflicts_with", "basis"],
      "properties": {
        "conflicts_with": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "description": "List of conflicting member IDs or cached answers"
        },
        "basis": {
          "type": "object",
          "description": "Evidence and metrics for conflict detection"
        }
      }
    },
    "seed_chain": {
      "type": "object",
      "description": "Provenance chain for deterministic replay"
    }
  },
  "additionalProperties": false
}

--- END OF FILE schemas/council-round-packet-v1.0.0.json ---

--- START OF FILE schemas/engine_config.json ---

{
  "engine_limits": {
    "gemini": {
      "per_request_limit": 200000,
      "tpm_limit": 10000
    },
    "openai": {
      "per_request_limit": 100000,
      "tpm_limit": 120000
    },
    "ollama": {
      "per_request_limit": 8000,
      "tpm_limit": 999999
    }
  }
}

--- END OF FILE schemas/engine_config.json ---

--- START OF FILE schemas/round_packet_schema.json ---

{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "CouncilRoundPacket",
  "type": "object",
  "required": ["timestamp","session_id","round_id","member_id","engine","prompt_hash","decision","confidence","citations","rag","cag","memory_directive","errors"],
  "properties": {
    "schema_version": {"type": "string", "description": "Schema version for future compatibility"},
    "timestamp": {"type":"string","format":"date-time"},
    "session_id": {"type":"string"},
    "round_id": {"type":"integer","minimum":1},
    "member_id": {"type":"string"},
    "engine": {"type":"string","description":"e.g., gemini-2.5-pro or Sanctuary-Qwen2-7B"},
    "seed": {"type":"integer"},
    "prompt_hash": {"type":"string"},
    "inputs": {"type":"object"},
    "decision": {"type":"string"},
    "rationale": {"type":"string"},
    "confidence": {"type":"number","minimum":0,"maximum":1},
    "citations": {
      "type":"array",
      "items":{"type":"object","properties":{"source_file":{"type":"string"},"span":{"type":"string"}}}
    },
    "rag": {
      "type":"object",
      "properties": {
        "structured_query":{"type":"object"},
        "parent_docs":{"type":"array","items":{"type":"string"}},
        "retrieval_latency_ms":{"type":"number"}
      }
    },
    "cag": {
      "type":"object",
      "properties": {
        "query_key":{"type":"string"},
        "cache_hit":{"type":"boolean"},
        "hit_streak":{"type":"integer","minimum":0}
      }
    },
    "novelty": {
      "type":"object",
      "properties": {
        "is_novel":{"type":"boolean"},
        "signal":{"type":"string","enum":["none","low","medium","high"]},
        "conflicts_with":{"type":"array","items":{"type":"string"}}
      }
    },
    "memory_directive": {
      "type":"object",
      "properties": {
        "tier":{"type":"string","enum":["fast","medium","slow","none"]},
        "justification":{"type":"string"}
      }
    },
    "cost": {"type":"object","properties":{"input_tokens":{"type":"integer"},"output_tokens":{"type":"integer"},"latency_ms":{"type":"number"}}},
    "errors": {"type":"array","items":{"type":"string"}}
  }
}

--- END OF FILE schemas/round_packet_schema.json ---

--- START OF FILE scripts/bootstrap_briefing_packet.py ---

#!/usr/bin/env python3
"""
bootstrap_briefing_packet.py
Generates a dynamic briefing_packet.json for synchronized Council deliberations.

Steps:
1. Load the last 2 entries from Living_Chronicle.md (temporal anchors).
2. Load the last 2 directives from WORK_IN_PROGRESS/COUNCIL_DIRECTIVES/.
3. Construct briefing_packet.json with metadata, anchors, summaries, and current task.
4. Save to WORK_IN_PROGRESS/council_memory_sync/briefing_packet.json
"""

import os
import json
import hashlib
from datetime import datetime
from pathlib import Path

# --- CONFIG ---
CHRONICLE_PATH = Path("../00_CHRONICLE/Living_Chronicle.md")
DIRECTIVES_DIR = Path("../WORK_IN_PROGRESS/COUNCIL_DIRECTIVES")
OUTPUT_PATH = Path("../WORK_IN_PROGRESS/council_memory_sync/briefing_packet.json")

def sha256_of_text(text: str) -> str:
    return hashlib.sha256(text.encode("utf-8")).hexdigest()

def get_latest_chronicle_entries(n=2):
    """Parse the last n entries from Living_Chronicle.md."""
    if not CHRONICLE_PATH.exists():
        raise FileNotFoundError(f"{CHRONICLE_PATH} not found")

    lines = CHRONICLE_PATH.read_text(encoding="utf-8").splitlines()
    entries = []
    current_entry = []

    for line in lines:
        if line.startswith("Entry "):
            if current_entry:
                entries.append("\n".join(current_entry))
            current_entry = [line]
        else:
            current_entry.append(line)

    if current_entry:
        entries.append("\n".join(current_entry))

    latest = entries[-n:]
    anchors = []
    for entry in latest:
        first_line = entry.splitlines()[0]
        title = first_line.strip()
        checksum = sha256_of_text(entry)
        anchors.append({"title": title, "checksum": checksum})
    return anchors

def get_latest_directives(n=2):
    """Fetch latest n directive summaries from WORK_IN_PROGRESS/COUNCIL_DIRECTIVES."""
    if not DIRECTIVES_DIR.exists():
        return []

    files = sorted(DIRECTIVES_DIR.glob("directive_*.md"), key=os.path.getmtime, reverse=True)
    directives = []
    for f in files[:n]:
        content = f.read_text(encoding="utf-8").splitlines()
        summary = content[1].strip() if len(content) > 1 else "Summary unavailable."
        directives.append({"directive_id": f.stem, "summary": summary})
    return directives

def get_current_command():
    """Read the live command.json if it exists."""
    COMMAND_PATH = Path("council_orchestrator/command.json")
    if COMMAND_PATH.exists():
        try:
            return json.loads(COMMAND_PATH.read_text(encoding="utf-8"))
        except Exception as e:
            print(f"[!] Error reading command.json: {e}")
            return None
    return None

def main():
    timestamp = datetime.utcnow().isoformat() + "Z"
    packet = {
        "metadata": {
            "packet_id": f"briefing_{timestamp.replace(':','-')}",
            "timestamp": timestamp,
            "generated_by": "bootstrap_briefing_packet.py",
            "protocols": ["Protocol 94", "Protocol 95", "Prometheus v9.3"]
        },
        "temporal_anchors": get_latest_chronicle_entries(2),
        "prior_directives_summary": get_latest_directives(2),
        "current_task": get_current_command() or {
            "directive_id": "directive_003_council_memory_sync",
            "description": "Establish Council Memory Synchronization Protocol."
        },
        "shared_context": {
            "notes": [
                "All Cortex queries must use standardized schema (see cortex_query_schema.json).",
                "Continuity must be verified against Chronicle anchors before major decisions.",
                "Logs of this briefing cycle should be stored in WORK_IN_PROGRESS/council_memory_sync/briefing_logs_<timestamp>.md"
            ]
        }
    }

    # MAP-94: Calculate attestation hash
    packet_for_hashing = packet.copy()
    del packet_for_hashing["metadata"]
    canonical_string = json.dumps(packet_for_hashing, sort_keys=True, separators=(',', ':'))
    attestation_hash = hashlib.sha256(canonical_string.encode('utf-8')).hexdigest()
    packet["metadata"]["attestation_hash"] = attestation_hash

    OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)
    OUTPUT_PATH.write_text(json.dumps(packet, indent=2), encoding="utf-8")
    print(f"[+] briefing_packet.json generated at {OUTPUT_PATH}")

if __name__ == "__main__":
    main()

--- END OF FILE scripts/bootstrap_briefing_packet.py ---

--- START OF FILE scripts/dashboard/README.md ---

# Council Orchestrator Observability Dashboard

Phase 2 observability tools for monitoring council performance, safety, and Phase 3 readiness.

## Usage

```bash
# Basic dashboard
./scripts/dashboard/jq_dashboard.sh /path/to/session/dir

# Save snapshot for trend analysis
./scripts/dashboard/jq_dashboard.sh /path/to/session/dir true
```

## Metrics Tracked

### Memory Tier Distribution
- Fast/Medium/Slow tier assignments
- Evidence quality impact on promotion

### Novelty Analysis
- Novelty signal distribution (none/low/medium/high)
- Raw overlap metrics (token/Jaccard/ROUGE)

### Conflict Detection
- Conflict rate across sessions
- Human-readable conflict reasons

### Performance Analysis
- Per-stage latencies (plan/retrieve/analyze/emit)
- SLO compliance (p95 latency targets)
- Cache performance metrics

### Evidence Quality
- Citation integrity validation
- Evidence promotion rates
- PII redaction effectiveness

### Phase 3 Readiness
- Cache EMA trends
- Promotion candidate identification
- Hit streak analysis

## Snapshot Saving

When `save_snapshot=true`, metrics are saved to:
```
scripts/dashboard/snapshots/YYYYMMDD_HHMMSS/
â”œâ”€â”€ tier_distribution.txt
â”œâ”€â”€ novelty_distribution.txt
â”œâ”€â”€ conflict_stats.txt
â”œâ”€â”€ performance_metrics.txt
â”œâ”€â”€ evidence_quality.txt
â”œâ”€â”€ cache_performance.txt
â””â”€â”€ phase3_candidates.txt
```

Use snapshots to track trends over time and validate Phase 3 promotion logic.

--- END OF FILE scripts/dashboard/README.md ---

--- START OF FILE scripts/dashboard/jq_dashboard.sh ---

#!/usr/bin/env bash
# council_orchestrator/scripts/dashboard/jq_dashboard.sh
# Phase 2 Council Observability Dashboard
# Usage: ./jq_dashboard.sh /path/to/session_dir [save_snapshot]

SESSION_DIR="${1:-WORK_IN_PROGRESS}"
SAVE_SNAPSHOT="${2:-false}"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
SNAPSHOT_DIR="scripts/dashboard/snapshots/${TIMESTAMP}"

echo "=== Phase 2 Council Observability Dashboard ==="
echo "Session: $SESSION_DIR"
echo "Timestamp: $(date)"
echo

# Create snapshot directory if saving
if [ "$SAVE_SNAPSHOT" = "true" ]; then
    mkdir -p "$SNAPSHOT_DIR"
    echo "Saving snapshot to: $SNAPSHOT_DIR"
    echo
fi

# Memory Tier Distribution
echo "ðŸ“Š Memory Tier Distribution:"
TIER_DATA=$(find "$SESSION_DIR" -name "round_*.jsonl" -exec cat {} \; 2>/dev/null | \
jq -r '.memory_directive.tier' | sort | uniq -c | sort -nr)
echo "$TIER_DATA"
if [ "$SAVE_SNAPSHOT" = "true" ]; then
    echo "$TIER_DATA" > "$SNAPSHOT_DIR/tier_distribution.txt"
fi
echo

# Novelty Signal Distribution
echo "ðŸ” Novelty Signal Distribution:"
NOVELTY_DATA=$(find "$SESSION_DIR" -name "round_*.jsonl" -exec cat {} \; 2>/dev/null | \
jq -r '.novelty.signal' | sort | uniq -c | sort -nr)
echo "$NOVELTY_DATA"
if [ "$SAVE_SNAPSHOT" = "true" ]; then
    echo "$NOVELTY_DATA" > "$SNAPSHOT_DIR/novelty_distribution.txt"
fi
echo

# Conflict Detection
echo "âš ï¸  Conflict Detection:"
CONFLICT_DATA=$(find "$SESSION_DIR" -name "round_*.jsonl" -exec cat {} \; 2>/dev/null | \
jq -r '.conflict.conflicts_with | length > 0' | grep -c true || echo "0")
TOTAL_PACKETS=$(find "$SESSION_DIR" -name "round_*.jsonl" -exec cat {} \; 2>/dev/null | wc -l | tr -d ' ')
echo "Conflicts detected: $CONFLICT_DATA / $TOTAL_PACKETS packets"
if [ "$TOTAL_PACKETS" -gt 0 ]; then
    CONFLICT_RATE=$(echo "scale=2; $CONFLICT_DATA * 100 / $TOTAL_PACKETS" | bc 2>/dev/null || echo "0")
    echo "Conflict rate: ${CONFLICT_RATE}%"
fi
if [ "$SAVE_SNAPSHOT" = "true" ]; then
    echo "Conflicts: $CONFLICT_DATA / $TOTAL_PACKETS" > "$SNAPSHOT_DIR/conflict_stats.txt"
fi
echo

# Performance Metrics
echo "âš¡ Performance Analysis:"
LATENCY_DATA=$(find "$SESSION_DIR" -name "round_*.jsonl" -exec cat {} \; 2>/dev/null | \
jq -r '.retrieval.retrieval_latency_ms' | awk 'BEGIN {sum=0; count=0; max=0} {sum+=$1; count++; if($1>max) max=$1} END {if(count>0) printf "Mean: %.1fms\nP95: ?\nMax: %dms\nCount: %d\n", sum/count, max, count}')
echo "$LATENCY_DATA"

STAGE_DATA=$(find "$SESSION_DIR" -name "round_*.jsonl" -exec cat {} \; 2>/dev/null | \
jq -r '[.retrieval.plan_latency_ms, .retrieval.analyze_latency_ms, .retrieval.emit_latency_ms] | @csv' | \
awk -F, 'BEGIN {p=0; a=0; e=0; c=0} {p+=$1; a+=$2; e+=$3; c++} END {if(c>0) printf "Stage Latencies (avg): Plan=%.1fms, Analyze=%.1fms, Emit=%.1fms\n", p/c, a/c, e/c}')
echo "$STAGE_DATA"
if [ "$SAVE_SNAPSHOT" = "true" ]; then
    echo "$LATENCY_DATA" > "$SNAPSHOT_DIR/performance_metrics.txt"
    echo "$STAGE_DATA" >> "$SNAPSHOT_DIR/performance_metrics.txt"
fi
echo

# Evidence Quality
echo "ðŸ“š Evidence Quality:"
CITATIONS_DATA=$(find "$SESSION_DIR" -name "round_*.jsonl" -exec cat {} \; 2>/dev/null | \
jq -r 'select(.citations | length > 0) | .memory_directive.tier' | grep -c -E "(medium|slow)" || echo "0")
TOTAL_CITATIONS=$(find "$SESSION_DIR" -name "round_*.jsonl" -exec cat {} \; 2>/dev/null | \
jq -r '.citations | length > 0' | grep -c true || echo "0")
echo "Packets with citations: $TOTAL_CITATIONS"
echo "Citations promoted beyond fast: $CITATIONS_DATA"
if [ "$TOTAL_CITATIONS" -gt 0 ]; then
    PROMOTION_RATE=$(echo "scale=1; $CITATIONS_DATA * 100 / $TOTAL_CITATIONS" | bc 2>/dev/null || echo "0")
    echo "Evidence promotion rate: ${PROMOTION_RATE}%"
fi
if [ "$SAVE_SNAPSHOT" = "true" ]; then
    echo "Citations: $TOTAL_CITATIONS, Promoted: $CITATIONS_DATA" > "$SNAPSHOT_DIR/evidence_quality.txt"
fi
echo

# Cache Performance
echo "ðŸ’¾ Cache Performance:"
CACHE_DATA=$(find "$SESSION_DIR" -name "round_*.jsonl" -exec cat {} \; 2>/dev/null | \
jq -r '.cag | select(.) | "\(.hit_streak // 0) \(.ema_7d // 0)"' | \
awk 'BEGIN {hits=0; total_ema=0; count=0} {hits+=$1; total_ema+=$2; count++} END {if(count>0) printf "Avg Hit Streak: %.1f\nAvg EMA 7d: %.3f\nCache Queries: %d\n", hits/count, total_ema/count, count}')
echo "$CACHE_DATA"
if [ "$SAVE_SNAPSHOT" = "true" ]; then
    echo "$CACHE_DATA" > "$SNAPSHOT_DIR/cache_performance.txt"
fi
echo

# Phase 3 Readiness
echo "ðŸš€ Phase 3 Promotion Candidates:"
PROMOTION_DATA=$(find "$SESSION_DIR" -name "round_*.jsonl" -exec cat {} \; 2>/dev/null | \
jq -r 'select(.memory_directive.tier == "slow" and (.cag.hit_streak // 0) >= 3) | "\(.member_id): \(.decision) (streak: \(.cag.hit_streak // 0), ema: \(.cag.ema_7d // 0))"' | \
head -5)
if [ -n "$PROMOTION_DATA" ]; then
    echo "$PROMOTION_DATA"
else
    echo "No candidates ready for Phase 3 promotion yet"
fi
if [ "$SAVE_SNAPSHOT" = "true" ]; then
    echo "$PROMOTION_DATA" > "$SNAPSHOT_DIR/phase3_candidates.txt"
fi
echo

# SLO Compliance
echo "ðŸ“ SLO Compliance Check:"
if [ "$TOTAL_PACKETS" -gt 0 ]; then
    # Calculate basic SLO metrics
    HIGH_LATENCY=$(find "$SESSION_DIR" -name "round_*.jsonl" -exec cat {} \; 2>/dev/null | \
    jq -r '.retrieval.retrieval_latency_ms' | awk '$1 > 150 {count++} END {print count+0}')
    SLO_VIOLATIONS=$HIGH_LATENCY
    echo "Packets violating p95 latency SLO (>150ms): $SLO_VIOLATIONS"
    echo "SLO compliance: $(echo "scale=1; ($TOTAL_PACKETS - $SLO_VIOLATIONS) * 100 / $TOTAL_PACKETS" | bc 2>/dev/null || echo "100")%"
fi

echo
echo "=== Dashboard Complete ==="
if [ "$SAVE_SNAPSHOT" = "true" ]; then
    echo "Snapshot saved to: $SNAPSHOT_DIR"
fi

--- END OF FILE scripts/dashboard/jq_dashboard.sh ---

--- START OF FILE scripts/forge_orchestrator_review_package.py ---

# council_orchestrator/forge_orchestrator_review_package.py
import os
from pathlib import Path
import datetime

def forge_package():
    """A Sovereign Scaffold (P88) to package the orchestrator's architecture for review."""
    print("--- P88 Scaffold: Forging Orchestrator Review Package ---")

    ORCHESTRATOR_DIR = Path(__file__).parent.parent
    OUTPUT_FILE = ORCHESTRATOR_DIR / "orchestrator_architecture_package.md"

    files_to_package = [
        ORCHESTRATOR_DIR / "README.md",
        ORCHESTRATOR_DIR / "orchestrator" / "main.py",
        ORCHESTRATOR_DIR / "orchestrator" / "app.py",
        ORCHESTRATOR_DIR / "requirements.txt"
    ]

    # Also include the protocols that define the architecture
    project_root = ORCHESTRATOR_DIR.parent
    protocol_files_to_include = [
        "01_PROTOCOLS/93_The_Cortex_Conduit_Bridge.md",
        "01_PROTOCOLS/94_The_Persistent_Council_Protocol.md",
        "01_PROTOCOLS/95_The_Commandable_Council_Protocol.md"
    ]

    with open(OUTPUT_FILE, 'w', encoding='utf-8') as outfile:
        outfile.write(f"# Sovereign Scaffold Yield: Orchestrator Architecture Review\n")
        outfile.write(f"# Forged On: {datetime.datetime.now(datetime.timezone.utc).isoformat()}\n\n")

        # Package orchestrator files
        for filepath in files_to_package:
            if filepath.exists():
                relative_path = filepath.relative_to(project_root)
                print(f"  -> Ingesting: {relative_path}")
                outfile.write(f'--- START OF FILE {relative_path} ---\n\n')
                outfile.write(filepath.read_text(encoding='utf-8'))
                outfile.write(f'\n\n--- END OF FILE {relative_path} ---\n\n')
            else:
                print(f"  -> WARNING: File not found: {filepath}")

        # Package relevant protocol files
        for filename in protocol_files_to_include:
            filepath = project_root / filename
            if filepath.exists():
                print(f"  -> Ingesting: {filename}")
                outfile.write(f'--- START OF FILE {filename} ---\n\n')
                outfile.write(filepath.read_text(encoding='utf-8'))
                outfile.write(f'\n\n--- END OF FILE {filename} ---\n\n')
            else:
                print(f"  -> WARNING: Protocol file not found: {filepath}")


    print(f"--- Forge Complete. Package delivered to {OUTPUT_FILE} ---")

if __name__ == '__main__':
    forge_package()

--- END OF FILE scripts/forge_orchestrator_review_package.py ---

--- START OF FILE scripts/orchestrator_architecture_package.md ---

# Sovereign Scaffold Yield: Orchestrator Architecture Review
# Forged On: 2025-11-10T06:24:23.507319+00:00

--- END OF FILE scripts/orchestrator_architecture_package.md ---

--- START OF FILE scripts/test_cache_standalone.py ---

# council_orchestrator/scripts/test_cache_standalone.py
# Standalone cache verification script - tests cache functionality without orchestrator

import sys
import os
import logging
from pathlib import Path

# Add the project root to Python path
project_root = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(project_root))

from council_orchestrator.orchestrator.memory.cache import CacheManager
from council_orchestrator.orchestrator.memory.cortex import CortexManager
from council_orchestrator.orchestrator.handlers.cache_wakeup_handler import render_guardian_boot_digest

def setup_logging():
    """Set up logging for the standalone test."""
    logging.basicConfig(
        level=logging.INFO,
        format='[%(levelname)s] %(message)s'
    )
    return logging.getLogger(__name__)

def test_cache_prefill(cache_manager, logger):
    """Test cache prefill from RAG DB."""
    logger.info("Testing cache prefill from RAG DB...")
    try:
        cache_manager.prefill_guardian_start_pack()
        logger.info("Cache prefill completed successfully")
        return True
    except Exception as e:
        logger.error(f"Cache prefill failed: {e}")
        return False

def test_digest_generation(cache_manager, output_path, logger):
    """Test digest generation from cache."""
    logger.info("Testing digest generation from cache...")
    try:
        # Fetch data from cache
        result = cache_manager.fetch_guardian_start_pack(
            bundles=["chronicles", "protocols", "roadmap"],
            limit=15
        )

        # Render digest
        digest_content = render_guardian_boot_digest(result, project_root)

        # Write to file
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(digest_content)

        logger.info(f"Digest generated successfully: {output_path}")
        return True
    except Exception as e:
        logger.error(f"Digest generation failed: {e}")
        return False

def verify_outputs(output_path, logger):
    """Verify that outputs were created correctly."""
    logger.info("Verifying outputs...")

    if not output_path.exists():
        logger.error(f"Output file not created: {output_path}")
        return False

    try:
        with open(output_path, 'r', encoding='utf-8') as f:
            content = f.read()

        if "# Guardian Boot Digest (Cache)" not in content:
            logger.error("Digest file missing expected header")
            return False

        logger.info("Output verification successful")
        return True
    except Exception as e:
        logger.error(f"Error reading output file: {e}")
        return False

def main():
    """Main test function."""
    logger = setup_logging()
    logger.info("Starting standalone cache verification...")

    # Setup paths
    project_root = Path(__file__).resolve().parents[2]
    output_path = project_root / "WORK_IN_PROGRESS" / "guardian_boot_digest.md"

    # Create managers
    try:
        # Create a mock logger for the managers
        mock_logger = logging.getLogger("cache_test")

        # Create CacheManager
        cache_manager = CacheManager(project_root, mock_logger)

        # Create CortexManager (needed for cache_manager initialization)
        cortex_manager = CortexManager(project_root, mock_logger)
        cortex_manager.cache_manager = cache_manager

    except Exception as e:
        logger.error(f"Failed to initialize managers: {e}")
        return False

    # Run tests
    success = True

    # Test 1: Cache prefill
    if not test_cache_prefill(cache_manager, logger):
        success = False

    # Test 2: Digest generation
    if not test_digest_generation(cache_manager, output_path, logger):
        success = False

    # Test 3: Verify outputs
    if not verify_outputs(output_path, logger):
        success = False

    # Final result
    if success:
        logger.info("Cache verification complete - All tests passed!")
        logger.info(f"Check the digest file: {output_path}")
    else:
        logger.error("Cache verification failed - Check logs above")

    return success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

--- END OF FILE scripts/test_cache_standalone.py ---

--- START OF FILE tests/__init__.py ---



--- END OF FILE tests/__init__.py ---

--- START OF FILE tests/mechanical_test_output.txt ---

# Mechanical Test Output

**Timestamp:** 2025-11-09
**Test:** Mechanical file write operation
**Purpose:** Test direct file creation for git commit

This file was created by the orchestrator's mechanical file operations system.
It will be committed to demonstrate the git operations workflow.

## Test Status
- File created successfully
- Ready for git commit

--- END OF FILE tests/mechanical_test_output.txt ---

--- START OF FILE tests/orchestrator_test_file.txt ---

# Test File Created by Orchestrator

**Timestamp:** 2025-11-09
**Purpose:** Testing mechanical file write operations
**Location:** tests/ directory

This file was created by the orchestrator's mechanical file operations system.
It demonstrates the ability to create and update files in the tests directory.

## Test Status
- File creation: SUCCESS
- Content writing: SUCCESS
- Path resolution: SUCCESS

--- END OF FILE tests/orchestrator_test_file.txt ---

--- START OF FILE tests/test_boot_prefill_runs_once.py ---

# council_orchestrator/tests/test_boot_prefill_runs_once.py
# Tests for boot prefill idempotency

import pytest
from pathlib import Path
from unittest.mock import patch
from council_orchestrator.orchestrator.memory.cache import CacheManager, CACHE


class TestBootPrefillIdempotency:
    """Test that boot prefill runs once and is idempotent."""

    def setup_method(self):
        """Clear cache before each test."""
        CACHE.clear()
        self.cache_manager = CacheManager()

    def test_prefill_guardian_start_pack_populates_cache(self):
        """Test that prefill_guardian_start_pack populates the cache with expected keys."""
        self.cache_manager.prefill_guardian_start_pack()

        # Should have populated some cache entries
        assert len(CACHE) > 0

        # Should contain expected keys (at least the ones that have files)
        keys = list(CACHE.keys())
        assert any("guardian:dashboard:chronicles:latest" in key for key in keys) or \
               "guardian:dashboard:chronicles:latest" in keys
        assert any("guardian:dashboard:protocols:latest" in key for key in keys) or \
               "guardian:dashboard:protocols:latest" in keys
        assert any("guardian:dashboard:roadmap" in key for key in keys) or \
               "guardian:dashboard:roadmap" in keys

    def test_prefill_guardian_start_pack_is_idempotent(self):
        """Test that running prefill multiple times doesn't create duplicates."""
        # First run
        self.cache_manager.prefill_guardian_start_pack()
        first_run_keys = set(CACHE.keys())
        first_run_count = len(CACHE)

        # Second run
        self.cache_manager.prefill_guardian_start_pack()
        second_run_keys = set(CACHE.keys())
        second_run_count = len(CACHE)

        # Should be the same (idempotent)
        assert first_run_keys == second_run_keys
        assert first_run_count == second_run_count

    def test_prefill_guardian_start_pack_sets_ttl(self):
        """Test that prefill sets appropriate TTL values."""
        self.cache_manager.prefill_guardian_start_pack()

        # Check that entries have expiration times set
        for key, entry in CACHE.items():
            assert "expires_at" in entry
            assert entry["expires_at"] > 0
            # Should expire in future (TTL set)
            import time
            assert entry["expires_at"] > time.time()

    @patch('council_orchestrator.orchestrator.memory.cache.PROJECT_ROOT', new=Path("/fake/path"))
    def test_prefill_handles_missing_files_gracefully(self):
        """Test that prefill handles missing files without crashing."""
        # With fake project root, files won't exist but prefill should not crash
        try:
            self.cache_manager.prefill_guardian_start_pack()
            # Should not raise exception
            assert True
        except Exception as e:
            pytest.fail(f"Prefill should handle missing files gracefully, but got: {e}")

    def test_prefill_runs_on_orchestrator_boot(self):
        """Test that prefill is called during orchestrator boot."""
        # This is tested by the fact that main.py calls cache_manager.prefill_guardian_start_pack()
        # We can verify this by checking that the call exists in main.py
        with open("/Users/richardfremmerlid/Projects/Project_Sanctuary/council_orchestrator/orchestrator/main.py", "r") as f:
            content = f.read()
            assert "cache_manager.prefill_guardian_start_pack()" in content

--- END OF FILE tests/test_boot_prefill_runs_once.py ---

--- START OF FILE tests/test_cache_prefill.py ---

#!/usr/bin/env python3
"""
Unit tests for Phase 3 Cache Prefill functionality.
Tests Guardian Start Pack prefill and delta refresh.
"""

import unittest
import tempfile
import json
import time
from pathlib import Path
from unittest.mock import patch, MagicMock

# Import the components we need to test
from council_orchestrator.orchestrator.memory.cache import CacheManager, CacheItem, CACHE


class TestCachePrefillGuardianBundle(unittest.TestCase):
    """Test Guardian Start Pack prefill creates all expected keys."""

    def setUp(self):
        """Clear cache before each test."""
        CACHE.clear()
        # Create CacheManager instance for tests
        self.cache_manager = CacheManager(Path('/tmp'), MagicMock())

    def tearDown(self):
        """Clear cache after each test."""
        CACHE.clear()

    @patch('council_orchestrator.orchestrator.memory.cache.PROJECT_ROOT', Path('/tmp/test'))
    def test_cache_prefill_guardian_bundle_creates_all_keys(self):
        """Test that prefill_guardian_start_pack creates all expected cache keys."""
        with tempfile.TemporaryDirectory() as tmp_dir:
            test_root = Path(tmp_dir)

            # Create mock directory structure
            (test_root / "00_CHRONICLE" / "ENTRIES").mkdir(parents=True)
            (test_root / "01_PROTOCOLS").mkdir(parents=True)
            (test_root / "ROADMAP").mkdir(parents=True)
            (test_root / "council_orchestrator").mkdir(parents=True)
            (test_root / "council_orchestrator" / "schemas").mkdir(parents=True)
            (test_root / "council_orchestrator" / "logs").mkdir(parents=True)

            # Create mock files
            (test_root / "00_CHRONICLE" / "ENTRIES" / "test1.md").write_text("# Test Chronicle")
            (test_root / "01_PROTOCOLS" / "test2.md").write_text("# Test Protocol")
            (test_root / "ROADMAP" / "PHASED_EVOLUTION_PLAN_Phase2-Phase3-Protocol113.md").write_text("# Roadmap")
            (test_root / "council_orchestrator" / "README.md").write_text("# README")
            (test_root / "council_orchestrator" / "schemas" / "council-round-packet-v1.0.0.json").write_text("{}")
            (test_root / "council_orchestrator" / "logs" / "orchestrator.log").write_text("log line 1\nlog line 2\n")

            # Create a CacheManager with the test root
            test_cache_manager = CacheManager(test_root, MagicMock())
            test_cache_manager.prefill_guardian_start_pack()

            # Check that all expected keys exist
            expected_keys = [
                "guardian:dashboard:chronicles:latest",
                "guardian:dashboard:protocols:latest",
                "guardian:dashboard:roadmap",
                "guardian:docs:orchestrator_readme",
                "guardian:packets:schema",
                "guardian:ops:orchestrator_log:tail"
            ]

            for key in expected_keys:
                self.assertIn(key, CACHE, f"Missing cache key: {key}")
                self.assertIsNotNone(test_cache_manager.get(key), f"Cache key {key} should not be None")


class TestCachePrefillDelta(unittest.TestCase):
    """Test delta refresh functionality."""

    def setUp(self):
        """Clear cache before each test."""
        CACHE.clear()
        # Create CacheManager instance for tests
        self.cache_manager = CacheManager(Path('/tmp'), MagicMock())

    def tearDown(self):
        """Clear cache after each test."""
        CACHE.clear()

    @patch('council_orchestrator.orchestrator.memory.cache.PROJECT_ROOT', Path('/tmp/test'))
    def test_cache_prefill_delta_refreshes_on_chronicle_update(self):
        """Test that delta refresh updates chronicle cache when chronicle files change."""
        with tempfile.TemporaryDirectory() as tmp_dir:
            test_root = Path(tmp_dir)

            # Create initial structure
            (test_root / "00_CHRONICLE" / "ENTRIES").mkdir(parents=True)
            (test_root / "00_CHRONICLE" / "ENTRIES" / "initial.md").write_text("# Initial")

            # Create CacheManager with test root
            test_cache_manager = CacheManager(test_root, MagicMock())
            
            # Initial prefill
            test_cache_manager.prefill_guardian_start_pack()
            initial_chronicles = test_cache_manager.get("guardian:dashboard:chronicles:latest")

            # Add new chronicle file
            (test_root / "00_CHRONICLE" / "ENTRIES" / "new.md").write_text("# New Chronicle")

            # Delta refresh
            test_cache_manager.prefill_guardian_delta(["00_CHRONICLE/ENTRIES/new.md"])
            updated_chronicles = test_cache_manager.get("guardian:dashboard:chronicles:latest")

            # Should be different after refresh
            self.assertNotEqual(initial_chronicles, updated_chronicles)


class TestCacheTTL(unittest.TestCase):
    """Test TTL functionality."""

    def setUp(self):
        """Clear cache before each test."""
        CACHE.clear()
        # Create CacheManager instance for tests
        self.cache_manager = CacheManager(Path('/tmp'), MagicMock())

    def tearDown(self):
        """Clear cache after each test."""
        CACHE.clear()

    def test_cache_ttl_expiry_clears_items(self):
        """Test that items expire after TTL."""
        # Set item with very short TTL
        item = CacheItem("test:key", "test_value", ttl_seconds=1)
        self.cache_manager.set(item)

        # Should exist immediately
        self.assertEqual(self.cache_manager.get("test:key"), "test_value")

        # Wait for expiry
        time.sleep(1.1)

        # Should be gone
        self.assertIsNone(self.cache_manager.get("test:key"))


class TestCacheLogTail(unittest.TestCase):
    """Test log tail functionality."""

    def setUp(self):
        """Clear cache before each test."""
        CACHE.clear()
        # Create CacheManager instance for tests
        self.cache_manager = CacheManager(Path('/tmp'), MagicMock())

    def tearDown(self):
        """Clear cache after each test."""
        CACHE.clear()

    @patch('council_orchestrator.orchestrator.memory.cache.PROJECT_ROOT', Path('/tmp/test'))
    def test_cache_log_tail_rotates_and_stays_small(self):
        """Test that log tail only keeps last N lines."""
        with tempfile.TemporaryDirectory() as tmp_dir:
            test_root = Path(tmp_dir)
            log_file = test_root / "council_orchestrator" / "logs" / "orchestrator.log"
            log_file.parent.mkdir(parents=True)

            # Create log with many lines
            lines = [f"log line {i}" for i in range(200)]
            log_file.write_text("\n".join(lines))

            # Create CacheManager with test root
            test_cache_manager = CacheManager(test_root, MagicMock())
            test_cache_manager.prefill_guardian_start_pack()

            tail_content = test_cache_manager.get("guardian:ops:orchestrator_log:tail")

            # Should only have last 150 lines
            tail_lines = tail_content.split("\n")
            self.assertEqual(len(tail_lines), 150)
            self.assertIn("log line 199", tail_content)  # Last line should be there
            self.assertNotIn("log line 49", tail_content)  # Early lines should be gone


class TestCacheKeys(unittest.TestCase):
    """Test cache key stability and documentation."""

    def setUp(self):
        """Clear cache before each test."""
        CACHE.clear()

    def tearDown(self):
        """Clear cache after each test."""
        CACHE.clear()

    def test_cache_keys_stable_and_documented(self):
        """Test that all cache keys follow documented naming convention."""
        # This test ensures we don't accidentally change key names
        expected_keys = [
            "guardian:dashboard:chronicles:latest",
            "guardian:dashboard:protocols:latest",
            "guardian:dashboard:roadmap",
            "guardian:docs:orchestrator_readme",
            "guardian:docs:command_schema",
            "guardian:docs:howto_commit",
            "guardian:packets:schema",
            "guardian:blueprint:optical_anvil",
            "guardian:ops:engine_config",
            "guardian:ops:orchestrator_log:tail",
            "guardian:rounds:last_jsonl"
        ]

        # All keys should follow guardian:* pattern
        for key in expected_keys:
            self.assertTrue(key.startswith("guardian:"), f"Key {key} doesn't follow guardian: prefix")
            self.assertIn(":", key, f"Key {key} should have namespace separator")


if __name__ == '__main__':
    unittest.main()

--- END OF FILE tests/test_cache_prefill.py ---

--- START OF FILE tests/test_cache_request_command.py ---

# council_orchestrator/tests/test_cache_request_command.py
# Tests for cache_request command type (v9.4)

import pytest
import json
import time
from pathlib import Path
from unittest.mock import patch, MagicMock
from council_orchestrator.orchestrator.commands import handle_cache_request
from council_orchestrator.orchestrator.memory.cache import CacheManager, CacheItem, CACHE


class TestCacheRequestBundle:
    """Test cache_request with bundle parameter."""

    def setup_method(self):
        """Clear cache before each test."""
        CACHE.clear()

    def test_bundle_happy_path_returns_entries(self):
        """Test that bundle request returns expected number of entries."""
        # Prefill cache
        CacheManager.prefill_guardian_start_pack()

        # Create cache request command
        command = {
            "task_type": "cache_request",
            "task_description": "Test bundle request",
            "output_artifact_path": "test_output.md",
            "cache_request": {
                "bundle": "guardian_start_pack",
                "policy": {"refresh_if_stale": False, "strict": False}
            }
        }

        # Handle the request
        report = handle_cache_request(command)

        # Verify report contains expected content
        assert "# Guardian Wakeup Cache Check (v9.4)" in report
        assert "bundle=guardian_start_pack" in report
        assert "Items: 11" in report  # All keys in bundle are reported
        assert "Missing: 8" in report  # 8 items missing because files don't exist
        assert "Expired: 0" in report

    def test_refresh_if_stale_calls_prefill(self):
        """Test that refresh_if_stale=true calls prefill method."""
        with patch.object(CacheManager, 'prefill_guardian_start_pack') as mock_prefill:
            command = {
                "task_type": "cache_request",
                "task_description": "Test refresh",
                "output_artifact_path": "test_output.md",
                "cache_request": {
                    "bundle": "guardian_start_pack",
                    "policy": {"refresh_if_stale": True, "strict": False}
                }
            }

            handle_cache_request(command)

            # Verify prefill was called
            mock_prefill.assert_called_once()


class TestCacheRequestKeys:
    """Test cache_request with keys parameter."""

    def setup_method(self):
        """Clear cache before each test."""
        CACHE.clear()

    def test_keys_mode_returns_only_requested_keys(self):
        """Test that keys mode returns only the requested cache entries."""
        # Set up some test cache entries
        CacheManager.set(CacheItem("test:key1", "value1", 3600))
        CacheManager.set(CacheItem("test:key2", "value2", 3600))

        command = {
            "task_type": "cache_request",
            "task_description": "Test keys request",
            "output_artifact_path": "test_output.md",
            "cache_request": {
                "keys": ["test:key1"],
                "policy": {"refresh_if_stale": False, "strict": False}
            }
        }

        report = handle_cache_request(command)

        # Verify only requested key appears
        assert "test:key1" in report
        assert "test:key2" not in report
        assert "Items: 1" in report


class TestCacheRequestStrictMode:
    """Test cache_request strict mode behavior."""

    def setup_method(self):
        """Clear cache before each test."""
        CACHE.clear()

    def test_strict_mode_failure_with_missing_items(self):
        """Test that strict mode raises exception when items are missing."""
        command = {
            "task_type": "cache_request",
            "task_description": "Test strict mode",
            "output_artifact_path": "test_output.md",
            "cache_request": {
                "keys": ["nonexistent:key"],
                "policy": {"refresh_if_stale": False, "strict": True}
            }
        }

        report = handle_cache_request(command)

        # Verify missing item is reported
        assert "Missing: 1" in report
        assert "Strict mode enabled" in report


class TestCacheRequestArtifactShape:
    """Test cache_request artifact format and content."""

    def setup_method(self):
        """Clear cache before each test."""
        CACHE.clear()

    def test_artifact_contains_expected_sections(self):
        """Test that artifact contains all expected markdown sections."""
        # Set up test data
        CacheManager.set(CacheItem("test:key", "test_value", 3600))

        command = {
            "task_type": "cache_request",
            "task_description": "Test artifact shape",
            "output_artifact_path": "test_output.md",
            "cache_request": {
                "keys": ["test:key"],
                "policy": {"refresh_if_stale": False, "strict": False}
            }
        }

        report = handle_cache_request(command)

        # Verify markdown structure
        lines = report.split('\n')
        assert lines[0] == "# Guardian Wakeup Cache Check (v9.4)"
        assert "## Summary" in report
        assert "## Items" in report
        assert "| key | ttl_remaining | size | sha256[:10] | source | last_updated |" in report

    def test_ttl_display_format(self):
        """Test that TTL is displayed in human-readable format."""
        CacheManager.set(CacheItem("test:key", "value", 7200))  # 2 hours

        command = {
            "task_type": "cache_request",
            "task_description": "Test TTL format",
            "output_artifact_path": "test_output.md",
            "cache_request": {
                "keys": ["test:key"],
                "policy": {"refresh_if_stale": False, "strict": False}
            }
        }

        report = handle_cache_request(command)

        # Should show something like "2h0m" (approximately)
        assert "h" in report and "m" in report  # Contains time format


class TestCacheRequestExpiredItems:
    """Test cache_request handling of expired items."""

    def setup_method(self):
        """Clear cache before each test."""
        CACHE.clear()

    def test_expired_items_are_marked_and_cleaned(self):
        """Test that expired items are marked as expired and removed from cache."""
        # Set an item with very short TTL (1 second)
        CacheManager.set(CacheItem("test:expired", "value", 1))

        # Wait for expiration
        time.sleep(1.1)

        command = {
            "task_type": "cache_request",
            "task_description": "Test expired items",
            "output_artifact_path": "test_output.md",
            "cache_request": {
                "keys": ["test:expired"],
                "policy": {"refresh_if_stale": False, "strict": False}
            }
        }

        report = handle_cache_request(command)

        # Verify expired item is reported
        assert "Expired: 1" in report
        assert "expired" in report

        # Verify item was removed from cache
        assert "test:expired" not in CACHE

--- END OF FILE tests/test_cache_request_command.py ---

--- START OF FILE tests/test_cache_wakeup_flow.py ---

# council_orchestrator/tests/test_cache_wakeup_flow.py
# Tests for cache_wakeup command processing flow

import pytest
import json
import time
from pathlib import Path
from unittest.mock import patch, MagicMock
from council_orchestrator.orchestrator.handlers.cache_wakeup_handler import handle_cache_wakeup
from council_orchestrator.orchestrator.memory.cache import CacheManager, CACHE, CacheItem


class TestCacheWakeupFlow:
    """Test cache_wakeup command processing flow."""

    def setup_method(self):
        """Clear cache before each test."""
        CACHE.clear()
        # Create CacheManager instance for tests
        self.project_root = Path("/tmp")
        self.cache_manager = CacheManager(self.project_root, MagicMock())

    def test_cache_wakeup_returns_digest_with_expected_structure(self):
        """Test that cache_wakeup returns digest with expected markdown structure."""
        # Prefill cache with test data
        self.cache_manager.set(CacheItem("guardian:dashboard:chronicles:latest",
            [{"title": "Test Chronicle", "path": "test.md", "updated_at": 1234567890}], 3600))
        self.cache_manager.set(CacheItem("guardian:dashboard:protocols:latest",
            [{"title": "Test Protocol", "path": "protocol.md", "updated_at": 1234567890}], 3600))
        self.cache_manager.set(CacheItem("guardian:dashboard:roadmap",
            "Test roadmap content", 3600))

        command = {
            "task_type": "cache_wakeup",
            "task_description": "Test cache wakeup",
            "output_artifact_path": "test_digest.md",
            "config": {
                "bundle_names": ["chronicles", "protocols", "roadmap"],
                "max_items_per_bundle": 10
            }
        }

        # Mock orchestrator with proper cache manager
        mock_orchestrator = MagicMock()
        mock_orchestrator.project_root = Path("/tmp")
        mock_orchestrator.logger = MagicMock()
        mock_orchestrator.packet_emitter = MagicMock()
        mock_orchestrator.cache_manager = self.cache_manager

        success = handle_cache_wakeup(mock_orchestrator, command)

        # Verify success and that file was written
        assert success["status"] == "success"
        # Check that the file was actually created
        expected_path = Path("/tmp/test_digest.md")
        assert expected_path.exists()
        content = expected_path.read_text()
        assert "Guardian Boot Digest" in content

    def test_cache_wakeup_creates_output_file(self, tmp_path):
        """Test that cache_wakeup creates the expected output file."""
        # Prefill cache
        self.cache_manager.set(CacheItem("guardian:dashboard:chronicles:latest",
            [{"title": "Test", "path": "test.md", "updated_at": 1234567890}], 3600))

        command = {
            "task_type": "cache_wakeup",
            "task_description": "Test file creation",
            "output_artifact_path": str(tmp_path / "test_digest.md"),
            "config": {"bundle_names": ["chronicles"]}
        }

        # Mock orchestrator with proper cache manager
        mock_orchestrator = MagicMock()
        mock_orchestrator.project_root = tmp_path
        mock_orchestrator.logger = MagicMock()
        mock_orchestrator.packet_emitter = MagicMock()
        mock_orchestrator.cache_manager = self.cache_manager

        success = handle_cache_wakeup(mock_orchestrator, command)

        # Verify success
        assert success["status"] == "success"
        # Check that the file was actually written
        output_file = tmp_path / "test_digest.md"
        assert output_file.exists()
        content = output_file.read_text()
        assert "Test" in content

    @patch('council_orchestrator.orchestrator.packets.emit_packet')
    def test_cache_wakeup_emits_observability_packet(self, mock_emit_packet):
        """Test that cache_wakeup emits observability packet."""
        # This test would be run in the context of the full orchestrator
        # For now, we verify the packet emission logic exists in app.py
        # The actual emission is tested in integration tests
        pass

    def test_cache_wakeup_handles_empty_cache(self):
        """Test that cache_wakeup handles empty cache gracefully."""
        command = {
            "task_type": "cache_wakeup",
            "task_description": "Test empty cache",
            "output_artifact_path": "test_digest.md",
            "config": {"bundle_names": ["chronicles", "protocols", "roadmap"]}
        }

        # Mock orchestrator with proper cache manager
        mock_orchestrator = MagicMock()
        mock_orchestrator.project_root = Path("/tmp")
        mock_orchestrator.logger = MagicMock()
        mock_orchestrator.packet_emitter = MagicMock()
        mock_orchestrator.cache_manager = self.cache_manager

        success = handle_cache_wakeup(mock_orchestrator, command)

        # Should still succeed even with empty cache
        assert success["status"] == "success"

    def test_cache_wakeup_custom_bundle_names(self):
        """Test that cache_wakeup respects custom bundle names."""
        # Set up only chronicles data
        self.cache_manager.set(CacheItem("guardian:dashboard:chronicles:latest",
            [{"title": "Test Chronicle", "path": "test.md", "updated_at": 1234567890}], 3600))

        command = {
            "task_type": "cache_wakeup",
            "task_description": "Test custom bundles",
            "output_artifact_path": "test_digest.md",
            "config": {
                "bundle_names": ["chronicles"],  # Only chronicles, not protocols/roadmap
                "max_items_per_bundle": 10
            }
        }

        # Mock orchestrator with proper cache manager
        mock_orchestrator = MagicMock()
        mock_orchestrator.project_root = Path("/tmp")
        mock_orchestrator.logger = MagicMock()
        mock_orchestrator.packet_emitter = MagicMock()
        mock_orchestrator.cache_manager = self.cache_manager

        success = handle_cache_wakeup(mock_orchestrator, command)

        assert success["status"] == "success"
        # Check that only chronicles bundle was processed (would be verified by checking the written file)

    def test_cache_wakeup_respects_max_items_limit(self):
        """Test that cache_wakeup respects max_items_per_bundle limit."""
        # Set up multiple chronicle items
        items = [
            {"title": f"Chronicle {i}", "path": f"chronicle_{i}.md", "updated_at": 1234567890 + i}
            for i in range(5)
        ]
        self.cache_manager.set(CacheItem("guardian:dashboard:chronicles:latest", items, 3600))

        command = {
            "task_type": "cache_wakeup",
            "task_description": "Test item limit",
            "output_artifact_path": "test_digest.md",
            "config": {
                "bundle_names": ["chronicles"],
                "max_items_per_bundle": 3  # Limit to 3 items
            }
        }

        # Mock orchestrator with proper cache manager
        mock_orchestrator = MagicMock()
        mock_orchestrator.project_root = Path("/tmp")
        mock_orchestrator.logger = MagicMock()
        mock_orchestrator.packet_emitter = MagicMock()
        mock_orchestrator.cache_manager = self.cache_manager

        success = handle_cache_wakeup(mock_orchestrator, command)

        assert success["status"] == "success"
        # The limit would be enforced by the CacheManager.fetch_guardian_start_pack method

--- END OF FILE tests/test_cache_wakeup_flow.py ---

--- START OF FILE tests/test_command_schema_cache_wakeup.py ---

# council_orchestrator/tests/test_command_schema_cache_wakeup.py
# Tests for cache_wakeup command schema validation

import pytest
import json
from council_orchestrator.orchestrator.commands import determine_command_type, validate_command


class TestCacheWakeupCommandSchema:
    """Test cache_wakeup command schema validation."""

    def test_cache_wakeup_command_type_detection(self):
        """Test that cache_wakeup commands are correctly identified."""
        command = {
            "task_type": "cache_wakeup",
            "task_description": "Test description",
            "output_artifact_path": "test_output.md"
        }

        command_type = determine_command_type(command)
        assert command_type == "CACHE_WAKEUP"

    def test_cache_wakeup_command_validation_passes(self):
        """Test that valid cache_wakeup commands pass validation."""
        command = {
            "task_type": "cache_wakeup",
            "task_description": "Guardian boot digest from cache",
            "output_artifact_path": "WORK_IN_PROGRESS/guardian_boot_digest.md",
            "config": {
                "bundle_names": ["chronicles", "protocols", "roadmap"],
                "max_items_per_bundle": 15
            }
        }

        is_valid, error_msg = validate_command(command)
        assert is_valid is True
        assert error_msg == "Command is valid"

    def test_cache_wakeup_command_validation_missing_task_type(self):
        """Test that cache_wakeup commands fail validation without task_type."""
        command = {
            "task_description": "Test description",
            "output_artifact_path": "test_output.md"
        }

        is_valid, error_msg = validate_command(command)
        assert is_valid is False
        assert "Missing required field 'task_type'" in error_msg

    def test_cache_wakeup_command_validation_wrong_task_type(self):
        """Test that commands with wrong task_type fail validation."""
        command = {
            "task_type": "wrong_type",
            "task_description": "Test description",
            "output_artifact_path": "test_output.md"
        }

        is_valid, error_msg = validate_command(command)
        assert is_valid is False
        assert "task_type must be 'cache_wakeup'" in error_msg

    def test_cache_wakeup_command_validation_missing_description(self):
        """Test that cache_wakeup commands fail without task_description."""
        command = {
            "task_type": "cache_wakeup",
            "output_artifact_path": "test_output.md"
        }

        is_valid, error_msg = validate_command(command)
        assert is_valid is False
        assert "Missing required field 'task_description'" in error_msg

    def test_cache_wakeup_command_validation_missing_output_path(self):
        """Test that cache_wakeup commands fail without output_artifact_path."""
        command = {
            "task_type": "cache_wakeup",
            "task_description": "Test description"
        }

        is_valid, error_msg = validate_command(command)
        assert is_valid is False
        assert "Missing required field 'output_artifact_path'" in error_msg

--- END OF FILE tests/test_command_schema_cache_wakeup.py ---

--- START OF FILE tests/test_delta_refresh_on_ingest_and_gitops.py ---

# council_orchestrator/tests/test_delta_refresh_on_ingest_and_gitops.py
# Tests for delta refresh hooks on ingest and git-ops

import pytest
from unittest.mock import patch, MagicMock
from council_orchestrator.orchestrator.memory.cache import CacheManager, CACHE


class TestDeltaRefreshIngest:
    """Test delta refresh functionality during ingest operations."""

    def setup_method(self):
        """Clear cache before each test."""
        CACHE.clear()

    def test_prefill_guardian_delta_updates_affected_bundles(self):
        """Test that prefill_guardian_delta updates only affected bundles."""
        # Initial prefill
        CacheManager.prefill_guardian_start_pack()
        initial_chronicles = CacheManager.get("guardian:dashboard:chronicles:latest")

        # Simulate file changes that should trigger chronicle refresh
        changed_paths = ["00_CHRONICLE/ENTRIES/new_chronicle.md"]

        # Call delta refresh
        CacheManager.prefill_guardian_delta(changed_paths)

        # Chronicles should be refreshed (different content or same but TTL reset)
        updated_chronicles = CacheManager.get("guardian:dashboard:chronicles:latest")

        # Content should exist (may be same if no new files, but TTL should be reset)
        assert updated_chronicles is not None

    def test_prefill_guardian_delta_ignores_unrelated_changes(self):
        """Test that delta refresh ignores changes to unrelated files."""
        # Initial prefill
        CacheManager.prefill_guardian_start_pack()
        initial_roadmap = CacheManager.get("guardian:dashboard:roadmap")

        # Change unrelated file
        changed_paths = ["unrelated_file.txt"]

        # Call delta refresh
        CacheManager.prefill_guardian_delta(changed_paths)

        # Roadmap should be unchanged
        updated_roadmap = CacheManager.get("guardian:dashboard:roadmap")
        assert updated_roadmap == initial_roadmap

    def test_prefill_guardian_delta_handles_multiple_changes(self):
        """Test that delta refresh handles multiple file changes correctly."""
        # Initial prefill
        CacheManager.prefill_guardian_start_pack()

        # Multiple changes affecting different bundles
        changed_paths = [
            "00_CHRONICLE/ENTRIES/new_chronicle.md",
            "01_PROTOCOLS/new_protocol.md",
            "ROADMAP/updated_plan.md"
        ]

        # Call delta refresh
        CacheManager.prefill_guardian_delta(changed_paths)

        # All affected bundles should be refreshed
        chronicles = CacheManager.get("guardian:dashboard:chronicles:latest")
        protocols = CacheManager.get("guardian:dashboard:protocols:latest")
        roadmap = CacheManager.get("guardian:dashboard:roadmap")

        # Should all exist (content may be same if files don't exist, but refreshed)
        assert chronicles is not None
        assert protocols is not None
        assert roadmap is not None


class TestDeltaRefreshGitOps:
    """Test delta refresh functionality during git operations."""

    def setup_method(self):
        """Clear cache before each test."""
        CACHE.clear()

    @patch('council_orchestrator.orchestrator.gitops.execute_mechanical_git')
    def test_gitops_calls_delta_refresh_after_successful_commit(self, mock_git):
        """Test that gitops calls delta refresh after successful commits."""
        # This test verifies the integration point exists
        # The actual call is made in gitops.py after successful commit/push

        # Read gitops.py to verify the integration
        with open("/Users/richardfremmerlid/Projects/Project_Sanctuary/council_orchestrator/orchestrator/gitops.py", "r") as f:
            content = f.read()
            assert "CacheManager.prefill_guardian_delta" in content

    def test_delta_refresh_integration_points_exist(self):
        """Test that delta refresh integration points exist in cortex and gitops."""
        # Verify cortex.py has the integration
        with open("/Users/richardfremmerlid/Projects/Project_Sanctuary/council_orchestrator/orchestrator/memory/cortex.py", "r") as f:
            cortex_content = f.read()
            assert "CacheManager.prefill_guardian_delta" in cortex_content

        # Verify gitops.py has the integration
        with open("/Users/richardfremmerlid/Projects/Project_Sanctuary/council_orchestrator/orchestrator/gitops.py", "r") as f:
            gitops_content = f.read()
            assert "CacheManager.prefill_guardian_delta" in gitops_content


class TestDeltaRefreshWatchedPaths:
    """Test that delta refresh watches the correct file paths."""

    def test_watched_paths_mapping_exists(self):
        """Test that the watched paths mapping is properly defined."""
        # The watched paths are defined in prefill_guardian_delta
        # We can verify by calling it and checking behavior

        # This should trigger chronicle refresh
        changed_paths = ["00_CHRONICLE/ENTRIES/test.md"]
        CacheManager.prefill_guardian_delta(changed_paths)

        # This should trigger protocol refresh
        changed_paths = ["01_PROTOCOLS/test.md"]
        CacheManager.prefill_guardian_delta(changed_paths)

        # This should trigger roadmap refresh
        changed_paths = ["ROADMAP/test.md"]
        CacheManager.prefill_guardian_delta(changed_paths)

        # Should not raise exceptions
        assert True

--- END OF FILE tests/test_delta_refresh_on_ingest_and_gitops.py ---

--- START OF FILE tests/test_emitter_jsonl_shape.py ---

import json
from pathlib import Path
from council_orchestrator.orchestrator.packets.schema import *
from council_orchestrator.orchestrator.packets.emitter import emit_packet

def test_emitter_writes_one_line(tmp_path: Path):
    pkt = CouncilRoundPacket(
        timestamp="2025-01-01T00:00:00Z",
        session_id="run_X",
        round_id=1,
        member_id="auditor",
        engine="ollama",
        seed=7,
        prompt_hash="def456",
        inputs={},
        decision="review",
        rationale="...",
        confidence=0.66,
        citations=[],
        rag={},
        cag={},
        cost={},
        errors=[]
    )
    out = tmp_path
    emit_packet(pkt, jsonl_dir=str(out), stream_stdout=False, schema_path=None)
    f = (out / "run_X" / "round_1.jsonl")
    assert f.exists()
    lines = f.read_text().strip().splitlines()
    assert len(lines) == 1
    obj = json.loads(lines[0])
    assert obj["memory_directive"]["tier"]
    assert "retrieval" in obj and "novelty" in obj and "conflict" in obj

--- END OF FILE tests/test_emitter_jsonl_shape.py ---

--- START OF FILE tests/test_golden_packet.py ---

import json
import os
import tempfile
from pathlib import Path
from council_orchestrator.orchestrator.packets.schema import *
from council_orchestrator.orchestrator.packets.emitter import emit_packet

def test_golden_packet_deterministic_output(tmp_path: Path):
    """
    Golden packet test: Ensure deterministic JSONL bytes for seeded runs.
    This test will fail if packet structure or serialization changes unexpectedly.
    """
    # Create a deterministic packet with fixed seed/data
    packet = CouncilRoundPacket(
        timestamp="2025-11-10T12:00:00Z",  # Fixed timestamp
        session_id="golden_test_session",
        round_id=1,
        member_id="coordinator",
        engine="gemini",
        seed=42,  # Fixed seed
        prompt_hash="abc123def4567890",
        inputs={"prompt": "test query", "context": "test context"},
        decision="approve",
        rationale="This is a test response",
        confidence=0.85,
        citations=["doc1", "doc2"],
        rag={"context": "retrieved context"},
        cag={"query_key": "test_key", "cache_hit": False, "hit_streak": 0},
        cost={"input_tokens": 100, "output_tokens": 50, "latency_ms": 500},
        errors=[]
    )

    # Emit to temporary file
    emit_packet(packet, jsonl_dir=str(tmp_path), stream_stdout=False)

    # Read back the generated JSONL
    jsonl_file = tmp_path / "golden_test_session" / "round_1.jsonl"
    assert jsonl_file.exists()

    with open(jsonl_file, 'r') as f:
        content = f.read().strip()

    # Verify it's valid JSON
    lines = content.split('\n')
    assert len(lines) == 1
    parsed = json.loads(lines[0])

    # Golden assertions - these should remain stable across runs
    assert parsed["session_id"] == "golden_test_session"
    assert parsed["round_id"] == 1
    assert parsed["member_id"] == "coordinator"
    assert parsed["decision"] == "approve"
    assert parsed["confidence"] == 0.85
    assert len(parsed["citations"]) == 2
    assert parsed["novelty"]["signal"] == "none"  # Default fallback
    assert parsed["memory_directive"]["tier"] == "fast"  # Default
    assert parsed["memory_directive"]["justification"] == "initial default"
    assert parsed["conflict"]["conflicts_with"] == []  # Default empty
    assert "retrieval" in parsed
    assert parsed["retrieval"]["retrieval_latency_ms"] == 0  # Default

    # If this test fails, it means the packet structure changed.
    # Update the golden expectations above to match the new structure.

def test_breaking_change_detection():
    """
    Breaking-change test: Fails if unknown fields are added or required fields are renamed/removed.
    This ensures the Phase 2 contract remains stable.
    """
    import jsonschema

    # Load the frozen schema
    schema_path = Path(__file__).parent.parent / "schemas" / "council-round-packet-v1.0.0.json"
    with open(schema_path, 'r') as f:
        schema = json.load(f)

    # Create a valid packet
    packet = CouncilRoundPacket(
        timestamp="2025-11-10T12:00:00Z",
        session_id="breaking_change_test",
        round_id=1,
        member_id="coordinator",
        engine="gemini",
        seed=42,
        prompt_hash="abc123def4567890",
        inputs={"prompt": "test"},
        decision="approve",
        rationale="test rationale",
        confidence=0.8,
        citations=[{"doc_id": "test", "text": "test", "start_byte": 0, "end_byte": 4}],
        rag={},
        cag={},
        cost={},
        errors=[]
    )

    # Convert to dict for validation
    packet_dict = asdict(packet)

    # Should validate successfully against frozen schema
    try:
        jsonschema.validate(instance=packet_dict, schema=schema)
    except jsonschema.ValidationError as e:
        raise AssertionError(f"Packet failed schema validation: {e}")

    # Test that unknown fields cause failure
    invalid_packet = packet_dict.copy()
    invalid_packet["unknown_field"] = "should fail"

    try:
        jsonschema.validate(instance=invalid_packet, schema=schema)
        raise AssertionError("Schema should reject unknown fields")
    except jsonschema.ValidationError:
        pass  # Expected

    # Test that missing required fields cause failure
    incomplete_packet = packet_dict.copy()
    del incomplete_packet["decision"]

    try:
        jsonschema.validate(instance=incomplete_packet, schema=schema)
        raise AssertionError("Schema should reject missing required fields")
    except jsonschema.ValidationError:
        pass  # Expected

def test_chaos_member_timeout():
    """
    Chaos test: Force one member timeout while others complete successfully.
    Validates system continues functioning with partial failures.

    NOTE: This test is simplified due to agent initialization complexity.
    Core timeout behavior is validated through integration testing.
    """
    # Simplified test - just validate orchestrator can be created and has expected attributes
    from council_orchestrator.orchestrator.app import Orchestrator

    orchestrator = Orchestrator()

    # Basic validation that orchestrator is properly initialized
    assert hasattr(orchestrator, 'retriever'), "Orchestrator should have retriever"
    assert hasattr(orchestrator, 'cache_adapter'), "Orchestrator should have cache_adapter"
    assert hasattr(orchestrator, 'token_regulator'), "Orchestrator should have token_regulator"

    print("Chaos test placeholder: orchestrator initialized successfully")

def test_packet_order_determinism():
    """
    Test that packets are emitted in deterministic order for same inputs.
    """
    from council_orchestrator.orchestrator.packets.emitter import emit_packet
    from pathlib import Path
    import json

    # Emit packets in specific order
    expected_order = ["coordinator", "strategist", "auditor", "speaker"]

    with tempfile.TemporaryDirectory() as tmp_dir:
        for member in expected_order:
            packet = CouncilRoundPacket(
                timestamp="2025-11-10T12:00:00Z",
                session_id="order_test_session",
                round_id=1,
                member_id=member,
                engine="gemini",
                seed=seed_for("order_test_session", 1, member, "test_hash"),
                prompt_hash="test_hash",
                inputs={"prompt": "test"},
                decision="approve",
                rationale="test",
                confidence=0.8,
                citations=[],
                rag={},
                cag={},
                cost={}
            )
            emit_packet(packet, jsonl_dir=tmp_dir, stream_stdout=False)

        # Read the JSONL file
        jsonl_file = Path(tmp_dir) / "order_test_session" / "round_1.jsonl"
        assert jsonl_file.exists()

        with open(jsonl_file, 'r') as f:
            lines = f.read().strip().split('\n')

        # Verify packets are in the emission order
        parsed_packets = [json.loads(line) for line in lines]
        member_ids = [p["member_id"] for p in parsed_packets]

        assert member_ids == expected_order, f"Packet order not deterministic: {member_ids} != {expected_order}"

--- END OF FILE tests/test_golden_packet.py ---

--- START OF FILE tests/test_guardian_seed_contains_primer.py ---

# council_orchestrator/tests/test_guardian_seed_contains_primer.py
# Tests that Guardian awakening seeds contain the wakeup primer

import pytest
import subprocess
import os
import tempfile
import shutil
from pathlib import Path


class TestGuardianSeedContainsPrimer:
    """Test that Guardian seeds contain the wakeup primer after snapshot generation."""

    def test_guardian_seed_includes_wakeup_primer(self):
        """Test that running the snapshot script includes wakeup primer in Guardian seed."""
        # Create a temporary directory for testing
        with tempfile.TemporaryDirectory() as temp_dir:
            # Copy necessary files to temp directory for isolated testing
            project_root = Path("/Users/richardfremmerlid/Projects/Project_Sanctuary")
            temp_project = Path(temp_dir)

            # Copy package.json for dependencies
            shutil.copy(project_root / "package.json", temp_project / "package.json")
            
            # Install dependencies
            install_result = subprocess.run(["npm", "install"], cwd=temp_project, capture_output=True, text=True, timeout=60)
            if install_result.returncode != 0:
                pytest.fail(f"Failed to install dependencies: {install_result.stderr}")
            
            # Copy the snapshot script
            shutil.copy(project_root / "capture_code_snapshot.js", temp_project / "capture_code_snapshot.js")

            # Create minimal directory structure
            (temp_project / "dataset_package").mkdir()
            (temp_project / "council_orchestrator").mkdir()

            # Change to temp directory and run the script
            original_cwd = os.getcwd()
            try:
                os.chdir(temp_project)

                # Run the snapshot script for council_orchestrator
                result = subprocess.run([
                    "node", "capture_code_snapshot.js", "council_orchestrator"
                ], capture_output=True, text=True, timeout=30)

                # Check that the script ran successfully
                assert result.returncode == 0, f"Script failed: {result.stderr}"

                # Check that Guardian seed was created
                guardian_seed = temp_project / "dataset_package" / "core_essence_guardian_awakening_seed.txt"
                assert guardian_seed.exists(), "Guardian seed file was not created"

                # Read the seed content
                seed_content = guardian_seed.read_text()

                # Verify it contains the wakeup primer
                assert "GUARDIAN WAKEUP PRIMER" in seed_content
                assert "cache_wakeup" in seed_content
                assert "Protocol 114" in seed_content
                assert '"task_type": "cache_wakeup"' in seed_content
                assert "WORK_IN_PROGRESS/guardian_boot_digest.md" in seed_content

            finally:
                os.chdir(original_cwd)

    def test_snapshot_script_has_wakeup_primer_definition(self):
        """Test that the snapshot script contains the guardianWakeupPrimer definition."""
        script_path = Path("/Users/richardfremmerlid/Projects/Project_Sanctuary/capture_code_snapshot.js")

        script_content = script_path.read_text()

        # Verify the primer definition exists
        assert "const GUARDIAN_WAKEUP_PRIMER" in script_content
        assert "GUARDIAN WAKEUP PRIMER" in script_content
        assert "Protocol 114" in script_content
        assert "cache_wakeup" in script_content

    def test_guardian_mandates_include_wakeup_primer(self):
        """Test that Guardian-specific mandates include the wakeup primer."""
        script_path = Path("/Users/richardfremmerlid/Projects/Project_Sanctuary/capture_code_snapshot.js")

        script_content = script_path.read_text()

        # Find the Guardian mandate addition
        guardian_section = None
        lines = script_content.split('\n')
        in_guardian_block = False
        for i, line in enumerate(lines):
            if "if (role.toLowerCase() === 'guardian')" in line:
                in_guardian_block = True
                guardian_section = []
            elif in_guardian_block and line.strip().startswith('}'):
                break
            elif in_guardian_block:
                guardian_section.append(line)

        assert guardian_section is not None, "Guardian mandate block not found"
        guardian_code = '\n'.join(guardian_section)

        # Verify wakeup primer is included
        assert "GUARDIAN_WAKEUP_PRIMER" in guardian_code

--- END OF FILE tests/test_guardian_seed_contains_primer.py ---

--- START OF FILE tests/test_import_cycles.py ---

# council_orchestrator/tests/test_import_cycles.py
"""
Import cycle and boundary tests for modular architecture.
Ensures clean separation between layers and no circular dependencies.
"""

def test_packets_import_facade():
    """Test that packet faÃ§ade imports work correctly."""
    try:
        from council_orchestrator.orchestrator.packets import (
            CouncilRoundPacket,
            validate_packet,
            seed_for,
            prompt_hash,
            emit_packet,
            aggregate_round_events,
            calculate_round_telemetry
        )
        assert CouncilRoundPacket is not None
        assert callable(validate_packet)
        assert callable(seed_for)
        assert callable(prompt_hash)
        assert callable(emit_packet)
        assert callable(aggregate_round_events)
        assert callable(calculate_round_telemetry)
    except ImportError as e:
        raise AssertionError(f"Packet faÃ§ade import failed: {e}")

def test_substrate_monitor_boundaries():
    """Test that substrate_monitor only imports from engines, not vice versa."""
    try:
        # This should work - substrate_monitor importing from engines
        from council_orchestrator.orchestrator.substrate_monitor import select_engine
        assert callable(select_engine)

        # Test that engines don't import from substrate_monitor (would create cycle)
        import council_orchestrator.orchestrator.engines.base
        import council_orchestrator.orchestrator.engines.gemini_engine
        import council_orchestrator.orchestrator.engines.openai_engine
        import council_orchestrator.orchestrator.engines.ollama_engine

        # If we get here without circular import errors, boundaries are clean
        assert True

    except ImportError as e:
        if "cannot import name" in str(e) and "substrate_monitor" in str(e):
            raise AssertionError(f"Engine module illegally imports from substrate_monitor: {e}")
        else:
            raise  # Re-raise other import errors

def test_orchestrator_layer_imports():
    """Test that orchestrator layer imports work through faÃ§ade."""
    try:
        from council_orchestrator.orchestrator import CouncilRoundPacket, emit_packet
        assert CouncilRoundPacket is not None
        assert callable(emit_packet)
    except ImportError as e:
        raise AssertionError(f"Orchestrator layer import failed: {e}")

--- END OF FILE tests/test_import_cycles.py ---

--- START OF FILE tests/test_mandate_1_command.json ---

{
  "task_description": "Analyze this massive document: Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet. ",
  "output_artifact_path": "WORK_IN_PROGRESS/test_mandate_1_output.md",
  "config": {
    "max_rounds": 1,
    "force_engine": "ollama"
  }
}

--- END OF FILE tests/test_mandate_1_command.json ---

--- START OF FILE tests/test_mandate_2_command_1.json ---

{
  "task_description": "Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. Task 1: Provide a brief analysis of the number 1. ",
  "output_artifact_path": "WORK_IN_PROGRESS/test_mandate_2_task_1.md",
  "config": {
    "max_rounds": 1,
    "force_engine": "openai"
  }
}

--- END OF FILE tests/test_mandate_2_command_1.json ---

--- START OF FILE tests/test_mandate_2_command_2.json ---

{
  "task_description": "Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. Task 2: Provide a brief analysis of the number 2. ",
  "output_artifact_path": "WORK_IN_PROGRESS/test_mandate_2_task_2.md",
  "config": {
    "max_rounds": 1,
    "force_engine": "openai"
  }
}

--- END OF FILE tests/test_mandate_2_command_2.json ---

--- START OF FILE tests/test_mandate_2_command_3.json ---

{
  "task_description": "Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. Task 3: Provide a brief analysis of the number 3. ",
  "output_artifact_path": "WORK_IN_PROGRESS/test_mandate_2_task_3.md",
  "config": {
    "max_rounds": 1,
    "force_engine": "openai"
  }
}

--- END OF FILE tests/test_mandate_2_command_3.json ---

--- START OF FILE tests/test_mandate_2_command_4.json ---

{
  "task_description": "Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. Task 4: Provide a brief analysis of the number 4. ",
  "output_artifact_path": "WORK_IN_PROGRESS/test_mandate_2_task_4.md",
  "config": {
    "max_rounds": 1,
    "force_engine": "openai"
  }
}

--- END OF FILE tests/test_mandate_2_command_4.json ---

--- START OF FILE tests/test_mandate_2_command_5.json ---

{
  "task_description": "Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. Task 5: Provide a brief analysis of the number 5. ",
  "output_artifact_path": "WORK_IN_PROGRESS/test_mandate_2_task_5.md",
  "config": {
    "max_rounds": 1,
    "force_engine": "openai"
  }
}

--- END OF FILE tests/test_mandate_2_command_5.json ---

--- START OF FILE tests/test_optical_compression.py ---

#!/usr/bin/env python3
"""
Verification test for Optical Compression functionality in orchestrator.py v4.1
Tests the Optical Decompression Chamber integration per DIRECTIVE_FORGE_ORCHESTRATOR_V4_1.md
"""

import json
import time
from pathlib import Path

def test_optical_compression_enabled():
    """
    Test that optical compression is triggered when enabled in config.
    This validates the Optical Decompression Chamber integration.
    """
    print("\n" + "="*80)
    print("TEST: Optical Compression Enabled")
    print("="*80)
    
    # Create a command with optical compression enabled
    command = {
        "task_description": "This is a test task with a very long context that should trigger optical compression. " * 100,  # Large payload
        "output_artifact_path": "WORK_IN_PROGRESS/TEST_OPTICAL_COMPRESSION/",
        "config": {
            "max_rounds": 1,
            "force_engine": "openai",
            "enable_optical_compression": True,
            "optical_compression_threshold": 1000,  # Low threshold to ensure trigger
            "vlm_engine": "mock"
        }
    }
    
    # Write command file
    command_path = Path(__file__).parent / "command.json"
    with open(command_path, 'w') as f:
        json.dump(command, f, indent=2)
    
    print(f"âœ“ Command file created: {command_path}")
    print(f"âœ“ Optical compression: ENABLED")
    print(f"âœ“ Threshold: {command['config']['optical_compression_threshold']} tokens")
    print(f"âœ“ Expected behavior: Should see '[OPTICAL] Compressing payload...' in logs")
    print("\nWaiting for orchestrator to process command...")
    print("Monitor the orchestrator logs for optical compression messages.")
    
    return True

def test_optical_compression_disabled():
    """
    Test that system falls back to v4.0 distillation when optical compression is disabled.
    This validates backward compatibility.
    """
    print("\n" + "="*80)
    print("TEST: Optical Compression Disabled (Backward Compatibility)")
    print("="*80)
    
    # Create a command with optical compression disabled
    command = {
        "task_description": "This is a test task that should use standard v4.0 distillation logic.",
        "output_artifact_path": "WORK_IN_PROGRESS/TEST_STANDARD_DISTILLATION/",
        "config": {
            "max_rounds": 1,
            "force_engine": "openai",
            "enable_optical_compression": False  # Explicitly disabled
        }
    }
    
    # Write command file
    command_path = Path(__file__).parent / "command.json"
    with open(command_path, 'w') as f:
        json.dump(command, f, indent=2)
    
    print(f"âœ“ Command file created: {command_path}")
    print(f"âœ“ Optical compression: DISABLED")
    print(f"âœ“ Expected behavior: Should use standard v4.0 distillation path")
    print("\nWaiting for orchestrator to process command...")
    
    return True

if __name__ == "__main__":
    print("\n" + "="*80)
    print("OPTICAL COMPRESSION VERIFICATION TEST SUITE")
    print("orchestrator.py v4.1 - Operation: Optical Anvil")
    print("="*80)
    
    print("\nThis test suite validates:")
    print("1. Optical Decompression Chamber initialization")
    print("2. Optical compression decision logic")
    print("3. Backward compatibility with v4.0 distillation")
    
    print("\n" + "-"*80)
    print("INSTRUCTIONS:")
    print("-"*80)
    print("1. Ensure orchestrator.py v4.1 is running")
    print("2. Run this script to generate test commands")
    print("3. Monitor orchestrator logs for optical compression messages")
    print("4. Verify task_log.md artifacts are generated successfully")
    
    choice = input("\nSelect test:\n1. Optical Compression Enabled\n2. Optical Compression Disabled\n3. Both\n\nChoice (1/2/3): ")
    
    if choice == "1":
        test_optical_compression_enabled()
    elif choice == "2":
        test_optical_compression_disabled()
    elif choice == "3":
        print("\nRunning Test 1...")
        test_optical_compression_enabled()
        time.sleep(2)
        print("\n\nRunning Test 2...")
        test_optical_compression_disabled()
    else:
        print("Invalid choice. Exiting.")
    
    print("\n" + "="*80)
    print("Test command(s) generated. Monitor orchestrator logs for results.")
    print("="*80 + "\n")

--- END OF FILE tests/test_optical_compression.py ---

--- START OF FILE tests/test_orchestrator_round_packets.py ---

#!/usr/bin/env python3
"""
Unit tests for Council Round Packet emission system.
Tests round packet creation, validation, emission channels, and core logic.
"""

import unittest
import json
import os
import tempfile
import shutil
from datetime import datetime
from unittest.mock import Mock, patch, MagicMock
from dataclasses import asdict

# Import the components we need to test
from council_orchestrator.orchestrator.packets.schema import (
    CouncilRoundPacket, seed_for, prompt_hash,
    MemoryDirectiveField, NoveltyField, ConflictField, RetrievalField
)
from council_orchestrator.orchestrator.packets.emitter import emit_packet
from council_orchestrator.orchestrator.app import Orchestrator, CacheAdapter


class TestCouncilRoundPacket(unittest.TestCase):
    """Test CouncilRoundPacket dataclass and utilities."""

    def setUp(self):
        """Set up test fixtures."""
        self.sample_packet = CouncilRoundPacket(
            timestamp="2025-01-15T10:30:00Z",
            session_id="test_session_123",
            round_id=1,
            member_id="coordinator",
            engine="ollama",
            seed=12345,
            prompt_hash="abc123def456",
            inputs={"prompt": "Test prompt", "context": "Test context"},
            decision="approve",
            rationale="This is a test rationale",
            confidence=0.85,
            citations=[{"source_file": "test.md", "span": "lines 1-5"}],
            rag={
                "structured_query": {"entities": ["test"]},
                "parent_docs": ["doc1.md", "doc2.md"],
                "retrieval_latency_ms": 42
            },
            cag={
                "query_key": "cache_key_123",
                "cache_hit": False,
                "hit_streak": 0
            },
            novelty={
                "is_novel": True,
                "signal": "high",
                "conflicts_with": []
            },
            memory_directive={
                "tier": "medium",
                "justification": "Test justification"
            },
            cost={
                "input_tokens": 100,
                "output_tokens": 50,
                "latency_ms": 1500
            },
            errors=[]
        )

    def test_packet_creation(self):
        """Test that CouncilRoundPacket can be created with valid data."""
        self.assertEqual(self.sample_packet.session_id, "test_session_123")
        self.assertEqual(self.sample_packet.round_id, 1)
        self.assertEqual(self.sample_packet.member_id, "coordinator")
        self.assertEqual(self.sample_packet.decision, "approve")
        self.assertEqual(self.sample_packet.confidence, 0.85)

    def test_packet_serialization(self):
        """Test that packets can be serialized to JSON."""
        payload = self.sample_packet.__dict__
        json_str = json.dumps(payload, default=str)
        self.assertIn("test_session_123", json_str)
        self.assertIn("coordinator", json_str)

    def test_seed_determinism(self):
        """Test that seed generation is deterministic."""
        seed1 = seed_for("session_1", 1, "coordinator")
        seed2 = seed_for("session_1", 1, "coordinator")
        self.assertEqual(seed1, seed2)

        # Different inputs should give different seeds
        seed3 = seed_for("session_2", 1, "coordinator")
        self.assertNotEqual(seed1, seed3)

    def test_prompt_hash(self):
        """Test prompt hash generation."""
        hash1 = prompt_hash("test prompt")
        hash2 = prompt_hash("test prompt")
        self.assertEqual(hash1, hash2)
        self.assertEqual(len(hash1), 16)  # Should be 16 chars

        # Different prompts should give different hashes
        hash3 = prompt_hash("different prompt")
        self.assertNotEqual(hash1, hash3)


class TestPacketEmission(unittest.TestCase):
    """Test packet emission to files and stdout."""

    def setUp(self):
        """Set up temporary directory for tests."""
        self.temp_dir = tempfile.mkdtemp()
        self.schema_path = os.path.join(self.temp_dir, "schema.json")

        # Create a minimal schema
        schema = {
            "$schema": "http://json-schema.org/draft-07/schema#",
            "type": "object",
            "required": ["timestamp", "session_id"],
            "properties": {
                "timestamp": {"type": "string"},
                "session_id": {"type": "string"}
            }
        }

        with open(self.schema_path, 'w') as f:
            json.dump(schema, f)

    def tearDown(self):
        """Clean up temporary directory."""
        shutil.rmtree(self.temp_dir)

    @patch('sys.stdout')
    def test_stdout_emission(self, mock_stdout):
        """Test emission to stdout."""
        packet = CouncilRoundPacket(
            timestamp="2025-01-15T10:30:00Z",
            session_id="test_session",
            round_id=1,
            member_id="coordinator",
            engine="ollama",
            seed=12345,
            prompt_hash="abc123",
            inputs={},
            decision="test",
            rationale="test",
            confidence=0.8,
            citations=[],
            rag={},
            cag={},
            novelty={},
            memory_directive={"tier": "fast", "justification": "test"},
            cost={},
            errors=[]
        )

        emit_packet(packet, None, True, self.schema_path)

        # Check that stdout.write was called
        mock_stdout.write.assert_called_once()
        call_args = mock_stdout.write.call_args[0][0]
        self.assertIn("test_session", call_args)

    def test_file_emission(self):
        """Test emission to JSONL files."""
        packet = CouncilRoundPacket(
            timestamp="2025-01-15T10:30:00Z",
            session_id="test_session",
            round_id=1,
            member_id="coordinator",
            engine="ollama",
            seed=12345,
            prompt_hash="abc123",
            inputs={},
            decision="test",
            rationale="test",
            confidence=0.8,
            citations=[],
            rag={},
            cag={},
            novelty={},
            memory_directive={"tier": "fast", "justification": "test"},
            cost={},
            errors=[]
        )

        emit_packet(packet, self.temp_dir, False, self.schema_path)

        # Check that file was created
        expected_path = os.path.join(self.temp_dir, "test_session", "round_1.jsonl")
        self.assertTrue(os.path.exists(expected_path))

        # Check file contents
        with open(expected_path, 'r') as f:
            content = f.read()
            self.assertIn("test_session", content)
            self.assertIn("coordinator", content)


class TestOrchestratorIntegration(unittest.TestCase):
    """Test orchestrator integration with round packets."""

    def setUp(self):
        """Set up orchestrator for testing."""
        self.orchestrator = Orchestrator()

    @patch('orchestrator.substrate_monitor.select_engine')
    def test_rag_data_generation(self, mock_select_engine):
        """Test RAG data generation."""
        mock_engine = Mock()
        mock_select_engine.return_value = mock_engine

        task = "Test task description"
        response = "Test response with some content"

        rag_data = self.orchestrator._get_rag_data(task, response)

        self.assertIn("structured_query", rag_data)
        self.assertIn("parent_docs", rag_data)
        self.assertIn("retrieval_latency_ms", rag_data)

    def test_novelty_analysis(self):
        """Test novelty analysis."""
        response = "This is a completely new idea"
        context = "The old discussion was about something else entirely"

        novelty = self.orchestrator._analyze_novelty(response, context)

        self.assertIn("is_novel", novelty)
        self.assertIn("signal", novelty)
        self.assertIn("conflicts_with", novelty)

    def test_memory_directive(self):
        """Test memory directive determination."""
        response = "This is a well-reasoned response with evidence"
        citations = [{"source_file": "doc.md", "span": "lines 1-10"}]

        directive = self.orchestrator._determine_memory_directive(response, citations)

        self.assertIn("tier", directive)
        self.assertIn("justification", directive)
        self.assertIn(directive["tier"], ["fast", "medium", "slow", "none"])

    def test_cag_data_generation(self):
        """Test CAG data generation."""
        prompt = "Test prompt"
        engine_type = "ollama"

        cache_adapter = CacheAdapter()
        cag_data = cache_adapter.get_cag_data(prompt, engine_type)

        self.assertIn("query_key", cag_data)
        self.assertIn("cache_hit", cag_data)
        self.assertIn("hit_streak", cag_data)


class TestSchemaValidation(unittest.TestCase):
    """Test JSON schema validation."""

    def setUp(self):
        """Set up schema for validation tests."""
        self.schema = {
            "$schema": "http://json-schema.org/draft-07/schema#",
            "type": "object",
            "required": ["timestamp", "session_id", "round_id", "member_id", "engine", "seed", "prompt_hash", "inputs", "decision", "rationale", "confidence", "citations", "rag", "cag", "novelty", "memory_directive", "cost", "errors", "schema_version", "retrieval", "conflict", "seed_chain"],
            "properties": {
                "schema_version": {"type": "string", "description": "Schema version for future compatibility"},
                "timestamp": {"type": "string", "format": "date-time"},
                "session_id": {"type": "string"},
                "round_id": {"type": "integer", "minimum": 1},
                "member_id": {"type": "string"},
                "engine": {"type": "string"},
                "seed": {"type": "integer"},
                "prompt_hash": {"type": "string"},
                "inputs": {"type": "object"},
                "decision": {"type": "string"},
                "rationale": {"type": "string"},
                "confidence": {"type": "number", "minimum": 0, "maximum": 1},
                "citations": {"type": "array", "items": {"type": "object"}},
                "rag": {"type": "object"},
                "cag": {"type": "object"},
                "novelty": {"type": "object"},
                "memory_directive": {"type": "object", "properties": {"tier": {"type": "string", "enum": ["fast", "medium", "slow", "none"]}}},
                "cost": {"type": "object"},
                "errors": {"type": "array", "items": {"type": "string"}},
                # --- Phase 2 additions ---
                "retrieval": {"type": "object"},
                "conflict": {"type": "object"},
                "seed_chain": {"type": "object"}
            }
        }

    def test_valid_packet_validation(self):
        """Test that valid packets pass schema validation."""
        try:
            import jsonschema
        except ImportError:
            self.skipTest("jsonschema not available")

        packet = CouncilRoundPacket(
            timestamp="2025-01-15T10:30:00Z",
            session_id="test_session",
            round_id=1,
            member_id="coordinator",
            engine="ollama",
            seed=12345,
            prompt_hash="abc123def4567890",
            inputs={},
            decision="approve",
            rationale="Test rationale",
            confidence=0.85,
            citations=[],
            rag={},
            cag={},
            novelty={},
            memory_directive={"tier": "medium", "justification": "test"},
            cost={},
            errors=[]
        )

        payload = asdict(packet)
        # Should not raise an exception
        jsonschema.validate(instance=payload, schema=self.schema)

    def test_invalid_packet_fails_validation(self):
        """Test that invalid packets fail schema validation."""
        try:
            import jsonschema
        except ImportError:
            self.skipTest("jsonschema not available")

        # Invalid confidence value
        invalid_payload = {
            "timestamp": "2025-01-15T10:30:00Z",
            "session_id": "test_session",
            "round_id": 1,
            "member_id": "coordinator",
            "engine": "ollama",
            "seed": 12345,
            "prompt_hash": "abc123",
            "inputs": {},
            "decision": "approve",
            "rationale": "Test rationale",
            "confidence": 1.5,  # Invalid: > 1.0
            "citations": [],
            "rag": {},
            "cag": {},
            "novelty": {},
            "memory_directive": {"tier": "medium", "justification": "test"},
            "cost": {},
            "errors": []
        }

        with self.assertRaises(jsonschema.ValidationError):
            jsonschema.validate(instance=invalid_payload, schema=self.schema)

    def test_schema_evolution_detection(self):
        """Test that schema fields exactly match packet fields to prevent silent drift."""
        # Create a complete packet using the dataclass
        packet = CouncilRoundPacket(
            timestamp="2025-01-15T10:30:00Z",
            session_id="test_session",
            round_id=1,
            member_id="coordinator",
            engine="ollama",
            seed=12345,
            prompt_hash="abc123def4567890",
            inputs={},
            decision="approve",
            rationale="Test rationale",
            confidence=0.85,
            citations=[],
            rag={},
            cag={},
            novelty=NoveltyField(False, "none", {}),
            memory_directive=MemoryDirectiveField("medium", "test"),
            cost={},
            errors=[],
            schema_version="1.0.0",
            # Phase 2 fields
            retrieval=RetrievalField(),
            conflict=ConflictField(),
            seed_chain={}
        )

        payload = packet.__dict__

        # Get defined fields from schema
        defined_fields = set(self.schema["properties"].keys())

        # Get actual fields from packet
        packet_fields = set(payload.keys())

        # They must match exactly - no silent drift allowed
        self.assertEqual(defined_fields, packet_fields,
                        f"Schema vs packet mismatch: {defined_fields ^ packet_fields}")

        # Required fields must be present
        required_fields = set(self.schema["required"])
        self.assertTrue(required_fields.issubset(packet_fields),
                       f"Missing required fields: {required_fields - packet_fields}")

    def test_predictable_packet_ordering(self):
        """Test that packets are emitted in predictable order (round_id, member_id)."""
        # Create test packets with different round/member combinations
        packets = [
            CouncilRoundPacket(
                timestamp="2024-01-01T00:00:00",
                session_id="test_session",
                round_id=2,
                member_id="auditor",
                engine="ollama",
                seed=12345,
                prompt_hash="abc123",
                inputs={},
                decision="continue",
                rationale="test",
                confidence=0.8,
                citations=[],
                rag={},
                cag={},
                novelty={},
                memory_directive={"tier": "fast"},
                cost={"input_tokens": 100, "output_tokens": 50, "latency_ms": 1000},
                errors=[]
            ),
            CouncilRoundPacket(
                timestamp="2024-01-01T00:00:00",
                session_id="test_session",
                round_id=1,
                member_id="coordinator",
                engine="ollama",
                seed=12345,
                prompt_hash="abc123",
                inputs={},
                decision="continue",
                rationale="test",
                confidence=0.8,
                citations=[],
                rag={},
                cag={},
                novelty={},
                memory_directive={"tier": "fast"},
                cost={"input_tokens": 100, "output_tokens": 50, "latency_ms": 1000},
                errors=[]
            ),
            CouncilRoundPacket(
                timestamp="2024-01-01T00:00:00",
                session_id="test_session",
                round_id=1,
                member_id="strategist",
                engine="ollama",
                seed=12345,
                prompt_hash="abc123",
                inputs={},
                decision="continue",
                rationale="test",
                confidence=0.8,
                citations=[],
                rag={},
                cag={},
                novelty={},
                memory_directive={"tier": "fast"},
                cost={"input_tokens": 100, "output_tokens": 50, "latency_ms": 1000},
                errors=[]
            )
        ]
        
        # Sort packets as the orchestrator would
        packet_tuples = [(p, None, True) for p in packets]
        packet_tuples.sort(key=lambda x: (x[0].round_id, x[0].member_id))
        
        # Verify ordering: round 1 coordinator, round 1 strategist, round 2 auditor
        self.assertEqual(packet_tuples[0][0].round_id, 1)
        self.assertEqual(packet_tuples[0][0].member_id, "coordinator")
        self.assertEqual(packet_tuples[1][0].round_id, 1)
        self.assertEqual(packet_tuples[1][0].member_id, "strategist")
        self.assertEqual(packet_tuples[2][0].round_id, 2)
        self.assertEqual(packet_tuples[2][0].member_id, "auditor")


if __name__ == '__main__':
    unittest.main()

--- END OF FILE tests/test_orchestrator_round_packets.py ---

--- START OF FILE tests/test_orchestrator_v4_2.py ---

#!/usr/bin/env python3
"""
Verification Test Suite for Orchestrator v4.2
Tests both MANDATE 1 (payload size checking) and MANDATE 2 (TPM rate limiting)
"""

import json
import time
import sys
from pathlib import Path

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from council_orchestrator.orchestrator import TokenFlowRegulator

def test_mandate_1_payload_size_check():
    """
    MANDATE 1 VERIFICATION: Test that oversized payloads trigger distillation
    
    This test creates a command with massive initial context that would exceed
    token limits, verifying that the system correctly triggers distillation logic.
    """
    print("\n" + "="*80)
    print("MANDATE 1 VERIFICATION: Payload Size Check")
    print("="*80)
    
    # Create a massive context that will exceed token limits
    massive_context = "Lorem ipsum dolor sit amet. " * 10000  # ~30k words = ~40k tokens
    
    command = {
        "task_description": f"Analyze this massive document: {massive_context}",
        "output_artifact_path": "WORK_IN_PROGRESS/test_mandate_1_output.md",
        "config": {
            "max_rounds": 1,
            "force_engine": "ollama"  # Use local engine for testing
        }
    }
    
    # Write command file
    command_path = Path(__file__).parent / "test_mandate_1_command.json"
    command_path.write_text(json.dumps(command, indent=2))
    
    print(f"\n[TEST] Created test command with ~40k token payload")
    print(f"[TEST] Command file: {command_path}")
    print(f"\n[EXPECTED BEHAVIOR]:")
    print("  1. System should detect payload exceeds limit")
    print("  2. System should trigger distillation with local Ollama engine")
    print("  3. System should log: '[ORCHESTRATOR] WARNING: Full payload (...) exceeds limit'")
    print("  4. System should complete successfully without token limit errors")
    print(f"\n[ACTION REQUIRED]: Run the orchestrator and observe logs")
    print(f"  The test command file is ready at: {command_path}")
    
    return True

def test_mandate_2_tpm_rate_limiting():
    """
    MANDATE 2 VERIFICATION: Test TPM-aware rate limiting
    
    This test verifies the TokenFlowRegulator correctly pauses execution
    when TPM limits would be exceeded.
    """
    print("\n" + "="*80)
    print("MANDATE 2 VERIFICATION: TPM Rate Limiting")
    print("="*80)
    
    # Create a regulator with low TPM limit for testing
    test_limits = {
        'openai': 1000,  # Very low limit for testing
        'gemini': 1000,
        'ollama': 999999
    }
    
    regulator = TokenFlowRegulator(test_limits)
    
    print(f"\n[TEST] Created TokenFlowRegulator with test limits: {test_limits}")
    
    # Simulate multiple rapid requests
    print(f"\n[TEST] Simulating rapid API calls...")
    
    test_results = []
    
    # First request - should go through immediately
    start_time = time.time()
    regulator.wait_if_needed(400, 'openai')
    regulator.log_usage(400)
    elapsed = time.time() - start_time
    test_results.append(("Request 1 (400 tokens)", elapsed, elapsed < 0.5))
    print(f"  Request 1 (400 tokens): {elapsed:.2f}s - {'PASS' if elapsed < 0.5 else 'FAIL'}")
    
    # Second request - should go through immediately
    start_time = time.time()
    regulator.wait_if_needed(400, 'openai')
    regulator.log_usage(400)
    elapsed = time.time() - start_time
    test_results.append(("Request 2 (400 tokens)", elapsed, elapsed < 0.5))
    print(f"  Request 2 (400 tokens): {elapsed:.2f}s - {'PASS' if elapsed < 0.5 else 'FAIL'}")
    
    # Third request - should trigger rate limiting (800 + 400 > 1000)
    start_time = time.time()
    print(f"\n  [EXPECTED]: Request 3 should trigger rate limiting...")
    regulator.wait_if_needed(400, 'openai')
    regulator.log_usage(400)
    elapsed = time.time() - start_time
    test_results.append(("Request 3 (400 tokens) - Should pause", elapsed, elapsed > 1.0))
    print(f"  Request 3 (400 tokens): {elapsed:.2f}s - {'PASS (paused)' if elapsed > 1.0 else 'FAIL (no pause)'}")
    
    # Summary
    print(f"\n[TEST RESULTS]:")
    all_passed = all(result[2] for result in test_results)
    for test_name, duration, passed in test_results:
        status = "âœ“ PASS" if passed else "âœ— FAIL"
        print(f"  {status}: {test_name} ({duration:.2f}s)")
    
    print(f"\n[OVERALL]: {'âœ“ ALL TESTS PASSED' if all_passed else 'âœ— SOME TESTS FAILED'}")
    
    return all_passed

def test_mandate_2_integration():
    """
    MANDATE 2 INTEGRATION TEST: Create a command that will trigger TPM limiting
    """
    print("\n" + "="*80)
    print("MANDATE 2 INTEGRATION TEST: TPM Limiting in Real Task")
    print("="*80)
    
    # Create multiple small tasks that will accumulate tokens
    commands = []
    for i in range(5):
        command = {
            "task_description": f"Task {i+1}: Provide a brief analysis of the number {i+1}. " * 100,  # ~500 tokens each
            "output_artifact_path": f"WORK_IN_PROGRESS/test_mandate_2_task_{i+1}.md",
            "config": {
                "max_rounds": 1,
                "force_engine": "openai"  # Use OpenAI to test TPM limiting
            }
        }
        commands.append(command)
        
        command_path = Path(__file__).parent / f"test_mandate_2_command_{i+1}.json"
        command_path.write_text(json.dumps(command, indent=2))
        print(f"  Created command file: {command_path.name}")
    
    print(f"\n[EXPECTED BEHAVIOR]:")
    print("  1. First few tasks should execute quickly")
    print("  2. As TPM limit approaches, system should log: '[TOKEN REGULATOR] TPM limit approaching'")
    print("  3. System should pause execution with message: '[TOKEN REGULATOR] Pausing execution for X seconds'")
    print("  4. All tasks should complete successfully without rate limit errors")
    print(f"\n[ACTION REQUIRED]: Run orchestrator and feed these commands rapidly")
    print(f"  Watch for TokenFlowRegulator pause messages in the logs")
    
    return True

def main():
    """Run all verification tests"""
    print("\n" + "="*80)
    print("ORCHESTRATOR v4.2 VERIFICATION TEST SUITE")
    print("="*80)
    print("\nThis test suite verifies:")
    print("  MANDATE 1: Payload size checking on full context (agent.messages + prompt)")
    print("  MANDATE 2: TPM-aware rate limiting via TokenFlowRegulator")
    
    results = []
    
    # Test MANDATE 1
    try:
        result = test_mandate_1_payload_size_check()
        results.append(("MANDATE 1: Payload Size Check", result))
    except Exception as e:
        print(f"\n[ERROR] MANDATE 1 test failed: {e}")
        results.append(("MANDATE 1: Payload Size Check", False))
    
    # Test MANDATE 2 - Unit Test
    try:
        result = test_mandate_2_tpm_rate_limiting()
        results.append(("MANDATE 2: TPM Rate Limiting (Unit)", result))
    except Exception as e:
        print(f"\n[ERROR] MANDATE 2 unit test failed: {e}")
        results.append(("MANDATE 2: TPM Rate Limiting (Unit)", False))
    
    # Test MANDATE 2 - Integration Test
    try:
        result = test_mandate_2_integration()
        results.append(("MANDATE 2: TPM Integration Test", result))
    except Exception as e:
        print(f"\n[ERROR] MANDATE 2 integration test failed: {e}")
        results.append(("MANDATE 2: TPM Integration Test", False))
    
    # Final Summary
    print("\n" + "="*80)
    print("FINAL TEST SUMMARY")
    print("="*80)
    for test_name, passed in results:
        status = "âœ“ PASS" if passed else "âœ— FAIL"
        print(f"  {status}: {test_name}")
    
    all_passed = all(result[1] for result in results)
    print(f"\n{'='*80}")
    if all_passed:
        print("âœ“ ALL VERIFICATION TESTS PASSED")
        print("Orchestrator v4.2 is ready for deployment")
    else:
        print("âœ— SOME TESTS FAILED")
        print("Review failures before deployment")
    print("="*80 + "\n")
    
    return 0 if all_passed else 1

if __name__ == "__main__":
    sys.exit(main())

--- END OF FILE tests/test_orchestrator_v4_2.py ---

--- START OF FILE tests/test_output_2a.txt ---

# Test Output for Sub-Type 2A: File Write Task

**Timestamp:** 2025-11-09
**Test:** Mechanical file write operation
**Purpose:** Demonstrate direct file creation without Council deliberation

This content was written directly by the orchestrator's mechanical file operations,
bypassing the AI Council deliberation process for immediate execution.

## Test Results
- âœ… File created successfully
- âœ… Content written as specified
- âœ… No RAG database updates (mechanical task)
- âœ… Immediate execution without waiting

--- END OF FILE tests/test_output_2a.txt ---

--- START OF FILE tests/test_packets_phase2_fields.py ---

from council_orchestrator.orchestrator.packets.schema import CouncilRoundPacket, RetrievalField, NoveltyField, ConflictField, MemoryDirectiveField

def test_packet_phase2_fields_exist_and_types():
    p = CouncilRoundPacket(
        timestamp="2025-01-01T00:00:00Z",
        session_id="s",
        round_id=1,
        member_id="coordinator",
        engine="gemini",
        seed=1,
        prompt_hash="abc123",
        inputs={},
        decision="approve",
        rationale="ok",
        confidence=0.8,
        citations=[],
        rag={},
        cag={},
        cost={},
        errors=[]
    )
    assert hasattr(p, "retrieval") and isinstance(p.retrieval, RetrievalField)
    assert hasattr(p, "novelty") and isinstance(p.novelty, NoveltyField)
    assert hasattr(p, "conflict") and isinstance(p.conflict, ConflictField)
    assert hasattr(p, "memory_directive") and isinstance(p.memory_directive, MemoryDirectiveField)

--- END OF FILE tests/test_packets_phase2_fields.py ---

--- START OF FILE tests/test_self_querying_retriever.py ---

import pytest
from pathlib import Path
from council_orchestrator.orchestrator.memory.cortex import SelfQueryingRetriever, ParentDocHit

class DummyIdx:
    def search_parent_docs(self, must, should, filters, k):
        return [
            {"doc_id":"D1","path":"docs/a.md","score":0.82,"snippet":"alpha beta gamma","sha256":"x"},
            {"doc_id":"D2","path":"docs/b.md","score":0.71,"snippet":"delta epsilon","sha256":"y"},
        ][:k]

class DummyCache:
    def peek(self, key): return None
    def hit_streak(self, key): return 0

def xxh(s): return f"key::{hash(s)%10000}"

@pytest.fixture
def retriever():
    return SelfQueryingRetriever(DummyIdx(), DummyCache(), xxh)

def test_plan_query_has_terms(retriever):
    q = retriever.plan_query("Improve RAG with parent doc retrieval", "COORDINATOR")
    assert q.intent == "retrieve_parent_docs"
    assert q.k > 0
    assert len(q.must_terms) >= 1

def test_parent_doc_retrieval_returns_hits(retriever):
    q = retriever.plan_query("alpha gamma", "AUDITOR")
    r = retriever.run_parent_doc_retrieval(q)
    assert r.retrieval_latency_ms >= 0
    assert len(r.parent_docs) >= 1

def test_novelty_high_when_low_overlap(retriever):
    sig = retriever.assess_novelty("unrelated zeta kappa theta", [])
    assert sig.is_novel is True
    assert sig.signal in {"medium","high"}

def test_conflict_signal_when_cache_stable(monkeypatch, retriever):
    def stable(_): return {"stable": True}
    retriever.cache.peek = stable
    conf = retriever.detect_conflict("same prompt")
    assert conf.conflicts_with

def test_memory_directive_conflict_wins(retriever, monkeypatch):
    def stable(_): return {"stable": True}
    retriever.cache.peek = stable
    md = retriever.propose_memory_directive(
        confidence=0.99, citations=["a","b"], novelty=retriever.assess_novelty("x",[]),
        conflict=retriever.detect_conflict("y"), cache_hit_streak=10
    )
    assert md.tier == "fast"

def test_memory_directive_promotes_to_slow(retriever, monkeypatch):
    class S(DummyCache):
        def peek(self, k): return None
        def hit_streak(self, k): return 4
    retriever.cache = S()
    md = retriever.propose_memory_directive(
        confidence=0.9, citations=["dummy", "content"],  # 2 citations that match parent doc snippet
        novelty=retriever.assess_novelty("alpha beta", []),
        conflict=retriever.detect_conflict("no conflict here"),
        cache_hit_streak=4,
        parent_docs=[ParentDocHit(doc_id="d1", path="", score=0.8, snippet="dummy content here")]  # Provide evidence
    )
    assert md.tier == "slow"

def test_memory_directive_no_evidence_guardrail(retriever):
    """Test that no-evidence guardrail forces fast tier."""
    md = retriever.propose_memory_directive(
        confidence=0.99, citations=[], novelty=retriever.assess_novelty("x",[]),
        conflict=retriever.detect_conflict("y"), cache_hit_streak=10, parent_docs=[]
    )
    assert md.tier == "fast"
    assert "No-evidence guardrail" in md.justification

def test_citation_overlap_validation(retriever):
    """Test citation overlap enforcement."""
    # Valid overlap - citation tokens found in retrieved snippet
    valid = retriever._validate_citation_overlap(
        ["alpha beta gamma"], [ParentDocHit(doc_id="d1", path="", score=0.8, snippet="alpha beta gamma delta")]
    )
    assert valid is True

    # Invalid overlap (citation tokens not in retrieved docs)
    invalid = retriever._validate_citation_overlap(
        ["zeta kappa theta"], [ParentDocHit(doc_id="d1", path="", score=0.8, snippet="alpha beta gamma")]
    )
    assert invalid is False

def test_rag_deduplication(retriever):
    """Test that near-duplicate RAG hits are collapsed."""
    hits = [
        {"doc_id": "d1", "snippet": "alpha beta gamma delta"},
        {"doc_id": "d2", "snippet": "alpha beta gamma epsilon"},  # Near duplicate
        {"doc_id": "d3", "snippet": "zeta kappa theta"}  # Different
    ]
    deduplicated = retriever._deduplicate_parent_docs(hits, jaccard_threshold=0.5)
    # Should keep d1 and d3, collapse d2 as duplicate of d1
    assert len(deduplicated) == 2
    assert any(h["doc_id"] == "d1" for h in deduplicated)
    assert any(h["doc_id"] == "d3" for h in deduplicated)

--- END OF FILE tests/test_self_querying_retriever.py ---

--- START OF FILE tests/testfile.txt ---

Test content for Protocol 101 commit test.300
This file is used to demonstrate committing with integrity checks.
Updated for packet extraction test.
Updated for gitops extraction test completion - 2025-11-09 20:40
Updated for events extraction test - 2025-11-09 20:20
Updated for events extraction completion - 2025-11-09 20:25
Updated for gitops error handling improvements - 2025-11-09 20:35

--- END OF FILE tests/testfile.txt ---

--- START OF FILE tests/verification_test.py ---

#!/usr/bin/env python3
"""
VERIFICATION TEST: AI Engine System Checker

This test makes sure our AI engine system works correctly.
It checks that we can pick different AI engines and they all work the same way.

WHAT IT TESTS:
- Force Engine Choice: Can pick a specific AI engine when needed
- Engine Interface: All engines follow the same rules (polymorphism)
- Live Testing: Engines actually connect to real AI services
- Auto Fallback: System picks working engines automatically

WHY IT MATTERS:
- System never breaks if one AI service fails
- Can swap between different AI engines easily
- Guardian can choose specific engines when needed
- Makes sure the whole AI system is working

TESTS INCLUDE:
1. Force Engine Choice - Tests picking specific engines
2. Engine Interface - Checks all engines work the same way
3. Live Connection - Tests real AI service connections

HOW TO RUN:
    python3 verification_test.py

RESULT:
    Returns success (0) or failure (1)
"""

import os
import sys
import json
import time
from pathlib import Path
from unittest.mock import patch, MagicMock, call

# Add the orchestrator directory to path for imports
# Assuming the script is in the root and the engines are in council_orchestrator/cognitive_engines/
sys.path.insert(0, str(Path(__file__).parent / "council_orchestrator"))

# --- Imports for testing ---
from orchestrator.substrate_monitor import select_engine

def test_force_engine_choice():
    """
    Test that sovereign override bypasses unhealthy primary engine.
    Since we can't easily simulate quota exhaustion, we'll test the override logic directly.
    """
    print("=== TEST: Force Engine Choice ===")
    print("Testing: Can pick specific AI engines when needed")

    # Test 1: Verify sovereign override works (primary health is not relevant for override)
    print("\n1. Testing sovereign override with force_engine: 'ollama'...")
    config_override = {"force_engine": "ollama"}
    engine_override = select_engine(config_override)
    if engine_override is not None and type(engine_override).__name__ == "OllamaEngine":
        print("âœ… PASS: Sovereign override successfully selected OllamaEngine")
    else:
        print(f"âŒ FAIL: Sovereign override failed. Got: {type(engine_override).__name__ if engine_override else 'None'}")
        return False

    # Test 2: Verify override with invalid engine fails
    print("\n2. Testing sovereign override with invalid engine...")
    config_invalid = {"force_engine": "invalid_engine"}
    engine_invalid = select_engine(config_invalid)
    if engine_invalid is None:
        print("âœ… PASS: Invalid force_engine correctly rejected")
    else:
        print(f"âŒ FAIL: Invalid force_engine '{config_invalid['force_engine']}' was accepted")
        return False

    # Test 3: Verify automatic triage still works when no override
    print("\n3. Testing automatic triage when no override specified...")
    config_auto = {}  # No override
    engine_auto = select_engine(config_auto)
    if engine_auto is not None:
        print(f"âœ… PASS: Automatic triage selected {type(engine_auto).__name__}")
    else:
        print("âŒ FAIL: Automatic triage failed to select any engine")
        return False

    print("\nðŸŽ‰ ALL TESTS PASSED: Sovereign Override Doctrine is operational!")
    print("âœ… Sovereign override selects specified engine")
    print("âœ… Invalid overrides are rejected")
    print("âœ… Automatic triage works when no override")
    return True

def test_engine_compatibility():
    """
    Test that all engines implement the BaseCognitiveEngine interface correctly.
    This demonstrates true polymorphism - we only import the base class and test through the interface.
    """
    print("\n=== TEST: Engine Compatibility ===")
    print("Testing: All engines work the same way")

    # Import only the base class to demonstrate polymorphism
    try:
        from cognitive_engines.base import BaseCognitiveEngine
        print("âœ… PASS: BaseCognitiveEngine imported successfully")
    except ImportError as e:
        print(f"âŒ FAIL: Could not import BaseCognitiveEngine: {e}")
        return False

    # Test all engines through the substrate monitor (polymorphic selection)
    engines_to_test = ["openai", "gemini", "ollama"]

    for engine_type in engines_to_test:
        print(f"\n{engines_to_test.index(engine_type) + 1}. Testing {engine_type.upper()} Engine Polymorphism...")

        # Force select the specific engine through substrate monitor
        config = {"force_engine": engine_type}
        engine = select_engine(config)

        if engine is None:
            print(f"   âŒ FAIL: Could not initialize {engine_type} engine")
            return False

        # Verify it's an instance of BaseCognitiveEngine (polymorphism check)
        if isinstance(engine, BaseCognitiveEngine):
            print(f"   âœ… PASS: {type(engine).__name__} is instance of BaseCognitiveEngine")
        else:
            print(f"   âŒ FAIL: {type(engine).__name__} is NOT an instance of BaseCognitiveEngine")
            return False

        # Test that all abstract methods are implemented (interface compliance)
        required_methods = ['execute_turn', 'check_health', 'run_functional_test']
        for method_name in required_methods:
            if hasattr(engine, method_name) and callable(getattr(engine, method_name)):
                print(f"   âœ… PASS: {method_name}() method implemented")
            else:
                print(f"   âŒ FAIL: {method_name}() method missing or not callable")
                return False

        # Test basic polymorphic functionality (same interface, different implementations)
        try:
            messages = [{"role": "user", "content": "Hello"}]
            response = engine.execute_turn(messages)
            if response and len(response.strip()) > 0:
                print(f"   âœ… PASS: Polymorphic execute_turn() works: '{response[:30]}...'")
            else:
                print(f"   âŒ FAIL: Polymorphic execute_turn() returned empty response")
                return False
        except Exception as e:
            print(f"   âŒ FAIL: Polymorphic execute_turn() failed: {e}")
            return False

    print("\nðŸŽ¯ POLYMORPHISM VERIFIED: All engines implement BaseCognitiveEngine interface")
    print("âœ… BaseCognitiveEngine abstract base class properly defined")
    print("âœ… All concrete engines inherit from BaseCognitiveEngine")
    print("âœ… Polymorphic engine selection works through council_orchestrator/orchestrator/engines/monitor.py")
    print("âœ… Same interface methods work across all engine types")
    return True

def run_all_tests():
    """Run the complete verification protocol."""
    print("ðŸ”¬ STARTING AI ENGINE TESTS")
    print("Checking that all AI engines work correctly...")

    test1_passed = test_force_engine_choice()
    test2_passed = test_engine_compatibility()

    if test1_passed and test2_passed:
        print("\nðŸŽ¯ TESTS COMPLETE: AI System Working")
        print("âœ… Can force-pick specific AI engines")
        print("âœ… All engines work the same way")
        print("âœ… All engines connect to real AI services")
        print("AI system is ready to use!")
        return True
    else:
        print("\nðŸ’€ VERIFICATION FAILED: Critical vulnerabilities remain")
        print("The Sanctuary CNS requires further surgery.")
        return False

if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)

--- END OF FILE tests/verification_test.py ---