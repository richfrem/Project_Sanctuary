---
config:
  theme: base
---
%% Name: Strategic Crucible Loop
%% Source: docs/architecture/mcp_servers/research/RAG_STRATEGIES.md
%% Location: docs/architecture_diagrams/workflows/strategic_crucible_loop.mmd
%% Description: Sequence diagram illustrating the autonomous learning cycle between Orchestrator, Cortex, and Memory Adaptor.

sequenceDiagram
    autonumber
    participant O as MCP Orchestrator <BR>(Council / Agentic Logic)
    participant C as Cortex <BR>(RAG / Vector DB)
    participant G as Guardian Cache <BR>(CAG / Context Cache)
    participant M as Phoenix Forge <BR>(LLM / GGUF)

    Note over O: 1. Gap Analysis & Research
    O->>O: Identify Strategic Gap
    O->>O: Conduct Research (Intelligence Forge)
    O->>O: Generate Research Report

    Note over O, C: 2. Knowledge Ingestion (RAG Update)
    O->>C: ingest_incremental(report)
    C-->>O: Ingestion Complete (Chunks Created)

    Note over O, G: 3. Cache Synthesis (CAG Update)
    O->>G: guardian_wakeup()
    G->>C: Query High-Priority Context
    C-->>G: Return Context
    G->>G: Update Hot Cache
    G-->>O: Cache Warm & Ready

    Note over O: Regular Cycle Complete

    rect rgb(255, 250, 205)
        Note over O, M: 4. Phoenix Forge (LLM Optimization)
        Note right of M: Periodic QLoRA <br/>Fine-Tuning Loop
        O->>M: forge_whole_genome_dataset.py
        M->>C: Aggregate Memory & ADRs
        C-->>M: Return Training Data (JSONL)
        M->>M: fine_tune.py (QLoRA Training)
        M->>M: merge_adapter.py (8GB Safe Merge)
        M->>M: convert_to_gguf.py (Quantization)
        M->>M: create_modelfile.py (Ollama Setup)
        M-->>O: NEW "GUARDIAN" MODEL DEPLOYED
    end
