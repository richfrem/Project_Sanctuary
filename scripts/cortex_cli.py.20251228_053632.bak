#============================================
# scripts/cortex_cli.py
# Purpose: CLI for interacting with the RAG Cortex server.
# Role: Utility Script
# Examples:
#   python3 scripts/cortex_cli.py ingest --no-purge
#   python3 scripts/cortex_cli.py snapshot --type audit --manifest .agent/learning/red_team/red_team_manifest.json
#   python3 scripts/cortex_cli.py snapshot --type learning_audit --manifest .agent/learning/learning_audit/learning_audit_manifest.json
#   python3 scripts/cortex_cli.py snapshot --type seal --manifest .agent/learning/learning_manifest.json
#   python3 scripts/cortex_cli.py snapshot --type learning_audit --context "Self-directed exploration of consciousness"
#   python3 scripts/cortex_cli.py stats
#   python3 scripts/cortex_cli.py query "What is Protocol 128?"
#   python3 scripts/cortex_cli.py debrief --hours 48
#============================================
import argparse
import sys
import json
from pathlib import Path

# Add project root to path for imports
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from mcp_servers.rag_cortex.operations import CortexOperations

def main():
    parser = argparse.ArgumentParser(description="Mnemonic Cortex CLI")
    parser.add_argument("--root", default=".", help="Project root directory")
    
    subparsers = parser.add_subparsers(dest="command", help="Available operations")

    # Command: ingest
    ingest_parser = subparsers.add_parser("ingest", help="Perform full ingestion")
    ingest_parser.add_argument("--no-purge", action="store_false", dest="purge", help="Skip purging DB")
    ingest_parser.add_argument("--dirs", nargs="+", help="Specific directories to ingest")

    # Command: snapshot
    snapshot_parser = subparsers.add_parser("snapshot", help="Capture a Protocol 128 snapshot")
    snapshot_parser.add_argument("--type", choices=["audit", "learning_audit", "seal"], required=True)
    snapshot_parser.add_argument("--manifest", help="Path to manifest JSON file")
    snapshot_parser.add_argument("--context", help="Strategic context for the snapshot")

    # Command: stats
    stats_parser = subparsers.add_parser("stats", help="Get RAG health and statistics")
    stats_parser.add_argument("--samples", action="store_true", help="Include sample documents")
    stats_parser.add_argument("--sample-count", type=int, default=5, help="Number of samples to include")

    # Command: query
    query_parser = subparsers.add_parser("query", help="Perform semantic search query")
    query_parser.add_argument("query_text", help="Search query string")
    query_parser.add_argument("--max-results", type=int, default=5, help="Maximum results to return")
    query_parser.add_argument("--use-cache", action="store_true", help="Use semantic cache")

    # Command: debrief
    debrief_parser = subparsers.add_parser("debrief", help="Run learning debrief (Protocol 128)")
    debrief_parser.add_argument("--hours", type=int, default=24, help="Lookback window in hours")
    debrief_parser.add_argument("--output", help="Output file path (default: .agent/learning/learning_debrief.md)")

    # Command: cache-stats
    subparsers.add_parser("cache-stats", help="Get cache statistics")

    # Command: cache-warmup
    warmup_parser = subparsers.add_parser("cache-warmup", help="Pre-populate cache with genesis queries")
    warmup_parser.add_argument("--queries", nargs="+", help="Custom queries to cache")

    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        sys.exit(1)
    
    # Initialize Operations
    ops = CortexOperations(project_root=args.root)

    if args.command == "ingest":
        print(f"ğŸ”„ Starting full ingestion (Purge: {args.purge})...")
        res = ops.ingest_full(purge_existing=args.purge, source_directories=args.dirs)
        if res.status == "success":
            print(f"âœ… Success: {res.documents_processed} docs, {res.chunks_created} chunks in {res.ingestion_time_ms/1000:.2f}s")
        else:
            print(f"âŒ Error: {res.error}")
            sys.exit(1)

    elif args.command == "snapshot":
        manifest = []
        if args.manifest:
            manifest_path = Path(args.manifest)
            if not manifest_path.exists():
                print(f"âŒ Manifest file not found: {args.manifest}")
                sys.exit(1)
            with open(manifest_path, 'r') as f:
                manifest = json.load(f)
            print(f"ğŸ“‹ Loaded manifest with {len(manifest)} files")
        
        print(f"ğŸ“¸ Capturing {args.type} snapshot...")
        res = ops.capture_snapshot(
            manifest_files=manifest, 
            snapshot_type=args.type,
            strategic_context=args.context
        )
        
        if res.status == "success":
            print(f"âœ… Snapshot created at: {res.snapshot_path}")
            print(f"ğŸ“Š Files: {res.total_files} | Bytes: {res.total_bytes}")
            print(f"ğŸ” Manifest verified: {res.manifest_verified}")
            print(f"ğŸ“ Git context: {res.git_diff_context}")
        else:
            print(f"âŒ Error: {res.error}")
            sys.exit(1)

    elif args.command == "stats":
        stats = ops.get_stats(include_samples=args.samples, sample_count=args.sample_count)
        print(f"ğŸ¥ Health: {stats.health_status}")
        print(f"ğŸ“š Documents: {stats.total_documents}")
        print(f"ğŸ§© Chunks: {stats.total_chunks}")
        
        if stats.collections:
            print("\nğŸ“Š Collections:")
            for name, coll in stats.collections.items():
                print(f"  - {coll.name}: {coll.count} items")
        
        if stats.samples:
            print(f"\nğŸ” Sample Documents:")
            for i, sample in enumerate(stats.samples, 1):
                print(f"\n  {i}. ID: {sample.id}")
                print(f"     Preview: {sample.content_preview[:100]}...")
                if sample.metadata:
                    print(f"     Metadata: {sample.metadata}")
        
        if stats.error:
            print(f"\nâŒ Error: {stats.error}")

    elif args.command == "query":
        print(f"ğŸ” Querying: {args.query_text}")
        res = ops.query(
            query=args.query_text,
            max_results=args.max_results,
            use_cache=args.use_cache
        )
        
        if res.status == "success":
            print(f"âœ… Found {len(res.results)} results in {res.query_time_ms:.2f}ms")
            print(f"ğŸ’¾ Cache hit: {res.cache_hit}")
            
            for i, result in enumerate(res.results, 1):
                print(f"\n--- Result {i} (Score: {result.relevance_score:.4f}) ---")
                print(f"Content: {result.content[:300]}...")
                if result.metadata:
                    source = result.metadata.get('source', 'Unknown')
                    print(f"Source: {source}")
        else:
            print(f"âŒ Error: {res.error}")
            sys.exit(1)

    elif args.command == "debrief":
        print(f"ğŸ“‹ Running learning debrief (lookback: {args.hours}h)...")
        debrief_content = ops.learning_debrief(hours=args.hours)
        
        # Default output path
        output_path = args.output or ".agent/learning/learning_debrief.md"
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, 'w') as f:
            f.write(debrief_content)
        
        print(f"âœ… Debrief written to: {output_file}")
        print(f"ğŸ“Š Content length: {len(debrief_content)} characters")

    elif args.command == "cache-stats":
        stats = ops.get_cache_stats()
        print(f"ğŸ’¾ Cache Statistics:")
        if isinstance(stats, dict):
            for key, value in stats.items():
                print(f"  {key}: {value}")
        else:
            print(f"  {stats}")

    elif args.command == "cache-warmup":
        queries = args.queries or None
        print(f"ğŸ”¥ Warming up cache...")
        res = ops.cache_warmup(genesis_queries=queries)
        
        if res.status == "success":
            print(f"âœ… Cached {res.queries_cached} queries")
            print(f"ğŸ’¾ Cache hits: {res.cache_hits}")
            print(f"âŒ Cache misses: {res.cache_misses}")
            print(f"â±ï¸  Total time: {res.total_time_ms/1000:.2f}s")
        else:
            print(f"âŒ Error: {res.error}")
            sys.exit(1)

if __name__ == "__main__":
    main()
