#!/usr/bin/env python3
"""
inject_summary.py
=====================================

Purpose:
    Direct JSON injection script for Agent-Driven Distillation.
    Allows an AI Agent (Claude, Gemini, Antigravity) to write a summary
    directly into the RLM cache, bypassing local Ollama and slow HTTP calls.

Layer: Curate / Rlm

Usage:
    python plugins/rlm-factory/skills/rlm-curator/scripts/inject_summary.py \
        --profile project \
        --file docs/architecture.md \
        --summary "Dense summary generated by agent..."
"""
import sys
import fcntl
import argparse
from pathlib import Path
from datetime import datetime

# ============================================================
# PATHS
# ============================================================
PROJECT_ROOT = Path(__file__).resolve().parents[5]
SCRIPT_DIR = Path(__file__).resolve().parent

if str(SCRIPT_DIR) not in sys.path:
    sys.path.insert(0, str(SCRIPT_DIR))

try:
    from rlm_config import (
        RLMConfig,
        compute_hash,
        load_cache,
        save_cache
    )
except ImportError as e:
    print(f"❌ Could not import local RLMConfig from {SCRIPT_DIR}: {e}")
    sys.exit(1)


def main() -> None:
    parser = argparse.ArgumentParser(description="RLM Agent Injection — Write summaries directly to cache")
    parser.add_argument("--profile", required=True, help="RLM profile name (from rlm_profiles.json)")
    parser.add_argument("--file", "-f", required=True, help="Single file to process (relative to project root)")
    parser.add_argument("--summary", required=True, help="The summary string to inject")

    args = parser.parse_args()

    try:
        config = RLMConfig(profile_name=args.profile)
        
        f_path = (PROJECT_ROOT / args.file).resolve()
        if not f_path.exists():
            print(f"❌ Target file not found on disk: {args.file}")
            sys.exit(1)

        rel_path = str(f_path.relative_to(PROJECT_ROOT))
        
        # Read the file to generate the content hash
        content = f_path.read_text(encoding="utf-8", errors="ignore")
        content_hash = compute_hash(content)

        # Use a lockfile to serialize concurrent writes (e.g. from swarm workers)
        lock_path = config.cache_path.with_suffix(".lock")
        lock_path.parent.mkdir(parents=True, exist_ok=True)
        with open(lock_path, "w") as lock_file:
            fcntl.flock(lock_file, fcntl.LOCK_EX)  # blocks until lock acquired
            try:
                cache = load_cache(config.cache_path)
                cache[rel_path] = {
                    "hash": content_hash,
                    "summary": args.summary,
                    "summarized_at": datetime.now().isoformat()
                }
                save_cache(cache, config.cache_path)
            finally:
                fcntl.flock(lock_file, fcntl.LOCK_UN)
        
        print(f"✅ Successfully injected summary for {rel_path} into {config.cache_path.name}")

    except Exception as e:
        print(f"❌ Fatal error during injection: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
